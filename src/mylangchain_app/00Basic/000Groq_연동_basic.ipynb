{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8fa7ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb097a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "#load_dotenv(dotenv_path='.env')\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "#print(OPENAI_API_KEY[:10])\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef09a323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt + llm + output \n",
    "\n",
    "# prompt: (ì‰½ê²Œ ë§í•´) AIì—ê²Œ í•˜ëŠ” ì§ˆë¬¸\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.\") , # AIì—ê²Œ ì—­í• ì„ ì£¼ëŠ” ê²ƒ.\n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6c47481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "System: ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.\n",
      "Human: íŒŒì´ì¬ì€ ë¬´ì—‡ì¸ê°€ìš”? ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n"
     ]
    }
   ],
   "source": [
    "prompt_text = prompt.format(input=\"íŒŒì´ì¬ì€ ë¬´ì—‡ì¸ê°€ìš”? ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\")\n",
    "print(type(prompt_text))\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c61ba15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n",
      "client=<openai.resources.chat.completions.completions.Completions object at 0x1402c5990> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1402c6bd0> root_client=<openai.OpenAI object at 0x1402c41d0> root_async_client=<openai.AsyncOpenAI object at 0x1402c68d0> model_name='openai/gpt-oss-120b' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "#llm = ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# GroqëŠ” ChatGPTì™€ í˜¸í™˜ -> ChatGPT ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥\n",
    "# Groq APIë¥¼ ì‚¬ìš©í•˜ëŠ” ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ëª¨ë¸ ê°€ì ¸ì™€ì„œ ìƒì„±)\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\", # ì‚¬ìš© ëª¨ë¸: llama-4-scout\n",
    "    #model=\"moonshotai/kimi-k2-instruct-0905\", # ì‚¬ìš© ëª¨ë¸: kimi-k2\n",
    "    model=\"openai/gpt-oss-120b\", # ì‚¬ìš© ëª¨ë¸: gpt-oss-120b\n",
    "    temperature=0.7\n",
    ")\n",
    "print(type(llm)) # íƒ€ì…: ChatOpenAI\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c3ff864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "ì‘ë‹µ: ## íŒŒì´ì¬(Python)ì´ë€?\n",
      "\n",
      "**íŒŒì´ì¬**ì€ 1991ë…„ ë„¤ëœë€ë“œì˜ í”„ë¡œê·¸ë˜ë¨¸ **ê·€ë„ ë°˜ ë¡œì¸(Guido van Rossum)**ì´ ë°œí‘œí•œ ê³ ìˆ˜ì¤€(highâ€‘level), ì¸í„°í”„ë¦¬í„° ë°©ì‹(interpreted) í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤. â€œíŒŒì´ì¬â€ì´ë¼ëŠ” ì´ë¦„ì€ ë¡œì¸ì´ ì˜êµ­ ì½”ë¯¸ë”” ê·¸ë£¹ *Montyâ€¯Python*ì˜ íŒ¬ì´ì—ˆê¸° ë•Œë¬¸ì— ë¶™ì—¬ì¡Œìœ¼ë©°, ê·¸ ìœ ë¨¸ ê°ê°ì´ ì–¸ì–´ ì„¤ê³„ ì² í•™ì—ë„ ë°˜ì˜ë˜ì—ˆìŠµë‹ˆë‹¤.  \n",
      "\n",
      "íŒŒì´ì¬ì€ **ì½ê¸° ì‰¬ìš´ ë¬¸ë²•**, **í­ë„“ì€ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬**, **ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œì˜ í™œìš©ì„±**ì„ ë°”íƒ•ìœ¼ë¡œ ì „ ì„¸ê³„ ê°œë°œìÂ·ì—°êµ¬ìÂ·í•™ìƒë“¤ì—ê²Œ ì‚¬ë‘ë°›ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. íŒŒì´ì¬ì˜ í•µì‹¬ íŠ¹ì§•\n",
      "\n",
      "| íŠ¹ì§• | ì„¤ëª… | ì¥ì  |\n",
      "|------|------|------|\n",
      "| **ì½ê¸° ì‰¬ìš´ ë¬¸ë²•** | ë“¤ì—¬ì“°ê¸°(Indentation)ë¡œ ë¸”ë¡ì„ êµ¬ë¶„í•˜ê³ , ë¶ˆí•„ìš”í•œ êµ¬ë¬¸(ì„¸ë¯¸ì½œë¡ , ì¤‘ê´„í˜¸ ë“±)ì´ ìµœì†Œí™”ë¨ | ì½”ë“œ ê°€ë…ì„±Â·ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ |\n",
      "| **ë™ì  íƒ€ì´í•‘(Dynamic Typing)** | ë³€ìˆ˜ì— íƒ€ì…ì„ ë¯¸ë¦¬ ì„ ì–¸í•˜ì§€ ì•Šì•„ë„ ëŸ°íƒ€ì„ì— ìë™ìœ¼ë¡œ ê²°ì • | ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘, ìƒì‚°ì„± â†‘ |\n",
      "| **ì¸í„°í”„ë¦¬í„° ë°©ì‹** | ì†ŒìŠ¤ ì½”ë“œë¥¼ ë°”ë¡œ ì‹¤í–‰(ì»´íŒŒì¼ ë‹¨ê³„ê°€ ë‚´ë¶€ì ìœ¼ë¡œ ìë™) | ë””ë²„ê¹…Â·ì‹¤í—˜ì´ ì‰¬ì›€ |\n",
      "| **í’ë¶€í•œ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬** | íŒŒì¼ I/O, ë„¤íŠ¸ì›Œí‚¹, ì›¹, ë°ì´í„°ë² ì´ìŠ¤, ì•”í˜¸í™” ë“± 2000ì—¬ ê°œ ëª¨ë“ˆ ì œê³µ | ì™¸ë¶€ íŒ¨í‚¤ì§€ ì—†ì´ë„ ë‹¤ì–‘í•œ ì‘ì—… ê°€ëŠ¥ |\n",
      "| **ë©€í‹°íŒ¨ëŸ¬ë‹¤ì„ ì§€ì›** | ì ˆì°¨ì , ê°ì²´ì§€í–¥, í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë° ëª¨ë‘ ì§€ì› | ìƒí™©ì— ë§ëŠ” ìŠ¤íƒ€ì¼ ì„ íƒ ê°€ëŠ¥ |\n",
      "| **í”Œë«í¼ ë…ë¦½ì„±** | Windows, macOS, Linux, iOS, Android ë“± ê±°ì˜ ëª¨ë“  OSì—ì„œ ì‹¤í–‰ | â€œWrite once, run anywhereâ€ |\n",
      "| **ëŒ€ê·œëª¨ ìƒíƒœê³„** | PyPI(Python Package Index)ì— 400,000ê°œ ì´ìƒì˜ ì„œë“œíŒŒí‹° íŒ¨í‚¤ì§€ | ë°ì´í„° ê³¼í•™, ì›¹, ê²Œì„, ì„ë² ë””ë“œ ë“± ê±°ì˜ ëª¨ë“  ë¶„ì•¼ ì»¤ë²„ |\n",
      "| **ì»¤ë®¤ë‹ˆí‹°ì™€ ë¬¸ì„œ** | ê³µì‹ ë¬¸ì„œ, íŠœí† ë¦¬ì–¼, Stack Overflow, GitHub ë“± í™œë°œí•œ ì§€ì› | ë¬¸ì œ í•´ê²°ì´ ë¹ ë¥´ê³  í•™ìŠµ ìë£Œê°€ í’ë¶€ |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. íŒŒì´ì¬ì˜ ì—­ì‚¬ì™€ ë²„ì „\n",
      "\n",
      "| ì—°ë„ | ì£¼ìš” ì‚¬ê±´ |\n",
      "|------|-----------|\n",
      "| **1989** | ê·€ë„ ë°˜ ë¡œì¸, â€œABCâ€ ì–¸ì–´ë¥¼ ê°œì„ í•˜ê³ ì íŒŒì´ì¬ ì„¤ê³„ ì‹œì‘ |\n",
      "| **1991** | íŒŒì´ì¬ 0.9.0 ê³µê°œ (ì˜ˆì™¸ ì²˜ë¦¬, í•¨ìˆ˜, ëª¨ë“ˆ) |\n",
      "| **2000** | íŒŒì´ì¬ 2.0 ë¦´ë¦¬ì¦ˆ â€“ ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜, ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ë“± |\n",
      "| **2008** | íŒŒì´ì¬ 3.0 (Pythonâ€¯3) ë°œí‘œ â€“ ë¬¸ìì—´ ìœ ë‹ˆì½”ë“œí™”, `print` í•¨ìˆ˜í™” ë“± í° ë³€í™” |\n",
      "| **2020** | íŒŒì´ì¬ 2.7 ê³µì‹ ì§€ì› ì¢…ë£Œ (EOL) â€“ ëŒ€ë¶€ë¶„ í”„ë¡œì íŠ¸ê°€ Pythonâ€¯3 ì „í™˜ |\n",
      "| **2023** | ìµœì‹  ì•ˆì • ë²„ì „: Pythonâ€¯3.12 (ì„±ëŠ¥ ìµœì í™”, íŒ¨í„´ ë§¤ì¹­ ê°œì„  ë“±) |\n",
      "\n",
      "> **í•µì‹¬ í¬ì¸íŠ¸**: í˜„ì¬ëŠ” **Pythonâ€¯3** ê³„ì—´ì´ í‘œì¤€ì´ë©°, Pythonâ€¯2ëŠ” ë³´ì•ˆÂ·ì—…ë°ì´íŠ¸ê°€ ì œê³µë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ìƒˆ í”„ë¡œì íŠ¸ì—ì„œëŠ” ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. íŒŒì´ì¬ ì½”ë“œ ì˜ˆì‹œì™€ ê¸°ë³¸ ë¬¸ë²•\n",
      "\n",
      "### 3-1. â€œHello, World!â€  \n",
      "\n",
      "```python\n",
      "print(\"Hello, World!\")\n",
      "```\n",
      "\n",
      "- `print`ëŠ” í•¨ìˆ˜ì´ë©°, ë¬¸ìì—´ì„ ì½˜ì†”ì— ì¶œë ¥í•©ë‹ˆë‹¤.\n",
      "\n",
      "### 3-2. ë³€ìˆ˜ì™€ ìë£Œí˜•  \n",
      "\n",
      "```python\n",
      "# ìˆ«ì\n",
      "x = 10          # ì •ìˆ˜\n",
      "y = 3.14        # ì‹¤ìˆ˜\n",
      "\n",
      "# ë¬¸ìì—´\n",
      "name = \"Alice\"\n",
      "\n",
      "# ë¦¬ìŠ¤íŠ¸ (ë°°ì—´)\n",
      "fruits = [\"apple\", \"banana\", \"cherry\"]\n",
      "\n",
      "# ë”•ì…”ë„ˆë¦¬ (í‚¤-ê°’ ìŒ)\n",
      "person = {\"name\": \"Bob\", \"age\": 30}\n",
      "```\n",
      "\n",
      "- íŒŒì´ì¬ì€ **ë™ì  íƒ€ì´í•‘**ì´ë¯€ë¡œ ë³€ìˆ˜ ì„ ì–¸ ì‹œ íƒ€ì…ì„ ëª…ì‹œí•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.\n",
      "\n",
      "### 3-3. ì œì–´ë¬¸  \n",
      "\n",
      "```python\n",
      "# ì¡°ê±´ë¬¸\n",
      "if x > 5:\n",
      "    print(\"xëŠ” 5ë³´ë‹¤ í½ë‹ˆë‹¤.\")\n",
      "elif x == 5:\n",
      "    print(\"xëŠ” 5ì™€ ê°™ìŠµë‹ˆë‹¤.\")\n",
      "else:\n",
      "    print(\"xëŠ” 5ë³´ë‹¤ ì‘ìŠµë‹ˆë‹¤.\")\n",
      "\n",
      "# ë°˜ë³µë¬¸\n",
      "for fruit in fruits:\n",
      "    print(fruit)\n",
      "\n",
      "i = 0\n",
      "while i < 5:\n",
      "    print(i)\n",
      "    i += 1\n",
      "```\n",
      "\n",
      "- ë¸”ë¡ êµ¬ë¶„ì€ **ë“¤ì—¬ì“°ê¸°**(ë³´í†µ 4ì¹¸ ìŠ¤í˜ì´ìŠ¤)ë¡œ í•©ë‹ˆë‹¤.\n",
      "\n",
      "### 3-4. í•¨ìˆ˜ ì •ì˜  \n",
      "\n",
      "```python\n",
      "def greet(name: str, times: int = 1) -> None:\n",
      "    \"\"\"ì£¼ì–´ì§„ ì´ë¦„ì„ ì§€ì •ëœ íšŸìˆ˜ë§Œí¼ ì¸ì‚¬í•©ë‹ˆë‹¤.\"\"\"\n",
      "    for _ in range(times):\n",
      "        print(f\"Hello, {name}!\")\n",
      "\n",
      "greet(\"Charlie\", 3)\n",
      "```\n",
      "\n",
      "- `def` í‚¤ì›Œë“œ, íƒ€ì… íŒíŠ¸(`: str`, `-> None`)ëŠ” ì„ íƒ ì‚¬í•­ì´ì§€ë§Œ ê°€ë…ì„±ê³¼ ì •ì  ë¶„ì„ì— ë„ì›€ì„ ì¤ë‹ˆë‹¤.\n",
      "\n",
      "### 3-5. í´ë˜ìŠ¤ì™€ ê°ì²´ì§€í–¥  \n",
      "\n",
      "```python\n",
      "class Animal:\n",
      "    def __init__(self, species: str):\n",
      "        self.species = species\n",
      "\n",
      "    def speak(self):\n",
      "        raise NotImplementedError(\"ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ êµ¬í˜„í•˜ì„¸ìš”.\")\n",
      "\n",
      "class Dog(Animal):\n",
      "    def speak(self):\n",
      "        return \"ë©ë©!\"\n",
      "\n",
      "dog = Dog(\"Canis lupus familiaris\")\n",
      "print(dog.speak())   # â†’ ë©ë©!\n",
      "```\n",
      "\n",
      "- `__init__`ì€ ìƒì„±ì, `self`ëŠ” ì¸ìŠ¤í„´ìŠ¤ ìì‹ ì„ ê°€ë¦¬í‚¤ëŠ” ê´€ë¡€ì  ì´ë¦„ì…ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. íŒŒì´ì¬ì´ ì£¼ë¡œ ì“°ì´ëŠ” ë¶„ì•¼\n",
      "\n",
      "| ë¶„ì•¼ | ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬/í”„ë ˆì„ì›Œí¬ | í™œìš© ì˜ˆì‹œ |\n",
      "|------|----------------------------|----------|\n",
      "| **ë°ì´í„° ê³¼í•™ & ë¨¸ì‹ ëŸ¬ë‹** | NumPy, pandas, SciPy, scikitâ€‘learn, TensorFlow, PyTorch | ë°ì´í„° ì „ì²˜ë¦¬, ëª¨ë¸ í•™ìŠµ, ì‹œê°í™” |\n",
      "| **ì›¹ ê°œë°œ** | Django, Flask, FastAPI, Tornado | ì›¹ì‚¬ì´íŠ¸Â·API ì„œë²„ êµ¬ì¶• |\n",
      "| **ìë™í™”Â·ìŠ¤í¬ë¦½íŠ¸** | `os`, `shutil`, `subprocess`, `pyautogui` | íŒŒì¼ ê´€ë¦¬, ì‹œìŠ¤í…œ ê´€ë¦¬, GUI ìë™í™” |\n",
      "| **ë„¤íŠ¸ì›Œí‚¹Â·ì‹œìŠ¤í…œ ê´€ë¦¬** | `socket`, `asyncio`, `paramiko` | ì„œë²„/í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„, ë¹„ë™ê¸° I/O |\n",
      "| **ê²Œì„ ê°œë°œ** | Pygame, Panda3D | 2DÂ·3D ê²Œì„ í”„ë¡œí† íƒ€ì… |\n",
      "| **ê³¼í•™Â·ê³µí•™ ì‹œë®¬ë ˆì´ì…˜** | Matplotlib, SymPy, Jupyter Notebook | ì‹œë®¬ë ˆì´ì…˜, ì‹œê°í™”, ì¸í„°ë™í‹°ë¸Œ ì‹¤í—˜ |\n",
      "| **ì„ë² ë””ë“œÂ·IoT** | MicroPython, CircuitPython | ë§ˆì´í¬ë¡œì»¨íŠ¸ë¡¤ëŸ¬(ESP32, Raspberry Pi Pico) í”„ë¡œê·¸ë˜ë° |\n",
      "| **ë³´ì•ˆÂ·í•´í‚¹** | `scapy`, `pwntools`, `impacket` | íŒ¨í‚· ë¶„ì„, ì·¨ì•½ì  í…ŒìŠ¤íŠ¸ |\n",
      "| **êµìœ¡** | Turtle, Jupyter | í”„ë¡œê·¸ë˜ë° ì…ë¬¸, ì‹œê°ì  í•™ìŠµ |\n",
      "\n",
      "> **í•µì‹¬**: íŒŒì´ì¬ì€ **â€œí•œ ë²ˆì— ëª¨ë“  ê²ƒì„ í•  ìˆ˜ ìˆë‹¤â€**ëŠ” ì´ë¯¸ì§€ê°€ ê°•ì ì´ë©°, ì‹¤ì œë¡œ ìœ„ ëª¨ë“  ë¶„ì•¼ì—ì„œ ì‹¤ë¬´ ìˆ˜ì¤€ í”„ë¡œì íŠ¸ê°€ ì§„í–‰ë©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. íŒŒì´ì¬ ì‹¤í–‰ í™˜ê²½\n",
      "\n",
      "| í™˜ê²½ | íŠ¹ì§• | ì¶”ì²œ ìƒí™© |\n",
      "|------|------|-----------|\n",
      "| **CPython** | ê³µì‹ êµ¬í˜„ (C ì–¸ì–´ë¡œ ì‘ì„±) | ëŒ€ë¶€ë¶„ì˜ ì¼ë°˜ í”„ë¡œì íŠ¸ |\n",
      "| **PyPy** | JIT(Justâ€‘Inâ€‘Time) ì»´íŒŒì¼ëŸ¬ íƒ‘ì¬, ë¹ ë¥¸ ì‹¤í–‰ ì†ë„ | ê³„ì‚° ì§‘ì•½ì ì¸ ì‘ì—… |\n",
      "| **Jython** | Java VM ìœ„ì—ì„œ ë™ì‘ | Javaì™€ì˜ ì—°ë™ í•„ìš” ì‹œ |\n",
      "| **IronPython** | .NET í™˜ê²½ | C#Â·.NET ìƒíƒœê³„ì™€ í†µí•© |\n",
      "| **MicroPython / CircuitPython** | ë§ˆì´í¬ë¡œì»¨íŠ¸ë¡¤ëŸ¬ìš© ê²½ëŸ‰ êµ¬í˜„ | ì„ë² ë””ë“œÂ·IoT |\n",
      "| **Anaconda** | ê³¼í•™Â·ë°ì´í„° ë¶„ì„ìš© ë°°í¬íŒ (íŒ¨í‚¤ì§€Â·í™˜ê²½ ê´€ë¦¬) | ë°ì´í„° ê³¼í•™, ë¨¸ì‹ ëŸ¬ë‹ |\n",
      "| **Docker** | ì»¨í…Œì´ë„ˆí™”ëœ íŒŒì´ì¬ ì´ë¯¸ì§€ | ë°°í¬Â·CI/CD, ê²©ë¦¬ëœ í™˜ê²½ |\n",
      "\n",
      "### ê°€ìƒ í™˜ê²½(Virtual Environment)\n",
      "\n",
      "í”„ë¡œì íŠ¸ë§ˆë‹¤ ë…ë¦½ëœ íŒ¨í‚¤ì§€ ì§‘í•©ì„ ê´€ë¦¬í•˜ë ¤ë©´ `venv`(í‘œì¤€) í˜¹ì€ `conda`(Anaconda) ë“±ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "\n",
      "```bash\n",
      "# venv ì˜ˆì‹œ\n",
      "python -m venv myenv          # ê°€ìƒ í™˜ê²½ ìƒì„±\n",
      "source myenv/bin/activate     # (Linux/macOS) í™œì„±í™”\n",
      "myenv\\Scripts\\activate.bat    # (Windows) í™œì„±í™”\n",
      "pip install requests          # íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 6. íŒŒì´ì¬ í•™ìŠµ ë¡œë“œë§µ (ì´ˆê¸‰ â†’ ê³ ê¸‰)\n",
      "\n",
      "1. **ê¸°ì´ˆ ë¬¸ë²•**  \n",
      "   - ë³€ìˆ˜, ìë£Œí˜•, ì—°ì‚°ì, ì…ì¶œë ¥, ì œì–´ë¬¸, í•¨ìˆ˜  \n",
      "   - ì—°ìŠµë¬¸ì œ: â€œ99 Bottles of Beerâ€, í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´, íŒŒì¼ ì½ê¸°/ì“°ê¸°\n",
      "\n",
      "2. **ë°ì´í„° êµ¬ì¡°ì™€ ì•Œê³ ë¦¬ì¦˜**  \n",
      "   - ë¦¬ìŠ¤íŠ¸, íŠœí”Œ, ë”•ì…”ë„ˆë¦¬, ì§‘í•©  \n",
      "   - ê¸°ë³¸ ì •ë ¬Â·ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„, `collections` ëª¨ë“ˆ í™œìš©\n",
      "\n",
      "3. **ê°ì²´ì§€í–¥ í”„ë¡œê·¸ë˜ë°(OOP)**  \n",
      "   - í´ë˜ìŠ¤, ìƒì†, ë‹¤í˜•ì„±, ë§¤ì§ ë©”ì„œë“œ(`__str__`, `__repr__`, `__len__` ë“±)\n",
      "\n",
      "4. **í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ í™œìš©**  \n",
      "   - `os`, `sys`, `pathlib`, `json`, `datetime`, `logging` ë“±\n",
      "\n",
      "5. **ê°€ìƒ í™˜ê²½Â·íŒ¨í‚¤ì§€ ê´€ë¦¬**  \n",
      "   - `pip`, `requirements.txt`, `setup.py`, `poetry` ë“±\n",
      "\n",
      "6. **í…ŒìŠ¤íŒ…**  \n",
      "   - `unittest`, `pytest`ë¥¼ ì´ìš©í•œ ë‹¨ìœ„Â·í†µí•© í…ŒìŠ¤íŠ¸\n",
      "\n",
      "7. **ê³ ê¸‰ ì£¼ì œ**  \n",
      "   - **ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°** (`asyncio`, `aiohttp`)  \n",
      "   - **ë°ì½”ë ˆì´í„°Â·í´ë¡œì €Â·í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°** (`functools`, `itertools`)  \n",
      "   - **C í™•ì¥** (`Cython`, `ctypes`, `cffi`)  \n",
      "   - **í”„ë¡œíŒŒì¼ë§Â·ìµœì í™”** (`cProfile`, `line_profiler`)\n",
      "\n",
      "8. **íŠ¹ì • ë¶„ì•¼ ì‹¬í™”**  \n",
      "   - **ë°ì´í„° ê³¼í•™**: pandas, NumPy, Matplotlib, Jupyter Notebook  \n",
      "   - **ì›¹**: Flask/Django, REST API ì„¤ê³„, ë°°í¬ (Gunicorn, uWSGI, Docker)  \n",
      "   - **ë¨¸ì‹ ëŸ¬ë‹**: scikitâ€‘learn, TensorFlow, PyTorch  \n",
      "   - **ìë™í™”**: Selenium, PyAutoGUI, `cron`/`task scheduler` ì—°ë™  \n",
      "\n",
      "---\n",
      "\n",
      "## 7. íŒŒì´ì¬ ì½”ë“œ í’ˆì§ˆ ê´€ë¦¬\n",
      "\n",
      "| ë„êµ¬ | ì—­í•  | ì˜ˆì‹œ |\n",
      "|------|------|------|\n",
      "| **flake8** | ë¬¸ë²•Â·ìŠ¤íƒ€ì¼ ê²€ì‚¬ (PEPâ€¯8) | `flake8 myproject/` |\n",
      "| **black** | ìë™ í¬ë§·íŒ… (ì½”ë“œ ìŠ¤íƒ€ì¼ ì¼ê´€ì„±) | `black .` |\n",
      "| **isort** | import ì •ë ¬ | `isort .` |\n",
      "| **mypy** | ì •ì  íƒ€ì… ê²€ì‚¬ (íƒ€ì… íŒíŠ¸ ê¸°ë°˜) | `mypy src/` |\n",
      "| **pre-commit** | ì»¤ë°‹ ì „ ìë™ ê²€ì‚¬Â·í¬ë§· | `.pre-commit-config.yaml` ì„¤ì • í›„ `pre-commit install` |\n",
      "| **Sphinx** | ë¬¸ì„œ ìë™ ìƒì„± | `sphinx-quickstart` â†’ `make html` |\n",
      "\n",
      "> **íŒ**: CI(Continuous Integration) íŒŒì´í”„ë¼ì¸ì— ìœ„ ë„êµ¬ë“¤ì„ í¬í•¨í•˜ë©´ íŒ€ ì „ì²´ ì½”ë“œ í’ˆì§ˆì„ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 8. íŒŒì´ì¬ ì»¤ë®¤ë‹ˆí‹°ì™€ í•™ìŠµ ìë£Œ\n",
      "\n",
      "| ì¢…ë¥˜ | ë§í¬ | íŠ¹ì§• |\n",
      "|------|------|------|\n",
      "| **ê³µì‹ ë¬¸ì„œ** | https://docs.python.org/3/ | ê°€ì¥ ì •í™•í•˜ê³  ìµœì‹  ì •ë³´ |\n",
      "| **Python.org íŠœí† ë¦¬ì–¼** | https://docs.python.org/3/tutorial/ | ì…ë¬¸ììš© ë‹¨ê³„ë³„ ê°€ì´ë“œ |\n",
      "| **Real Python** | https://realpython.com/ | ì‹¤ì „ ì˜ˆì œì™€ ì‹¬í™” ê¸€ |\n",
      "| **Awesome Python** | https://github.com/vinta/awesome-python | ë¼ì´ë¸ŒëŸ¬ë¦¬Â·ë„êµ¬ ëª¨ìŒ |\n",
      "| **Stack Overflow** | https://stackoverflow.com/questions/tagged/python | Q&A, ì‹¤ë¬´ ë¬¸ì œ í•´ê²° |\n",
      "| **PyCon** | https://pycon.org/ | êµ­ì œÂ·ì§€ì—­ ì»¨í¼ëŸ°ìŠ¤ ì˜ìƒÂ·ìë£Œ |\n",
      "| **Kaggle** | https://www.kaggle.com/ | ë°ì´í„° ê³¼í•™Â·ë¨¸ì‹ ëŸ¬ë‹ ì‹¤ì „ í”„ë¡œì íŠ¸ |\n",
      "| **GitHub** | https://github.com/python | íŒŒì´ì¬ ì†ŒìŠ¤Â·ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ íƒìƒ‰ |\n",
      "\n",
      "---\n",
      "\n",
      "## 9. íŒŒì´ì¬ì„ ì„ íƒí•´ì•¼ í•˜ëŠ” ì´ìœ  (ìš”ì•½)\n",
      "\n",
      "1. **ìƒì‚°ì„±** â€“ ì§§ì€ ì½”ë“œì™€ í’ë¶€í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ë¹ ë¥´ê²Œ í”„ë¡œí† íƒ€ì…ì„ ë§Œë“¤ ìˆ˜ ìˆë‹¤.  \n",
      "2. **ê°€ë…ì„±** â€“ ì½”ë“œê°€ ì§ê´€ì ì´ì–´ì„œ íŒ€ í˜‘ì—…ê³¼ ìœ ì§€ë³´ìˆ˜ê°€ ì‰½ë‹¤.  \n",
      "3. **ìƒíƒœê³„** â€“ 400k+ íŒ¨í‚¤ì§€ê°€ ìˆì–´ ê±°ì˜ ëª¨ë“  ë¬¸ì œì— ëŒ€í•œ ì†”ë£¨ì…˜ì„ ì°¾ì•„ë³¼ ìˆ˜ ìˆë‹¤.  \n",
      "4. **ë‹¤ì–‘í•œ ë¶„ì•¼** â€“ ì›¹, ë°ì´í„°, ì¸ê³µì§€ëŠ¥, ìë™í™”, ì„ë² ë””ë“œ ë“± ì–´ë””ì—ë“  ì ìš© ê°€ëŠ¥.  \n",
      "5. **ì»¤ë®¤ë‹ˆí‹°** â€“ ì „ ì„¸ê³„ ìˆ˜ë°±ë§Œ ê°œë°œìê°€ í™œë°œíˆ ì§€ì›í•˜ê³  ìˆì–´ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì‰½ê²Œ ì°¾ì„ ìˆ˜ ìˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 10. ê°„ë‹¨í•œ ì‹¤ì „ í”„ë¡œì íŠ¸ ì˜ˆì‹œ\n",
      "\n",
      "### í”„ë¡œì íŠ¸: â€œë‚ ì”¨ ì •ë³´ ì•Œë¦¬ë¯¸â€\n",
      "\n",
      "1. **ëª©í‘œ**: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë„ì‹œì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ì½˜ì†”ì— ì¶œë ¥í•œë‹¤.  \n",
      "2. **í•„ìš” íŒ¨í‚¤ì§€**: `requests` (HTTP ìš”ì²­), `python-dotenv` (API í‚¤ ê´€ë¦¬)  \n",
      "3. **API**: OpenWeatherMap (ë¬´ë£Œ API í‚¤ ì œê³µ)  \n",
      "\n",
      "```python\n",
      "# weather.py\n",
      "import os\n",
      "import requests\n",
      "from dotenv import load_dotenv\n",
      "\n",
      "load_dotenv()                     # .env íŒŒì¼ì—ì„œ API_KEY ë¡œë“œ\n",
      "API_KEY = os.getenv(\"OPENWEATHER_API_KEY\")\n",
      "BASE_URL = \"https://api.openweathermap.org/data/2.5/weather\"\n",
      "\n",
      "def get_weather(city: str) -> str:\n",
      "    params = {\"q\": city, \"appid\": API_KEY, \"units\": \"metric\", \"lang\": \"kr\"}\n",
      "    resp = requests.get(BASE_URL, params=params)\n",
      "    if resp.status_code != 200:\n",
      "        return f\"ì˜¤ë¥˜ ë°œìƒ: {resp.status_code}\"\n",
      "    data = resp.json()\n",
      "    description = data[\"weather\"][0][\"description\"]\n",
      "    temp = data[\"main\"][\"temp\"]\n",
      "    return f\"{city} í˜„ì¬ ë‚ ì”¨: {description}, ì˜¨ë„: {temp}Â°C\"\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    city_name = input(\"ë„ì‹œ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”: \")\n",
      "    print(get_weather(city_name))\n",
      "```\n",
      "\n",
      "- **ì‹¤í–‰**: `python weather.py` â†’ ë„ì‹œ ì´ë¦„ ì…ë ¥ â†’ ë‚ ì”¨ ì¶œë ¥  \n",
      "- **ë°°í¬**: `Dockerfile`ì„ ë§Œë“¤ê³  `docker build -t weather-app .` â†’ ì»¨í…Œì´ë„ˆë¡œ ë°°í¬ ê°€ëŠ¥  \n",
      "\n",
      "ì´ì™€ ê°™ì€ ì‘ì€ í”„ë¡œì íŠ¸ë¥¼ ì—¬ëŸ¬ ê°œ ë§Œë“¤ì–´ ë³´ë©´ íŒŒì´ì¬ì˜ **API í˜¸ì¶œ**, **íŒŒì¼ ì…ì¶œë ¥**, **íŒ¨í‚¤ì§€ ê´€ë¦¬**, **ë°°í¬** ê³¼ì •ì„ ìì—°ìŠ¤ëŸ½ê²Œ ìµí ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## ë§ˆë¬´ë¦¬\n",
      "\n",
      "íŒŒì´ì¬ì€ **â€œì‰½ê²Œ ë°°ìš°ê³ , ê°•ë ¥í•˜ê²Œ í™œìš©í•  ìˆ˜ ìˆëŠ”â€** ì–¸ì–´ë¼ëŠ” í‰ì„ ë°›ê³  ìˆìŠµë‹ˆë‹¤.  \n",
      "- **ì…ë¬¸**: ê¸°ë³¸ ë¬¸ë²•ê³¼ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¶€í„° ì‹œì‘ â†’ ì‘ì€ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±  \n",
      "- **ì‹¤ì „**: ì›¹Â·ë°ì´í„°Â·ìë™í™” ë“± ê´€ì‹¬ ë¶„ì•¼ì˜ í”„ë ˆì„ì›Œí¬Â·íŒ¨í‚¤ì§€ë¥¼ ì ìš©  \n",
      "- **ì „ë¬¸ê°€**: ì„±ëŠ¥ ìµœì í™”, íƒ€ì… íŒíŠ¸Â·ì •ì  ë¶„ì„, ëŒ€ê·œëª¨ í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ê³„  \n",
      "\n",
      "ìœ„ ë‚´ìš©ì´ íŒŒì´ì¬ì„ ì´í•´í•˜ê³ , ì•ìœ¼ë¡œ í•™ìŠµÂ·í™œìš©í•˜ëŠ” ë° ë„ì›€ì´ ë˜ê¸¸ ë°”ëë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì´ë‚˜ íŠ¹ì • ë¶„ì•¼ì— ëŒ€í•œ ë” ìì„¸í•œ ì•ˆë‚´ê°€ í•„ìš”í•˜ë©´ ì–¸ì œë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "# ìƒì„±í•œ ëª¨ë¸ì— ì§ˆë¬¸í•˜ê¸°(prompt ì…ë ¥)\n",
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(\"ì‘ë‹µ:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfc67af",
   "metadata": {},
   "source": [
    "# LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2e4a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd77300d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x1402c5990>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1402c6bd0>, root_client=<openai.OpenAI object at 0x1402c41d0>, root_async_client=<openai.AsyncOpenAI object at 0x1402c68d0>, model_name='openai/gpt-oss-120b', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c5ee6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\":\"LangChainì´ ë¬´ì—‡ì¸ê°€ìš”?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "51e647dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "## LangChainì´ë€?\n",
      "\n",
      "**LangChain**ì€ **ëŒ€í˜• ì–¸ì–´ ëª¨ë¸(LLM)** ì„ í™œìš©í•œ **ì• í”Œë¦¬ì¼€ì´ì…˜**ì„ ë³´ë‹¤ **ì‰½ê³  êµ¬ì¡°í™”ëœ ë°©ì‹**ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆê²Œ í•´ ì£¼ëŠ” **ì˜¤í”ˆì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬**ì…ë‹ˆë‹¤.  \n",
      "ì£¼ë¡œ **Python**ê³¼ **JavaScript/TypeScript**ì—ì„œ ì‚¬ìš©ë˜ë©°, LLMì„ ë‹¨ìˆœíˆ â€œí…ìŠ¤íŠ¸ë¥¼ ìƒì„±â€í•˜ëŠ” ìˆ˜ì¤€ì„ ë„˜ì–´ **ë‹¤ì–‘í•œ ì™¸ë¶€ ë„êµ¬Â·ë°ì´í„°Â·ì›Œí¬í”Œë¡œì™€ ì—°ê²°**í•˜ê³ , **ë³µì¡í•œ ë¡œì§ì„ êµ¬ì„±**í•  ìˆ˜ ìˆê²Œ ë„ì™€ì¤ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## í•µì‹¬ ê°œë…\n",
      "\n",
      "| ê°œë… | ì„¤ëª… | ì˜ˆì‹œ |\n",
      "|------|------|------|\n",
      "| **Chain** | ì—¬ëŸ¬ LLM í˜¸ì¶œÂ·í”„ë¡¬í”„íŠ¸Â·ì „ì²˜ë¦¬Â·í›„ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ìˆœì°¨Â·ë¶„ê¸°Â·ë°˜ë³µì ìœ¼ë¡œ ì—°ê²°í•œ íë¦„ | â€œì‚¬ìš©ì ì§ˆë¬¸ â†’ ê²€ìƒ‰ â†’ ë¬¸ì„œ ìš”ì•½ â†’ ë‹µë³€ ìƒì„±â€ |\n",
      "| **PromptTemplate** | ë³€ìˆ˜(í”Œë ˆì´ìŠ¤í™€ë”)ë¥¼ í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì •ì˜í•˜ê³ , ì‹¤í–‰ ì‹œ ê°’ ì‚½ì… | `template = \"ë‹¤ìŒ ë¬¸ì„œë¥¼ ìš”ì•½í•´ì¤˜: {text}\"` |\n",
      "| **LLM** | OpenAI, Anthropic, Cohere, Azure, HuggingFace ë“± ë‹¤ì–‘í•œ ëª¨ë¸ì— ëŒ€í•œ ë˜í¼ | `ChatOpenAI(model=\"gpt-4o\")` |\n",
      "| **Memory** | ëŒ€í™”/ì‘ì—… ì´ë ¥ì„ ì €ì¥í•´ ë‹¤ìŒ í˜¸ì¶œì— í™œìš© (ì»¨í…ìŠ¤íŠ¸ ìœ ì§€) | ëŒ€í™”í˜• ì±—ë´‡ì—ì„œ ì´ì „ ì§ˆë¬¸Â·ë‹µë³€ì„ ê¸°ì–µ |\n",
      "| **Agents** | â€œë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” LLMâ€ â†’ LLMì´ íŒë‹¨í•´ ê²€ìƒ‰, ê³„ì‚°, ë°ì´í„°ë² ì´ìŠ¤ ì§ˆì˜ ë“± ì™¸ë¶€ ë„êµ¬ë¥¼ í˜¸ì¶œ | â€œë‚ ì”¨ë¥¼ ì•Œë ¤ì¤˜â€ â†’ LLMì´ ë‚ ì”¨ API í˜¸ì¶œ í›„ ê²°ê³¼ ë°˜í™˜ |\n",
      "| **Retrievers** | ë²¡í„°ìŠ¤í† ì–´Â·ê²€ìƒ‰ì—”ì§„ ë“±ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì•„ ë°˜í™˜ (RAG: Retrievalâ€‘Augmented Generation) | `FAISS`, `Pinecone`, `ElasticSearch` ë“± |\n",
      "| **Callbacks / Tracing** | ì‹¤í–‰ íë¦„ì„ ë¡œê¹…Â·ì‹œê°í™”í•´ ë””ë²„ê¹…Â·ëª¨ë‹ˆí„°ë§ | LangSmith(ê³µì‹ íŠ¸ë ˆì´ì‹± ì„œë¹„ìŠ¤) |\n",
      "\n",
      "---\n",
      "\n",
      "## ì™œ LangChainì„ ì‚¬ìš©í•˜ë‚˜ìš”?\n",
      "\n",
      "| ì¥ì  | ìƒì„¸ ì„¤ëª… |\n",
      "|------|-----------|\n",
      "| **êµ¬ì¡°í™”ëœ íŒŒì´í”„ë¼ì¸** | ë³µì¡í•œ LLM ì›Œí¬í”Œë¡œë¥¼ `Chain` ê°ì²´ë¡œ ìº¡ìŠí™”í•´ ì¬ì‚¬ìš©Â·í…ŒìŠ¤íŠ¸ê°€ ì‰¬ì›€ |\n",
      "| **ë‹¤ì–‘í•œ ì™¸ë¶€ ë„êµ¬ ì—°ë™** | ê²€ìƒ‰, ë°ì´í„°ë² ì´ìŠ¤, API, íŒŒì¼ ì‹œìŠ¤í…œ ë“±ê³¼ ìì—°ìŠ¤ëŸ½ê²Œ ê²°í•© |\n",
      "| **í”„ë¡¬í”„íŠ¸ ê´€ë¦¬** | í…œí”Œë¦¿, ë³€ìˆ˜, ì²´ì´ë‹ì„ í†µí•´ í”„ë¡¬í”„íŠ¸ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ê´€ë¦¬ |\n",
      "| **ë©”ëª¨ë¦¬ì™€ ìƒíƒœ** | ëŒ€í™”í˜• ì•±ì—ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìë™ ë³´ì¡´ |\n",
      "| **ë©€í‹°ëª¨ë¸Â·ë©€í‹°í´ë¼ìš°ë“œ** | OpenAI, Anthropic, Azure, Bedrock ë“± ì—¬ëŸ¬ LLMì„ ë™ì¼ ì¸í„°í˜ì´ìŠ¤ë¡œ êµì²´ ê°€ëŠ¥ |\n",
      "| **ìƒì‚°ì„±** | ì‚¬ì „ êµ¬í˜„ëœ `Agents`, `Retrievers`, `DocumentLoaders` ë“±ìœ¼ë¡œ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘ |\n",
      "| **ì˜¤í”ˆì†ŒìŠ¤ + ì»¤ë®¤ë‹ˆí‹°** | í™œë°œí•œ GitHub, Docs, ì˜ˆì œ, í”ŒëŸ¬ê·¸ì¸(ì˜ˆ: LangSmith) ì œê³µ |\n",
      "\n",
      "---\n",
      "\n",
      "## ì£¼ìš” êµ¬ì„± ìš”ì†Œì™€ ì˜ˆì‹œ ì½”ë“œ (Python)\n",
      "\n",
      "```python\n",
      "from langchain import PromptTemplate, LLMChain\n",
      "from langchain.chat_models import ChatOpenAI\n",
      "from langchain.memory import ConversationBufferMemory\n",
      "from langchain.retrievers import FAISSRetriever\n",
      "from langchain.document_loaders import TextLoader\n",
      "from langchain.vectorstores import FAISS\n",
      "from langchain.embeddings import OpenAIEmbeddings\n",
      "\n",
      "# 1ï¸âƒ£ LLM ì„¤ì •\n",
      "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
      "\n",
      "# 2ï¸âƒ£ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
      "template = \"\"\"ë‹¤ìŒ ë¬¸ì„œë¥¼ ìš”ì•½í•´ì¤˜:\n",
      "{text}\n",
      "ìš”ì•½ì€ 3ë¬¸ì¥ ì´í•˜ë¡œ ì‘ì„±í•˜ê³ , í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ê°•ì¡°í•´ì¤˜.\"\"\"\n",
      "prompt = PromptTemplate.from_template(template)\n",
      "\n",
      "# 3ï¸âƒ£ ì²´ì¸ ì •ì˜ (í”„ë¡¬í”„íŠ¸ + LLM)\n",
      "summary_chain = LLMChain(prompt=prompt, llm=llm)\n",
      "\n",
      "# 4ï¸âƒ£ ë¬¸ì„œ ë¡œë“œ & ë²¡í„°ìŠ¤í† ì–´ (RAG)\n",
      "loader = TextLoader(\"data/article.txt\")\n",
      "docs = loader.load()\n",
      "embeddings = OpenAIEmbeddings()\n",
      "vectorstore = FAISS.from_documents(docs, embeddings)\n",
      "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
      "\n",
      "# 5ï¸âƒ£ ì „ì²´ íŒŒì´í”„ë¼ì¸ (RAG + ìš”ì•½)\n",
      "def answer_question(question: str) -> str:\n",
      "    # ê²€ìƒ‰ â†’ ìš”ì•½ â†’ LLM ì‘ë‹µ\n",
      "    retrieved_docs = retriever.get_relevant_documents(question)\n",
      "    combined_text = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
      "    summary = summary_chain.run({\"text\": combined_text})\n",
      "    final_prompt = f\"\"\"ì§ˆë¬¸: {question}\n",
      "ìš”ì•½ëœ ë‚´ìš©: {summary}\n",
      "ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëª…í™•í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì¤˜.\"\"\"\n",
      "    return llm.invoke(final_prompt).content\n",
      "\n",
      "print(answer_question(\"ì¸ê³µì§€ëŠ¥ ìœ¤ë¦¬ ë¬¸ì œëŠ” ë¬´ì—‡ì¸ê°€?\"))\n",
      "```\n",
      "\n",
      "### ì½”ë“œ íë¦„\n",
      "1. **LLM** (`ChatOpenAI`)ì„ ì´ˆê¸°í™”.  \n",
      "2. **PromptTemplate** ë¡œ ìš”ì•½ í”„ë¡¬í”„íŠ¸ ì •ì˜.  \n",
      "3. **LLMChain** ìœ¼ë¡œ â€œí…ìŠ¤íŠ¸ â†’ ìš”ì•½â€ ë‹¨ê³„ êµ¬í˜„.  \n",
      "4. **FAISS** ê¸°ë°˜ **Retriever** ë¡œ ì§ˆë¬¸ì— ê´€ë ¨ëœ ë¬¸ì„œ 3ê°œë¥¼ ê²€ìƒ‰.  \n",
      "5. ê²€ìƒ‰ëœ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ê³ , ìµœì¢… í”„ë¡¬í”„íŠ¸ì— ë„£ì–´ **ë‹µë³€** ìƒì„±.\n",
      "\n",
      "---\n",
      "\n",
      "## ëŒ€í‘œì ì¸ ì‚¬ìš© ì‚¬ë¡€\n",
      "\n",
      "| ë¶„ì•¼ | êµ¬ì²´ì ì¸ ì˜ˆì‹œ |\n",
      "|------|--------------|\n",
      "| **ê²€ìƒ‰ ê¸°ë°˜ Q&A** | ê¸°ì—… ìœ„í‚¤Â·ë²•ë¥  ë¬¸ì„œÂ·ì½”ë“œë² ì´ìŠ¤ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ì •í™•í•œ ë‹µë³€ ì œê³µ (RAG) |\n",
      "| **ëŒ€í™”í˜• ì—ì´ì „íŠ¸** | ê³ ê°ì§€ì› ì±—ë´‡, ë‚´ë¶€ í—¬í”„ë°ìŠ¤í¬, ê°œì¸ ë¹„ì„œ (ë©”ëª¨ë¦¬ + Toolâ€‘Calling) |\n",
      "| **ë°ì´í„° ë¶„ì„** | ìì—°ì–´ë¡œ SQL/NoSQL ì¿¼ë¦¬ ìƒì„± â†’ DB ì‹¤í–‰ â†’ ê²°ê³¼ ìš”ì•½ |\n",
      "| **ë¬¸ì„œ ìë™í™”** | ê³„ì•½ì„œ ì´ˆì•ˆ â†’ ì¡°í•­ ê²€í†  â†’ ìš”ì•½Â·í•˜ì´ë¼ì´íŠ¸ |\n",
      "| **ì½”ë“œ ë³´ì¡°** | í”„ë¡¬í”„íŠ¸ë¥¼ í†µí•´ ì½”ë“œë¥¼ ìƒì„±Â·ë””ë²„ê¹…Â·ë¦¬íŒ©í„°ë§ (ì½”ë“œ ì‹¤í–‰ ì—ì´ì „íŠ¸ì™€ ê²°í•©) |\n",
      "| **ë©€í‹°ëª¨ë‹¬** | ì´ë¯¸ì§€Â·í…ìŠ¤íŠ¸Â·ìŒì„± ë“± ì—¬ëŸ¬ ì…ë ¥ì„ LLMì— ì—°ê²° (LangChainâ€¯+â€¯LangGraph ë“±) |\n",
      "\n",
      "---\n",
      "\n",
      "## ì—ì½”ì‹œìŠ¤í…œ & í™•ì¥ í¬ì¸íŠ¸\n",
      "\n",
      "| ì˜ì—­ | ì§€ì›Â·ì—°ë™ |\n",
      "|------|-----------|\n",
      "| **ë²¡í„°ìŠ¤í† ì–´** | FAISS, Pinecone, Weaviate, Milvus, Chroma, Qdrant ë“± |\n",
      "| **ë°ì´í„° ë¡œë”** | íŒŒì¼(í…ìŠ¤íŠ¸, PDF, CSV), ì›¹ìŠ¤í¬ë˜í•‘, DB, Google Drive, S3 ë“± |\n",
      "| **íˆ´(Agents)** | `SerpAPI`(ê²€ìƒ‰), `PythonREPL`, `RequestsTool`, `SQLDatabaseToolkit`, `WolframAlpha` ë“± |\n",
      "| **ì¶”ì Â·ëª¨ë‹ˆí„°ë§** | LangSmith (ê³µì‹ íŠ¸ë ˆì´ì‹±Â·í”„ë¡¬í”„íŠ¸ ê´€ë¦¬), OpenTelemetry, ìì²´ ì½œë°± |\n",
      "| **ë©€í‹°ëª¨ë‹¬** | LangChainâ€¯+â€¯LangGraph(ì›Œí¬í”Œë¡œ ê·¸ë˜í”„), LangChainâ€¯+â€¯LLMâ€‘Vision(ì´ë¯¸ì§€) |\n",
      "| **ë°°í¬** | FastAPI, Flask, AWS Lambda, Azure Functions, LangServe(ê³µì‹ ì„œë²„), Docker, LangChainHub(ê³µìœ  ì²´ì¸) |\n",
      "\n",
      "---\n",
      "\n",
      "## ì‹œì‘í•˜ê¸° â€“ ê°„ë‹¨ ê°€ì´ë“œ\n",
      "\n",
      "1. **ì„¤ì¹˜**  \n",
      "   ```bash\n",
      "   pip install langchain openai  # ê¸°ë³¸ íŒ¨í‚¤ì§€\n",
      "   # í•„ìš”ì— ë”°ë¼ ì¶”ê°€\n",
      "   pip install faiss-cpu langchain-community\n",
      "   ```\n",
      "\n",
      "2. **API í‚¤ ì„¤ì •**  \n",
      "   ```bash\n",
      "   export OPENAI_API_KEY=\"sk-...\"\n",
      "   ```\n",
      "\n",
      "3. **ì²« ë²ˆì§¸ ì²´ì¸ ë§Œë“¤ê¸°**  \n",
      "   ```python\n",
      "   from langchain.chat_models import ChatOpenAI\n",
      "   from langchain.prompts import PromptTemplate\n",
      "   from langchain.chains import LLMChain\n",
      "\n",
      "   llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
      "   prompt = PromptTemplate.from_template(\"ë‹¤ìŒ ë¬¸ì¥ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì¤˜: {text}\")\n",
      "   translate_chain = LLMChain(prompt=prompt, llm=llm)\n",
      "\n",
      "   print(translate_chain.run({\"text\": \"Hello, world!\"}))\n",
      "   ```\n",
      "\n",
      "4. **ë¬¸ì„œ ê²€ìƒ‰ + ë‹µë³€** (ìœ„ ì˜ˆì‹œ ì½”ë“œ ì°¸ê³ )\n",
      "\n",
      "5. **ë°°í¬**  \n",
      "   *FastAPI*ì™€ `langserve`ë¥¼ ì´ìš©í•˜ë©´ ëª‡ ì¤„ë¡œ API ì„œë²„ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "   ```python\n",
      "   from fastapi import FastAPI\n",
      "   from langserve import add_routes\n",
      "\n",
      "   app = FastAPI()\n",
      "   add_routes(app, translate_chain, path=\"/translate\")\n",
      "   ```\n",
      "\n",
      "---\n",
      "\n",
      "## ì°¸ê³  ìë£Œ\n",
      "\n",
      "| ì¢…ë¥˜ | ë§í¬ |\n",
      "|------|------|\n",
      "| **ê³µì‹ Docs** | <https://python.langchain.com/> |\n",
      "| **GitHub** | <https://github.com/langchain-ai/langchain> |\n",
      "| **LangSmith** (íŠ¸ë ˆì´ì‹±Â·í”„ë¡¬í”„íŠ¸ ê´€ë¦¬) | <https://smith.langchain.com/> |\n",
      "| **íŠœí† ë¦¬ì–¼** | LangChain â€œGetting Startedâ€ Notebook (Colab) |\n",
      "| **ì»¤ë®¤ë‹ˆí‹°** | Discord, Reddit r/LangChain, StackOverflow íƒœê·¸ `langchain` |\n",
      "\n",
      "---\n",
      "\n",
      "### í•œ ì¤„ ìš”ì•½\n",
      "> **LangChain**ì€ LLMì„ **í”„ë¡¬í”„íŠ¸, ë©”ëª¨ë¦¬, ê²€ìƒ‰, ë„êµ¬**ì™€ ì—°ê²°í•´ **êµ¬ì¡°í™”ëœ íŒŒì´í”„ë¼ì¸(Chain)** ìœ¼ë¡œ ë§Œë“¤ ìˆ˜ ìˆê²Œ í•´ ì£¼ëŠ” **ì˜¤í”ˆì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬**ì´ë©°, ë³µì¡í•œ AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë¹ ë¥´ê²Œ í”„ë¡œí† íƒ€ì´í•‘Â·ë°°í¬í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(type(response))\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
