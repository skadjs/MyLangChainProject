{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8fa7ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb097a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "#load_dotenv(dotenv_path='.env')\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "#print(OPENAI_API_KEY[:10])\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef09a323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt + llm + output \n",
    "\n",
    "# prompt: (ì‰½ê²Œ ë§í•´) AIì—ê²Œ í•˜ëŠ” ì§ˆë¬¸\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.\") , # AIì—ê²Œ ì—­í• ì„ ì£¼ëŠ” ê²ƒ.\n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6c47481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "System: ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.\n",
      "Human: íŒŒì´ì¬ì€ ë¬´ì—‡ì¸ê°€ìš”? ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n"
     ]
    }
   ],
   "source": [
    "prompt_text = prompt.format(input=\"íŒŒì´ì¬ì€ ë¬´ì—‡ì¸ê°€ìš”? ìì„¸í•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\")\n",
    "print(type(prompt_text))\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c61ba15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n",
      "client=<openai.resources.chat.completions.completions.Completions object at 0x140293790> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1402ba610> root_client=<openai.OpenAI object at 0x14011d2d0> root_async_client=<openai.AsyncOpenAI object at 0x140292490> model_name='openai/gpt-oss-120b' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "#llm = ChatOpenAI(api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "# GroqëŠ” ChatGPTì™€ í˜¸í™˜ -> ChatGPT ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥\n",
    "# Groq APIë¥¼ ì‚¬ìš©í•˜ëŠ” ChatOpenAI ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ëª¨ë¸ ê°€ì ¸ì™€ì„œ ìƒì„±)\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\", # ì‚¬ìš© ëª¨ë¸: llama-4-scout\n",
    "    #model=\"moonshotai/kimi-k2-instruct-0905\", # ì‚¬ìš© ëª¨ë¸: kimi-k2\n",
    "    model=\"openai/gpt-oss-120b\", # ì‚¬ìš© ëª¨ë¸: gpt-oss-120b\n",
    "    temperature=0.7\n",
    ")\n",
    "print(type(llm)) # íƒ€ì…: ChatOpenAI\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c3ff864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "ì‘ë‹µ: ## íŒŒì´ì¬(Python)ì´ë€?\n",
      "\n",
      "íŒŒì´ì¬ì€ **ê³ ê¸‰(highâ€‘level) í”„ë¡œê·¸ë˜ë° ì–¸ì–´**ì´ë©°, 1991ë…„ ë„¤ëœë€ë“œì˜ ê·€ë„ ë°˜ ë¡œì„¬(Guido van Rossum)ì´ ì²˜ìŒ ë°œí‘œí–ˆìŠµë‹ˆë‹¤. í˜„ì¬ëŠ” ì „ ì„¸ê³„ ìˆ˜ë§ì€ ê°œë°œìì™€ ê¸°ì—…ì´ ì‚¬ìš©í•˜ê³  ìˆëŠ” ê°€ì¥ ì¸ê¸° ìˆëŠ” ì–¸ì–´ ì¤‘ í•˜ë‚˜ì´ë©°, **ì½ê¸° ì‰¬ìš´ ë¬¸ë²•**, **ë‹¤ì–‘í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬Â·í”„ë ˆì„ì›Œí¬**, **ê´‘ë²”ìœ„í•œ ì ìš© ë¶„ì•¼**ê°€ íŠ¹ì§•ì…ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. íŒŒì´ì¬ì˜ ì£¼ìš” íŠ¹ì§•\n",
      "\n",
      "| íŠ¹ì§• | ì„¤ëª… |\n",
      "|------|------|\n",
      "| **ì½ê¸° ì‰¬ìš´ ë¬¸ë²•** | ì½”ë“œê°€ ìì—°ì–´ì— ê°€ê¹ê³  ë“¤ì—¬ì“°ê¸°ë¡œ ë¸”ë¡ì„ êµ¬ë¶„í•´ ê°€ë…ì„±ì´ ë›°ì–´ë‚©ë‹ˆë‹¤. |\n",
      "| **ë™ì  íƒ€ì´í•‘** | ë³€ìˆ˜ ì„ ì–¸ ì‹œ íƒ€ì…ì„ ëª…ì‹œí•˜ì§€ ì•Šì•„ë„ ëŸ°íƒ€ì„ì— ìë™ìœ¼ë¡œ ê²°ì •ë©ë‹ˆë‹¤. |\n",
      "| **ì¸í„°í”„ë¦¬í„° ì–¸ì–´** | ì†ŒìŠ¤ ì½”ë“œë¥¼ ë°”ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆì–´ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ì™€ í”„ë¡œí† íƒ€ì´í•‘ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. |\n",
      "| **ë©€í‹°íŒ¨ëŸ¬ë‹¤ì„** | ì ˆì°¨í˜•, ê°ì²´ì§€í–¥, í•¨ìˆ˜í˜• í”„ë¡œê·¸ë˜ë°ì„ ëª¨ë‘ ì§€ì›í•©ë‹ˆë‹¤. |\n",
      "| **í’ë¶€í•œ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬** | íŒŒì¼ I/O, ë„¤íŠ¸ì›Œí‚¹, ì›¹, ë°ì´í„°ë² ì´ìŠ¤, ì•”í˜¸í™” ë“± 2ë§Œ ê°œ ì´ìƒì˜ ëª¨ë“ˆ ì œê³µ. |\n",
      "| **í”Œë«í¼ ë…ë¦½ì„±** | Windows, macOS, Linux ë“± ê±°ì˜ ëª¨ë“  ìš´ì˜ì²´ì œì—ì„œ ë™ì¼í•˜ê²Œ ë™ì‘í•©ë‹ˆë‹¤. |\n",
      "| **í™•ì¥ì„±** | C/C++ ë¡œ ì‘ì„±ëœ ëª¨ë“ˆì„ ì‰½ê²Œ í˜¸ì¶œí•˜ê±°ë‚˜, Cython, PyPy ë“±ìœ¼ë¡œ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. |\n",
      "| **í™œë°œí•œ ì»¤ë®¤ë‹ˆí‹°** | ì „ ì„¸ê³„ ê°œë°œìÂ·ì—°êµ¬ìë“¤ì´ ë§Œë“  ìˆ˜ë§ì€ ì˜¤í”ˆì†ŒìŠ¤ íŒ¨í‚¤ì§€ì™€ íŠœí† ë¦¬ì–¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. íŒŒì´ì¬ì˜ ê¸°ë³¸ ë¬¸ë²•\n",
      "\n",
      "### 2â€‘1. ë³€ìˆ˜ì™€ ìë£Œí˜•\n",
      "```python\n",
      "# ì •ìˆ˜, ì‹¤ìˆ˜, ë¬¸ìì—´, ë¶ˆë¦¬ì–¸\n",
      "a = 10          # int\n",
      "b = 3.14        # float\n",
      "name = \"Alice\"  # str\n",
      "flag = True     # bool\n",
      "```\n",
      "\n",
      "### 2â€‘2. ì»¬ë ‰ì…˜(ì‹œí€€ìŠ¤) ìë£Œí˜•\n",
      "```python\n",
      "# ë¦¬ìŠ¤íŠ¸\n",
      "numbers = [1, 2, 3, 4]\n",
      "\n",
      "# íŠœí”Œ (ë¶ˆë³€)\n",
      "coords = (10, 20)\n",
      "\n",
      "# ë”•ì…”ë„ˆë¦¬ (í‚¤-ê°’ ìŒ)\n",
      "person = {\"name\": \"Bob\", \"age\": 30}\n",
      "\n",
      "# ì§‘í•© (ì¤‘ë³µ ì—†ëŠ” ì›ì†Œ)\n",
      "unique = {1, 2, 3}\n",
      "```\n",
      "\n",
      "### 2â€‘3. ì œì–´ íë¦„\n",
      "```python\n",
      "# ì¡°ê±´ë¬¸\n",
      "if a > 5:\n",
      "    print(\"aëŠ” 5ë³´ë‹¤ í½ë‹ˆë‹¤.\")\n",
      "elif a == 5:\n",
      "    print(\"aëŠ” 5ì™€ ê°™ìŠµë‹ˆë‹¤.\")\n",
      "else:\n",
      "    print(\"aëŠ” 5ë³´ë‹¤ ì‘ìŠµë‹ˆë‹¤.\")\n",
      "\n",
      "# ë°˜ë³µë¬¸\n",
      "for i in range(5):      # 0~4\n",
      "    print(i)\n",
      "\n",
      "while flag:\n",
      "    # ì–´ë–¤ ì‘ì—… ìˆ˜í–‰\n",
      "    flag = False        # ë£¨í”„ íƒˆì¶œ\n",
      "```\n",
      "\n",
      "### 2â€‘4. í•¨ìˆ˜ ì •ì˜\n",
      "```python\n",
      "def greet(name: str, times: int = 1) -> None:\n",
      "    \"\"\"ì¸ì‚¬ë¥¼ ì—¬ëŸ¬ ë²ˆ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜.\"\"\"\n",
      "    for _ in range(times):\n",
      "        print(f\"Hello, {name}!\")\n",
      "\n",
      "greet(\"Alice\", 3)\n",
      "```\n",
      "\n",
      "### 2â€‘5. í´ë˜ìŠ¤ì™€ ê°ì²´ì§€í–¥\n",
      "```python\n",
      "class Animal:\n",
      "    def __init__(self, name):\n",
      "        self.name = name\n",
      "\n",
      "    def speak(self):\n",
      "        raise NotImplementedError\n",
      "\n",
      "class Dog(Animal):\n",
      "    def speak(self):\n",
      "        return \"ë©ë©!\"\n",
      "\n",
      "class Cat(Animal):\n",
      "    def speak(self):\n",
      "        return \"ì•¼ì˜¹!\"\n",
      "\n",
      "dog = Dog(\"ë°”ë‘‘ì´\")\n",
      "cat = Cat(\"ë‚˜ë¹„\")\n",
      "print(dog.speak())  # ë©ë©!\n",
      "print(cat.speak())  # ì•¼ì˜¹!\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 3. íŒŒì´ì¬ì´ ì“°ì´ëŠ” ë¶„ì•¼\n",
      "\n",
      "| ë¶„ì•¼ | í™œìš© ì˜ˆì‹œ |\n",
      "|------|-----------|\n",
      "| **ì›¹ ê°œë°œ** | Django, Flask, FastAPI ë“± ì›¹ í”„ë ˆì„ì›Œí¬ë¡œ ì„œë²„Â·API êµ¬í˜„ |\n",
      "| **ë°ì´í„° ê³¼í•™Â·ë¨¸ì‹ ëŸ¬ë‹** | NumPy, pandas, scikit-learn, TensorFlow, PyTorch ë“± |\n",
      "| **ìë™í™”Â·ìŠ¤í¬ë¦½íŠ¸** | ì‹œìŠ¤í…œ ê´€ë¦¬, íŒŒì¼ ì²˜ë¦¬, ì›¹ ìŠ¤í¬ë˜í•‘(BeautifulSoup, Selenium) |\n",
      "| **ê³¼í•™Â·ê³µí•™** | ì‹œë®¬ë ˆì´ì…˜, ìˆ˜ì¹˜í•´ì„(NumPy, SciPy), ì‹œê°í™”(Matplotlib, Seaborn) |\n",
      "| **ê²Œì„ ê°œë°œ** | Pygame, Panda3D ë“± |\n",
      "| **ë°ìŠ¤í¬í†±Â·GUI** | Tkinter, PyQt, Kivy ë“± |\n",
      "| **ì„ë² ë””ë“œÂ·IoT** | MicroPython, CircuitPython |\n",
      "| **êµìœ¡** | í”„ë¡œê·¸ë˜ë° ì…ë¬¸ ì–¸ì–´ë¡œ ë„ë¦¬ ì‚¬ìš© (ë¬¸ë²•ì´ ê°„ë‹¨í•˜ê³  ì§ê´€ì ) |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. íŒŒì´ì¬ ì‹¤í–‰ í™˜ê²½\n",
      "\n",
      "1. **CPython** â€“ ê°€ì¥ ì¼ë°˜ì ì¸ êµ¬í˜„ (Cë¡œ ì‘ì„±, ê³µì‹ ë ˆí¼ëŸ°ìŠ¤ êµ¬í˜„)\n",
      "2. **PyPy** â€“ JIT(Justâ€‘Inâ€‘Time) ì»´íŒŒì¼ëŸ¬ ê¸°ë°˜, ì†ë„ê°€ ë¹ ë¦„\n",
      "3. **Jython** â€“ Java í”Œë«í¼ ìœ„ì—ì„œ ë™ì‘, Java ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ í˜¸í™˜\n",
      "4. **IronPython** â€“ .NET í”Œë«í¼ìš© êµ¬í˜„\n",
      "5. **MicroPython / CircuitPython** â€“ ë§ˆì´í¬ë¡œì»¨íŠ¸ë¡¤ëŸ¬ìš© ê²½ëŸ‰ êµ¬í˜„\n",
      "\n",
      "### ê°€ìƒ í™˜ê²½(Virtual Environment)\n",
      "í”„ë¡œì íŠ¸ë§ˆë‹¤ ë…ë¦½ì ì¸ íŒ¨í‚¤ì§€ ì§‘í•©ì„ ê´€ë¦¬í•˜ê¸° ìœ„í•´ `venv` ë˜ëŠ” `conda`ì™€ ê°™ì€ ê°€ìƒ í™˜ê²½ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "\n",
      "```bash\n",
      "# venv ì‚¬ìš© ì˜ˆì‹œ\n",
      "python -m venv myenv\n",
      "source myenv/bin/activate   # macOS/Linux\n",
      "myenv\\Scripts\\activate.bat  # Windows\n",
      "\n",
      "# íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
      "pip install requests pandas\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 5. íŒŒì´ì¬ íŒ¨í‚¤ì§€ ê´€ë¦¬\n",
      "\n",
      "- **pip** : ê¸°ë³¸ íŒ¨í‚¤ì§€ ë§¤ë‹ˆì € (`pip install package_name`)\n",
      "- **conda** : ê³¼í•™Â·ë°ì´í„° ë¶„ì•¼ì—ì„œ ë§ì´ ì“°ì´ëŠ” í™˜ê²½Â·íŒ¨í‚¤ì§€ ë§¤ë‹ˆì € (`conda install numpy`)\n",
      "- **Poetry** / **pipenv** : ì˜ì¡´ì„± íŒŒì¼(`pyproject.toml`, `Pipfile`)ì„ ìë™ ê´€ë¦¬í•´ì£¼ëŠ” í˜„ëŒ€ì ì¸ ë„êµ¬\n",
      "\n",
      "---\n",
      "\n",
      "## 6. ì„±ëŠ¥ ìµœì í™” íŒ\n",
      "\n",
      "| ë°©ë²• | ì„¤ëª… |\n",
      "|------|------|\n",
      "| **Cython** | íŒŒì´ì¬ ì½”ë“œë¥¼ Cë¡œ ë³€í™˜í•´ ì‹¤í–‰ ì†ë„ í–¥ìƒ |\n",
      "| **Numba** | JIT ì»´íŒŒì¼ëŸ¬ë¥¼ ì‚¬ìš©í•´ ìˆ˜ì¹˜ ì—°ì‚° ê°€ì† |\n",
      "| **ë©€í‹°ìŠ¤ë ˆë”©** | I/O ë°”ìš´ë“œ ì‘ì—…ì— `threading` í™œìš© (GIL ì œí•œ) |\n",
      "| **ë©€í‹°í”„ë¡œì„¸ì‹±** | CPU ë°”ìš´ë“œ ì‘ì—…ì— `multiprocessing` í™œìš© |\n",
      "| **ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°** | `asyncio` ë¡œ I/O ë³‘ë ¬ ì²˜ë¦¬ |\n",
      "| **í”„ë¡œíŒŒì¼ë§** | `cProfile`, `line_profiler` ë¡œ ë³‘ëª© ì°¾ê¸° |\n",
      "| **ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬** | NumPy, pandas ë“± C/Fortran ê¸°ë°˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© |\n",
      "\n",
      "---\n",
      "\n",
      "## 7. íŒŒì´ì¬ í•™ìŠµ ë¡œë“œë§µ (ì´ˆê¸‰ â†’ ê³ ê¸‰)\n",
      "\n",
      "1. **ê¸°ì´ˆ ë¬¸ë²•**  \n",
      "   - ë³€ìˆ˜, ìë£Œí˜•, ì—°ì‚°ì, ì œì–´ë¬¸, í•¨ìˆ˜, ê¸°ë³¸ ì…ì¶œë ¥\n",
      "2. **ë°ì´í„° êµ¬ì¡°**  \n",
      "   - ë¦¬ìŠ¤íŠ¸, íŠœí”Œ, ë”•ì…”ë„ˆë¦¬, ì§‘í•©, ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜\n",
      "3. **íŒŒì¼Â·ì˜ˆì™¸ ì²˜ë¦¬**  \n",
      "   - `open()`, `with`, `try/except`\n",
      "4. **ê°ì²´ì§€í–¥**  \n",
      "   - í´ë˜ìŠ¤, ìƒì†, ë‹¤í˜•ì„±, ë§¤ì§ ë©”ì„œë“œ(`__init__`, `__str__` ë“±)\n",
      "5. **í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬**  \n",
      "   - `datetime`, `os`, `sys`, `json`, `re`(ì •ê·œí‘œí˜„ì‹) ë“±\n",
      "6. **ê°€ìƒ í™˜ê²½Â·íŒ¨í‚¤ì§€ ê´€ë¦¬**  \n",
      "   - `venv`, `pip`, `requirements.txt`\n",
      "7. **ì›¹ ê°œë°œ ì…ë¬¸**  \n",
      "   - Flask í˜¹ì€ Django ê¸°ë³¸ í”„ë¡œì íŠ¸ ë§Œë“¤ê¸°\n",
      "8. **ë°ì´í„° ê³¼í•™ ê¸°ì´ˆ**  \n",
      "   - NumPy, pandas, Matplotlib ì‹¤ìŠµ\n",
      "9. **í…ŒìŠ¤íŠ¸Â·ë””ë²„ê¹…**  \n",
      "   - `unittest`, `pytest`, `logging`\n",
      "10. **ê³ ê¸‰ ì£¼ì œ**  \n",
      "    - ë¹„ë™ê¸°(`asyncio`), ë©”íƒ€í´ë˜ìŠ¤, ë°ì½”ë ˆì´í„°, Cython/Numba í™œìš©\n",
      "11. **í”„ë¡œì íŠ¸ ê²½í—˜**  \n",
      "    - ì‹¤ì œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì‘ì€ í”„ë¡œì íŠ¸(ì˜ˆ: ì›¹ API, ë°ì´í„° ë¶„ì„, ìë™í™” ìŠ¤í¬ë¦½íŠ¸) ìˆ˜í–‰\n",
      "\n",
      "---\n",
      "\n",
      "## 8. íŒŒì´ì¬ ì»¤ë®¤ë‹ˆí‹°ì™€ ìë£Œ\n",
      "\n",
      "- **ê³µì‹ ë¬¸ì„œ** : https://docs.python.org/3/\n",
      "- **PyPI (íŒ¨í‚¤ì§€ ì €ì¥ì†Œ)** : https://pypi.org/\n",
      "- **Stack Overflow** : íŒŒì´ì¬ ê´€ë ¨ Q&A\n",
      "- **GitHub** : ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ íƒìƒ‰\n",
      "- **Kaggle** : ë°ì´í„° ì‚¬ì´ì–¸ìŠ¤Â·ë¨¸ì‹ ëŸ¬ë‹ ì‹¤ìŠµ\n",
      "- **í•œêµ­ íŒŒì´ì¬ ì‚¬ìš©ì ëª¨ì„** : íŒŒì´ì½˜, íŒŒì´ì¬ì½”ë¦¬ì•„ ë“±\n",
      "\n",
      "---\n",
      "\n",
      "## 9. ê°„ë‹¨í•œ ì‹¤ìŠµ ì˜ˆì œ: ì›¹ ìŠ¤í¬ë˜í•‘\n",
      "\n",
      "ì•„ë˜ ì½”ë“œëŠ” `requests`ì™€ `BeautifulSoup`ì„ ì´ìš©í•´ ìœ„í‚¤í”¼ë””ì•„ í˜ì´ì§€ì˜ ì²« ë²ˆì§¸ ë¬¸ë‹¨ì„ ê°€ì ¸ì˜¤ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤.\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "\n",
      "def get_wiki_intro(title: str) -> str:\n",
      "    url = f\"https://en.wikipedia.org/wiki/{title}\"\n",
      "    resp = requests.get(url)\n",
      "    resp.raise_for_status()      # ì˜¤ë¥˜ ì‹œ ì˜ˆì™¸ ë°œìƒ\n",
      "\n",
      "    soup = BeautifulSoup(resp.text, \"html.parser\")\n",
      "    # ë³¸ë¬¸ ì²« ë²ˆì§¸ <p> ìš”ì†Œ ì¶”ì¶œ\n",
      "    first_para = soup.select_one(\"div.mw-parser-output > p\")\n",
      "    return first_para.get_text(strip=True)\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    intro = get_wiki_intro(\"Python_(programming_language)\")\n",
      "    print(intro)\n",
      "```\n",
      "\n",
      "> **Tip**: ì‹¤ì œ ì„œë¹„ìŠ¤ì— ì ìš©í•  ê²½ìš° `robots.txt` ì •ì±…ì„ í™•ì¸í•˜ê³ , ê³¼ë„í•œ ìš”ì²­ì„ í”¼í•˜ê¸° ìœ„í•´ `time.sleep()` ë“±ìœ¼ë¡œ ë”œë ˆì´ë¥¼ ì£¼ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "## 10. ê²°ë¡ \n",
      "\n",
      "íŒŒì´ì¬ì€ **ì½ê¸° ì‰¬ìš´ ë¬¸ë²•**, **ê°•ë ¥í•œ í‘œì¤€Â·ì„œë“œíŒŒí‹° ë¼ì´ë¸ŒëŸ¬ë¦¬**, **ë‹¤ì–‘í•œ ì ìš© ë¶„ì•¼** ë•ë¶„ì— ì´ˆë³´ìë¶€í„° ì „ë¬¸ê°€ê¹Œì§€ í­ë„“ê²Œ í™œìš©ë˜ëŠ” ì–¸ì–´ì…ë‹ˆë‹¤. ê¸°ë³¸ ë¬¸ë²•ì„ íƒ„íƒ„íˆ ìµíŒ ë’¤, **í”„ë¡œì íŠ¸ ê¸°ë°˜ í•™ìŠµ**ì„ í†µí•´ ì›¹ ê°œë°œ, ë°ì´í„° ê³¼í•™, ìë™í™” ë“± ìì‹ ì´ ê´€ì‹¬ ìˆëŠ” ë¶„ì•¼ì— íŒŒì´ì¬ì„ ì ìš©í•´ ë³´ì„¸ìš”. ê¾¸ì¤€íˆ ì½”ë“œë¥¼ ì‘ì„±í•˜ê³ , ì»¤ë®¤ë‹ˆí‹°ì— ì°¸ì—¬í•œë‹¤ë©´ ë¹ ë¥´ê²Œ ì‹¤ë ¥ì„ ì„±ì¥ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. \n",
      "\n",
      "ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ì–¸ì œë“  ì§ˆë¬¸í•´ ì£¼ì„¸ìš”! ğŸš€\n"
     ]
    }
   ],
   "source": [
    "# ìƒì„±í•œ ëª¨ë¸ì— ì§ˆë¬¸í•˜ê¸°(prompt ì…ë ¥)\n",
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(type(response))\n",
    "    print(\"ì‘ë‹µ:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2e4a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd77300d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ê°œë°œìì…ë‹ˆë‹¤.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x13794dcd0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x140224090>, root_client=<openai.OpenAI object at 0x1378a6f90>, root_async_client=<openai.AsyncOpenAI object at 0x137e7d6d0>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c5ee6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\":\"ì§€êµ¬ì˜ ìì „ì£¼ê¸°ëŠ” ì–¼ë§ˆì¸ê°€ìš”?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51e647dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "ì§€êµ¬ì˜ ìì „ì£¼ê¸°ëŠ” 24ì‹œê°„ì…ë‹ˆë‹¤. ì´ë¥¼ íƒœì–‘ì‹œë¼ê³  ë¶€ë¥´ê¸°ë„ í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "print(type(response))\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
