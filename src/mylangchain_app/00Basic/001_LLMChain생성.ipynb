{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4cb2eb",
   "metadata": {},
   "source": [
    "# LLM Chain 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1e012",
   "metadata": {},
   "source": [
    "## 1. 환경 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addb358f",
   "metadata": {},
   "source": [
    "### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "983a63b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c8b9d0",
   "metadata": {},
   "source": [
    "### 2) OpenAI 인증키 설정\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92fb8c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_3\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a965e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.27\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3139ae1",
   "metadata": {},
   "source": [
    "## 2. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1096a2cb",
   "metadata": {},
   "source": [
    "### 1) Prompt + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "559b327f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"인공지능 모델의 학습 원리에 대하여 쉽게 설명해 주세요.\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0deaaba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='인공지능 모델의 학습 원리는 다음과 같습니다.\\n\\n1. **데이터 수집**: 인공지능 모델을 학습시키기 위해서는 대량의 데이터가 필요합니다. 이 데이터는 문제에 따라 달라지며, 예를 들어 이미지 인식 모델을 학습시키기 위해서는 많은 이미지 데이터가 필요합니다.\\n\\n2. **데이터 전처리**: 수집된 데이터를 모델이 학습할 수 있도록 전처리합니다. 예를 들어, 이미지 데이터를 픽셀 값으로 변환하거나, 텍스트 데이터를 숫자 값으로 변환하는 등의 작업이 포함됩니다.\\n\\n3. **모델 정의**: 인공지능 모델을 정의합니다. 모델은 신경망, 의사결정 트리, 선형 회귀 등 다양한 형태가 있을 수 있습니다.\\n\\n4. **학습**: 모델에 전처리된 데이터를 입력하고, 모델이 예측한 결과와 실제 결과(라벨)의 차이를 계산합니다. 이 차이를 **손실 함수(loss function)**라고 합니다. 손실 함수를 최소화하는 방향으로 모델의 가중치를 업데이트합니다. 이 과정을 **역전파(backpropagation)**라고 합니다.\\n\\n5. **평가**: 학습된 모델을 평가합니다. 평가 데이터에 모델을 적용하고, 모델의 성능을 측정합니다.\\n\\n6. **최적화**: 모델의 성능을 최적화하기 위해 하이퍼파라미터를 조정하거나, 모델의 구조를 변경합니다.\\n\\n7. **반복**: 4~6 단계를 반복하여 모델의 성능을 향상시킵니다.\\n\\n예를 들어, 고양이와 개를 구별하는 모델을 학습시킨다고 가정해 봅시다.\\n\\n*   데이터를 수집합니다. (고양이 이미지 1000개, 개 이미지 1000개)\\n*   이미지를 전처리합니다. (이미지를 픽셀 값으로 변환)\\n*   모델을 정의합니다. (신경망 모델)\\n*   학습합니다. (이미지를 입력하고, 모델이 예측한 결과와 실제 결과(고양이 또는 개)의 차이를 계산)\\n*   평가합니다. (평가 데이터에 모델을 적용하고, 모델의 성능을 측정)\\n*   최적화합니다. (하이퍼파라미터를 조정하거나, 모델의 구조를 변경)\\n*   반복합니다. (성능이 만족할 때까지 반복)\\n\\n이렇게 인공지능 모델은 데이터를 학습하여 패턴을 인식하고, 예측을 수행할 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 470, 'prompt_tokens': 24, 'total_tokens': 494, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.199640061, 'prompt_time': 0.000431443, 'completion_time': 1.233729772, 'total_time': 1.234161215}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_79da0e0073', 'id': 'chatcmpl-01daeb25-4116-4293-8a45-66d700e45d40', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--26111889-f3bf-489d-b094-5f4e525234e0-0' usage_metadata={'input_tokens': 24, 'output_tokens': 470, 'total_tokens': 494, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb66eda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해서는 대량의 데이터가 필요합니다. 이 데이터는 문제에 따라 달라지며, 예를 들어 이미지 인식 모델을 학습시키기 위해서는 많은 이미지 데이터가 필요합니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집된 데이터를 모델이 학습할 수 있도록 전처리합니다. 예를 들어, 이미지 데이터를 픽셀 값으로 변환하거나, 텍스트 데이터를 숫자 값으로 변환하는 등의 작업이 포함됩니다.\n",
      "\n",
      "3. **모델 정의**: 인공지능 모델을 정의합니다. 모델은 신경망, 의사결정 트리, 선형 회귀 등 다양한 형태가 있을 수 있습니다.\n",
      "\n",
      "4. **학습**: 모델에 전처리된 데이터를 입력하고, 모델이 예측한 결과와 실제 결과(라벨)의 차이를 계산합니다. 이 차이를 **손실 함수(loss function)**라고 합니다. 손실 함수를 최소화하는 방향으로 모델의 가중치를 업데이트합니다. 이 과정을 **역전파(backpropagation)**라고 합니다.\n",
      "\n",
      "5. **평가**: 학습된 모델을 평가합니다. 평가 데이터에 모델을 적용하고, 모델의 성능을 측정합니다.\n",
      "\n",
      "6. **최적화**: 모델의 성능을 최적화하기 위해 하이퍼파라미터를 조정하거나, 모델의 구조를 변경합니다.\n",
      "\n",
      "7. **반복**: 4~6 단계를 반복하여 모델의 성능을 향상시킵니다.\n",
      "\n",
      "예를 들어, 고양이와 개를 구별하는 모델을 학습시킨다고 가정해 봅시다.\n",
      "\n",
      "*   데이터를 수집합니다. (고양이 이미지 1000개, 개 이미지 1000개)\n",
      "*   이미지를 전처리합니다. (이미지를 픽셀 값으로 변환)\n",
      "*   모델을 정의합니다. (신경망 모델)\n",
      "*   학습합니다. (이미지를 입력하고, 모델이 예측한 결과와 실제 결과(고양이 또는 개)의 차이를 계산)\n",
      "*   평가합니다. (평가 데이터에 모델을 적용하고, 모델의 성능을 측정)\n",
      "*   최적화합니다. (하이퍼파라미터를 조정하거나, 모델의 구조를 변경)\n",
      "*   반복합니다. (성능이 만족할 때까지 반복)\n",
      "\n",
      "이렇게 인공지능 모델은 데이터를 학습하여 패턴을 인식하고, 예측을 수행할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821574e",
   "metadata": {},
   "source": [
    "### 2) PromptTemplate + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b617e8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} template='You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3358f7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='인공지능 모델이 ‘학습’한다는 말은, 우리가 ‘문제-정답’ 세트를 아이에게 계속 풀게 하면서 실력을 키워 주는 것과 똑같습니다.\\n\\n1. 예시 주기  \\n   “고양이 사진” → “고양이”라는 꼬리표  \\n   “강아지 사진” → “강아지”라는 꼬리표  \\n   이런 쌍을 수천∼수백만 장 준비합니다.\\n\\n2. 처음엔 맞을 확률이 10% 정도밖에 안 됩니다.  \\n   모델 안에는 수십억 개의 ‘다이얼(가중치)’가 있는데, 이 다이얼을 아무렇게나 돌려서 나온 답이 틀리기 때문입니다.\\n\\n3. 틀린 만큼 ‘얼마나 틀렸는지’를 수치로 계산합니다(이게 ‘손실 함수’).  \\n   “정답 100점, 내 답 30점 → 70점만큼 틀림”\\n\\n4. 미적분으로 “어느 다이얼을 얼마만큼 돌려야 점수가 가장 많이 오를까?”를 계산합니다(‘역전파’).  \\n   이 과정을 ‘그래디언트 하강’이라고 부릅니다.\\n\\n5. 다이얼을 살짝 돌려서 다음 번엔 30점→50점, 또 돌려서 50점→70점 …  \\n   이렇게 수백만 번 반복하면 95% 이상 맞추게 됩니다.\\n\\n6. 새로운 사진이 들어와도, 학습 때 조정한 다이얼로 계산하면  \\n   “이건 고양이일 확률 97%, 강아지 3%”처럼 답을 내놓습니다.\\n\\n요약:  \\n“잔뜩 틀렸다 → 얼마나 틀렸는지 계산 → 다이얼을 미세 조정 → 다시 틀린다 → 또 조정 …”  \\n이 무한 반복이 바로 ‘인공지능 학습’입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 563, 'prompt_tokens': 66, 'total_tokens': 629, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.172977705, 'prompt_time': 0.01148507, 'completion_time': 2.291208439, 'total_time': 2.302693509}, 'model_name': 'moonshotai/kimi-k2-instruct-0905', 'system_fingerprint': 'fp_b8565bb333', 'id': 'chatcmpl-44932096-45f7-451f-abb4-6022438b8d3e', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--3b8c5d95-9d7e-42fa-91b9-a5fce18f0145-0' usage_metadata={'input_tokens': 66, 'output_tokens': 563, 'total_tokens': 629, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))\n",
    "\n",
    "# chain 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4b14ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 스스로 학습할 수 있도록 하는 것이죠. \n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 구분하는 모델을 만든다고 가정해 봅시다.\n",
      "\n",
      "1. **데이터 수집**: 수많은 고양이와 강아지의 사진을 모읍니다. 이 사진들이 바로 인공지능이 학습하는 재료가 됩니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집한 사진들을 컴퓨터가 이해할 수 있는 형태로 변환합니다. \n",
      "\n",
      "3. **모델 설계**: 고양이와 강아지의 특징을 스스로 찾아낼 수 있는 신경망 구조를 설계합니다. 이 구조는 여러 층의 노드(또는 뉴런)로 구성되어 있습니다.\n",
      "\n",
      "4. **학습**: 이 모델에 고양이 사진에는 '고양이'라는 레이블을, 강아지 사진에는 '강아지'라는 레이블을 달아줍니다. 그런 다음, 모델이 이 사진들과 레이블들을 보고 스스로 고양이와 강아지를 구분할 수 있는 규칙을 찾도록 합니다. 이 과정에서는 모델이 예측한 결과와 실제 레이블 간의 오차를 계산하고, 이 오차를 줄이기 위해 모델의 내부 파라미터들을 조금씩 조정합니다. 이를 반복하면서 모델은 점점 더 정확하게 고양이와 강아지를 구분하는 법을 배웁니다.\n",
      "\n",
      "5. **평가**: 학습이 끝난 후, 모델이 새로운 사진들을 보고 고양이와 강아지를 얼마나 정확하게 구분하는지 테스트합니다.\n",
      "\n",
      "6. **튜닝**: 필요하다면 모델의 구조를 바꾸거나, 학습 데이터를 조정하여 모델의 성능을 더욱 향상시킵니다.\n",
      "\n",
      "이처럼 인공지능 모델은 대량의 데이터를 통해 반복적으로 학습하며, 스스로 문제 해결 능력을 키웁니다. 이를 통해 이미지 인식, 자연어 처리, 음성 인식 등 다양한 분야에서 놀라운 성능을 발휘할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35860af9",
   "metadata": {},
   "source": [
    "### 3) PromptTemplate + LLM(invoke()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e888e777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'str'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \n",
      "\n",
      "사람이 경험을 통해 배우고 기억하는 것처럼, 인공지능 모델도 데이터를 통해 학습합니다. \n",
      "\n",
      "인공지능 모델의 학습 과정은 다음과 같습니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해 필요한 데이터를 수집합니다. 이 데이터는 문제에 대한 답을 포함하고 있어야 합니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집한 데이터를 모델이 이해할 수 있도록 가공합니다. \n",
      "\n",
      "3. **모델 훈련**: 전처리된 데이터를 모델에 입력하여 모델의 파라미터를 조정합니다. 이 과정은 예측 결과와 실제 값의 오차를 최소화하는 방향으로 진행됩니다.\n",
      "\n",
      "4. **모델 평가**: 훈련된 모델의 성능을 평가합니다. \n",
      "\n",
      "5. **모델 개선**: 평가 결과에 따라 모델을 개선합니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 보겠습니다. \n",
      "\n",
      "이를 위해 고양이와 강아지의 사진을 많이 수집하고, 각 사진에 고양이 또는 강아지라는 레이블을 붙입니다. \n",
      "\n",
      "이 데이터를 모델에 입력하여 모델이 고양이와 강아지의 특징을 학습하도록 합니다. \n",
      "\n",
      "학습이 완료되면, 새로운 사진을 입력했을 때, 모델은 고양이 또는 강아지라는 레이블을 출력할 수 있습니다.\n",
      "\n",
      "인공지능 모델의 학습 원리는 이처럼 데이터를 통해 모델을 학습시키고, 모델의 성능을 평가하고 개선하는 과정입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. \\\n",
    "                                      Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 2. chain 생성 (LCEL)\n",
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "\n",
    "# 3. chain의 invoke 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7106b99",
   "metadata": {},
   "source": [
    "### 4) PromptTemplate + LLM(stream()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14003c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 배우고, 판단하고, 결정하는 능력을 키우는 과정이라고 생각하시면 됩니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델이 학습하기 위해서는 많은 데이터가 필요합니다. 이 데이터는 과거에 발생했던 일에 대한 정보이거나, 현재 상태에 대한 정보일 수 있습니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집된 데이터는 모델이 학습하기 전에 전처리 과정을 거칩니다. 이 과정에서는 데이터의 오류를 수정하거나, 필요한 정보를 추가하는 등의 작업이 이루어집니다.\n",
      "\n",
      "3. **모델 훈련**: 전처리된 데이터는 이제 모델의 훈련에 사용됩니다. 모델은 주어진 데이터로부터 패턴이나 규칙을 스스로 찾아냅니다. 이 과정은 '훈련' 또는 '학습'이라고 하며, 모델은 이 과정을 통해 특정 작업을 수행하는 능력을 키웁니다.\n",
      "\n",
      "4. **손실 함수**: 모델의 성능을 평가하기 위해 손실 함수(loss function)라는 것을 사용합니다. 손실 함수는 모델의 예측 결과와 실제 값 사이의 차이를 계산합니다. 손실 함수의 값을 최소화하는 것이 모델의 목표입니다.\n",
      "\n",
      "5. **최적화**: 모델은 손실 함수의 값을 최소화하기 위해 최적화 알고리즘을 사용합니다. 최적화 알고리즘은 모델의 파라미터를 조정하여 손실 함수의 값을 줄여가는 과정입니다.\n",
      "\n",
      "6. **평가**: 모델의 성능을 평가하기 위해 테스트 데이터를 사용합니다. 테스트 데이터에 대한 모델의 성능이 만족할 만한 수준이면, 모델은 잘 학습했다고 할 수 있습니다.\n",
      "\n",
      "7. **예측**: 학습된 모델은 새로운 데이터에 대해 예측을 수행할 수 있습니다. 예측 결과는 실제 값과 유사해야 하며, 모델의 성능에 따라 예측의 정확도가 달라집니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. \n",
      "\n",
      "- **데이터 수집**: 고양이와 강아지의 사진들을 많이 수집합니다.\n",
      "- **데이터 전처리**: 사진들을 일정한 크기로 줄이고, 필요 없는 부분은 제거하는 등의 작업을 합니다.\n",
      "- **모델 훈련**: 수집된 사진들을 모델에 보여주면서, 고양이 사진인지 강아지 사진인지를 모델 스스로 구분하도록 합니다.\n",
      "- **손실 함수**: 모델의 예측 결과와 실제 값(고양이 또는 강아지) 사이의 차이를 계산합니다.\n",
      "- **최적화**: 모델은 손실 함수의 값을 최소화하기 위해 파라미터를 조정합니다.\n",
      "- **평가**: 테스트 데이터에 대해 모델의 성능을 평가합니다.\n",
      "- **예측**: 새로운 사진이 주어졌을 때, 모델은 고양이 사진인지 강아지 사진인지를 예측합니다.\n",
      "\n",
      "이처럼 인공지능 모델은 데이터를 통해 학습하고, 주어진 작업에 대해 스스로 판단하고 결정하는 능력을 키웁니다."
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. \\\n",
    "                                      Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "lm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "# 스트리밍 출력\n",
    "#print(answer)\n",
    "\n",
    "for token in answer:\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.(flush=True)\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9facb193",
   "metadata": {},
   "source": [
    "### 5) Multiple Chains\n",
    "- Multi Chain을 활용한 영화 추천 및 줄거리 요약 (잘 동작하지 않는 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce6e5cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      " ===> 추천된 영화:\n",
      "**<언 포기븐 (Unforgiven, 1992)>**를 꼽고 싶습니다.  \n",
      "클린트 이스트우드가 감독·주연을 맡은 서부극이지만, 본질은 ‘죄와 속죄’를 그린 무거운 드라마예요. 퇴직한 살인청부업자가 마지막 의뢰를 받고 다시 총을 잡으며 벌어지는 이야기인데, 폭력이 남기는 상처와 인간 내면의 어둠을 조용하면서도 잔인하게 파헹칩니다. 끝없이 펼쳐진 대지와 서늘한 감성이 몰입도를 더해주죠. 서부극 특유의 여운과 함께 ‘과연 사람은 변할 수 있을까’라는 질문을 오래 들고 있게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "movie = chain1.invoke({\"genre\": \"Drama\"})  # 영화 제목 얻기\n",
    "\n",
    "print(type(movie))\n",
    "print(\" ===> 추천된 영화:\")  # movie 값 출력\n",
    "print(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c1268e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first={\n",
      "  movie: ChatPromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, template='{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.'), additional_kwargs={})])\n",
      "         | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10cd8b1d0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10ce0a490>, root_client=<openai.OpenAI object at 0x10cd88e50>, root_async_client=<openai.AsyncOpenAI object at 0x10ce095d0>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "         | StrOutputParser()\n",
      "} middle=[ChatPromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, template='{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요'), additional_kwargs={})]), ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x10cd8b1d0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x10ce0a490>, root_client=<openai.OpenAI object at 0x10cd88e50>, root_async_client=<openai.AsyncOpenAI object at 0x10ce095d0>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n",
      "\n",
      "🔹 영화 줄거리 요약:\n",
      " **《컨트롤》 (Control, 2007)**  \n",
      "감독: 앤톤 코르빈  \n",
      "캐스팅: 샘 라일리(이안 커티스), 사만다 모튼(데보라 커티스), 알렉산드라 마리아 라라(애니크), 조 덴(훅이), 제임스 피어슨(모리스)  \n",
      "\n",
      "줄거리: 1970년대 말 영국 맨체스터, 10대 소년 이안 커티스는 학교 친구들과 록밴드 Joy Division을 결성하고 급속도로 명성을 얻는다. 하지만 무대 위의 카리스마와 달리 그의 일상은 뇌전증 진단, 결혼과 외도, 찾아오는 우울증으로 점차 무너져 간다. 흑백 화면 속에 담긴 그의 23년간 짧고 강렬한 삶은 음악과 고통, 그리고 예술가의 고독이 어떻게 뒤얽혀 있는지를 섬세하게 그려낸다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(chain2)\n",
    "\n",
    "# 실행: \"Drama\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\\n\", response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae506f04",
   "metadata": {},
   "source": [
    "##### chain1과 chain2에서 영화 제목이 일관되게 전달 되도록 변경 (잘 동작하는 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37f8e752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 영화 줄거리 요약:\n",
      "('어바웃 타임  \\n'\n",
      " 'About Time  \\n'\n",
      " '리차드 커티스 감독 | 레이첼 맥아담스, 돈흐갤런 글리슨, 빌 나이, 린데이 던컨, 톰 화이터 출연  \\n'\n",
      " '\\n'\n",
      " '어느 날, 21살 생일을 맞은 팀은 아버지로부터 놀라운 가문의 비밀을 들려준다: 집 안 남자들은 모두 시간을 되돌릴 수 있다는 것. '\n",
      " '하지만 팀은 단순히 과거를 고치는 대신, 진짜로 중요한 순간들을 알아차리며 자신만의 방식으로 ‘완벽한’ 하루하루를 만들어간다. 우연히 '\n",
      " '만난 메리와의 사랑, 가족과의 관계, 그리고 평범한 일상 속에서 발견하는 특별한 순간들이 그려지는 가운데, 시간 여행은 결국 ‘어떻게 '\n",
      " '살아갈 것인가’에 대한 따뜻한 답을 찾아가는 여정이 된다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: \"Drama\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\")\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
