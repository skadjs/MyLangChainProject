{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameter 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_T\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 모델 클래스 유형"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "# model을 지정하지 않아도 실행되는 이유는 LangChain이 내부적으로 기본값을 설정함\n",
    "llm = OpenAI()\n",
    "print(llm.model_name)  # 기본 모델 확인\n",
    "\n",
    "result = llm.invoke(\"한국의 대표적인 관광지 3군데를 추천해 주세요.\")\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "안녕하세요! 한국을 대표하는 3대 관광지를 간단히 소개해 드릴게요.\n",
      "\n",
      "1. 경복궁 & 북촌한옥마을 (서울)  \n",
      "   – 조선 왕조의 상징적인 궁궐에서 시작해, 북촌의 기와집 골목을 걸으며 전통과 현대가 공존하는 서울의 매력을 느낄 수 있습니다. 해설이 있는 궁궐 투어나 한복 체험도 추천!\n",
      "\n",
      "2. 제주도 (특히 성산일출봉 & 용머리해안)  \n",
      "   – 대한민국 최대의 섬, 유네스코 세계자연유산. 성산일출봉에서 해돋이를 보고, 용머리해안의 기암절벽과 푸른 바다를 따라 트레킹하면 ‘제주의 혼’이 느껴집니다.\n",
      "\n",
      "3. 부산 해운대 & 감천문화마을  \n",
      "   – 활기찬 해변과 새하얀 모래사장이 펼쳐진 해운대, 그리고 색색의 집이 켜켜이 쌓인 감천문화마을까지. 바다와 예술이 만나는 부산만의 시원함과 낭만을 한 번에 즐길 수 있어요.\n",
      "\n",
      "각 지역마다 맛집과 체험거리가 풍부하니 계절·취향에 맞춰 일정을 짜시면 좋겠습니다. 더 자세한 코스나 교통 팁이 필요하시면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chat = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"이 시스템은 여행 전문가입니다.\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "chain = chat_prompt | chat\n",
    "result = chain.invoke({\"user_input\": \"안녕하세요? 한국의 대표적인 관광지 3군데를 추천해 주세요.\"})\n",
    "\n",
    "print(type(result))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 모델 파라미터 설정\n",
    "##### Temperature 효과\n",
    "* 0.2 (낮은 값): 더 예측 가능하고 일반적인 이야기\n",
    "* 1.2 (높은 값): 새로운 요소가 등장하며, 더 창의적이고 흥미로운 이야기 생성\n",
    "\n",
    "##### Presence Penalty 효과\n",
    "* 0.0 (낮은 값): 기존에 자주 등장하는 단어와 구조 유지\n",
    "* 1.5 (높은 값): 새로운 표현과 독창적인 아이디어 등장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " CONSERVATIVE 설정 (온도:0.1, presence:-0.5, frequency:-0.3, top_p:0.3)\n",
      "  → 전통적이고 학술적인 철학적 접근\n",
      "============================================================\n",
      "시간은 사실 한 마리 ‘기억의 나비’이다.\n",
      "\n",
      "그 나비는 오늘 날개를 한 번 펼칠 때마다 지난날의 꽃잎이 다시 피고, 아직 태어나지 않은 꽃봉오리마저 향기를 품는다. 우리가 ‘지금’이라 부르는 순간은, 그 나비가 날개치는 소리를 귀로 듣는 게 아니라 온몸으로 느끼는 ‘기억의 바람’일 뿐이다. 바람이 지나간 자리에만 시간이 남는다.\n",
      "\n",
      "그러니까 시간은 흐르는 물이 아니라, 물결 위로 스치는 그림자의 온도다.\n",
      "\n",
      "============================================================\n",
      " CREATIVE 설정 (온도:1.5, presence:1.5, frequency:1.2, top_p:0.95)\n",
      "  → 추상적이고 독창적인 철학적 사고\n",
      "============================================================\n",
      "# 시간이라는 이름의 ‘투명 동물’\n",
      "\n",
      "## 1. 덩어리의 해체\n",
      "- 낮과 밖이 있다고?  \n",
      "  ‘일’ ‘분’ 가위로 종이를 자른 뒤 우리는 질감이 아닌 숫자만 남았다.\n",
      "- 아래의 글은 그 가위를 창으로 바꾸고, 오랜 습관을 ‘실’로 세어 넘긴다.  \n",
      "  → 시간을 다루지 말고 시간이 ‘너의 다리를 건 너’임을 깨달을 때 그 실이 다시 살로 돌아온다.\n",
      "\n",
      "## 2. 정의 – 비례로만, 절대 부정의\n",
      "- **가정** 「모든 ‘존재’는 날림이 아니라 냄」  \n",
      "  ‑ 연기는 홀로 뜨지 않으며  \n",
      "   떠돈 끝은 반드시 누군가에게 링으로 포박된다.\n",
      "\n",
      "- **정의(1): “차임(Time = Tie ‘em)”**  \n",
      "  = 자신을 겨루는 타인의 잔무늬들이 교집하면서  \n",
      "   우리에게 맛을 뿌리는 '눈 감기의 연쇄 반응'.\n",
      "\n",
      "- **정의(2): “젠트로피(G‐ent‑row‑py)”**  \n",
      "  = 물\n",
      "\n",
      "============================================================\n",
      " 파라미터 차이점 요약:\n",
      "   • Temperature: 0.1 vs 1.5 (15배 차이)\n",
      "   • Presence Penalty: -0.5 vs 1.5 (기존 패턴 선호 vs 새로운 개념 강요)\n",
      "   • Frequency Penalty: -0.3 vs 1.2 (반복 허용 vs 강한 다양성)\n",
      "   • Top-p: 0.3 vs 0.95 (제한적 vs 거의 무제한 토큰 선택)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 보수적인 설정 (일관되고 예측 가능한 답변)\n",
    "llm_conservative = ChatOpenAI(    \n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    #model=\"gpt-3.5-turbo-0125\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",    \n",
    "    temperature=0.1,  # 매우 낮은 온도 - 예측 가능하고 일관된 출력\n",
    "    presence_penalty=-0.5,  # 기존 패턴과 표현을 강하게 선호\n",
    "    frequency_penalty=-0.3,  # 반복적 표현 허용, 일관성 증대\n",
    "    max_tokens=200,  # 적당한 길이\n",
    "    top_p=0.3  # 매우 제한적인 토큰 선택 - 안전하고 예측 가능한 단어만\n",
    ")\n",
    "\n",
    "# 창의적인 설정 (독창적이고 예측 불가능한 답변)\n",
    "llm_creative = ChatOpenAI(\n",
    "    #model=\"gpt-3.5-turbo-0125\",\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\", \n",
    "    temperature=1.5,  # 매우 높은 온도 - 창의적이고 예측 불가능한 출력\n",
    "    presence_penalty=1.5,  # 새로운 주제와 개념을 강하게 유도\n",
    "    frequency_penalty=1.2,  # 반복을 강하게 억제하여 매우 다양한 표현 생성\n",
    "    max_tokens=350,  # 더 긴 창의적 서술 허용\n",
    "    top_p=0.95  # 거의 모든 토큰 후보에서 선택 - 최대 창의성\n",
    ")\n",
    "\n",
    "# 질문 설정: 파라미터 차이가 극명하게 드러나는 추상적/철학적 질문\n",
    "question = \"\"\"\n",
    "\"시간\"이라는 개념을 다른 방식으로 정의한다면 어떻게 표현할 수 있을까요?\n",
    "일상적인 시계나 달력의 관점이 아닌, 완전히 새로운 시각에서 시간을 바라보고 설명해주세요.\n",
    "기존의 고정관념을 벗어나서 자유롭게 사고해주세요.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\" CONSERVATIVE 설정 (온도:0.1, presence:-0.5, frequency:-0.3, top_p:0.3)\")\n",
    "print(\"  → 전통적이고 학술적인 철학적 접근\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 보수적 모델 호출\n",
    "response_conservative = llm_conservative.invoke(question)\n",
    "print(response_conservative.content)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" CREATIVE 설정 (온도:1.5, presence:1.5, frequency:1.2, top_p:0.95)\")\n",
    "print(\"  → 추상적이고 독창적인 철학적 사고\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 창의적 모델 호출\n",
    "response_creative = llm_creative.invoke(question)\n",
    "print(response_creative.content)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" 파라미터 차이점 요약:\")\n",
    "print(\"   • Temperature: 0.1 vs 1.5 (15배 차이)\")\n",
    "print(\"   • Presence Penalty: -0.5 vs 1.5 (기존 패턴 선호 vs 새로운 개념 강요)\")\n",
    "print(\"   • Frequency Penalty: -0.3 vs 1.2 (반복 허용 vs 강한 다양성)\")\n",
    "print(\"   • Top-p: 0.3 vs 0.95 (제한적 vs 거의 무제한 토큰 선택)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Parameter\n",
    "* Temperature (온도): 이 파라미터는 모델의 예측 불확실성을 조절합니다. \n",
    "    * 낮은 온도는 모델이 가장 확률이 높은 다음 단어를 선택하게 하여 안정적인 결과를 내고, 높은 온도는 확률이 낮은 단어까지 선택지에 포함시켜 더 창의적이고 예측 불가능한 답변을 생성합니다. \n",
    "* Presence Penalty & Frequency Penalty: 두 파라미터 모두 토큰(단어)의 반복성을 제어합니다.\n",
    "    * Presence Penalty는 이전에 나온 단어나 주제에 '페널티'를 주어 새로운 단어를 사용하게 합니다. 값이 높을수록 새로운 내용을 더 자주 시도합니다.\n",
    "    * Frequency Penalty는 단어가 등장한 빈도에 비례하여 '페널티'를 줍니다. 값이 높을수록 특정 단어를 반복적으로 사용하는 것을 강하게 억제하여 더 다양한 어휘를 사용하게 합니다. \n",
    "* Top_p: 이 파라미터는 다음 토큰을 선택할 때 고려할 단어의 범위를 조절합니다. Top_p가 0.3이면 확률이 높은 상위 30%의 단어 중에서만 선택하고, 0.95면 확률이 낮은 단어들까지 포함하여 거의 모든 단어를 고려합니다. Top_p가 높을수록 모델의 선택지가 넓어져 더 자유로운 응답이 가능합니다.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " 보수적 설정 (논리적, 일관적)\n",
      " → 일상적이고 일반적인 비유를 사용하여 안정적인 답변\n",
      "============================================================\n",
      "도시의 소음은, 사실 한 마리 거대한 야수다.  \n",
      "아침이 되면 그 짐승은 깊은 잠에서 잠깐 눈을 뜬다.  \n",
      "먼저 눈꺼풀을 두드리는 것은 지하철의 지르는 울음—철장을 흔드는 굉음은 눈알을 부라져 오게 하는 눈물이다.  \n",
      "그 눈물은 금세 빗줄기처럼 도로를 타고 흐르며, 차량들은 빗방울 하나하마 저마다의 색깔을 뒤집어쓴 채 질주한다.  \n",
      "이때 야수는 코를 킁킁거린다\n",
      "\n",
      "============================================================\n",
      " 창의적 설정 (풍부한 비유와 은유)\n",
      " → 예상치 못한 독창적인 비유와 감각적인 표현 사용\n",
      "============================================================\n",
      "도시의 소음은 도시를 살아가는 수많은 생명의 호흡이자 타박타박하는 맥박이라고 할 수 있습니다. 각 소음은 생명의 작은 세포와도 같아서 하나씩 모으면 다양한 생태계를 형성합니다. 예를 들어 버스나 택시의 엔진 소리는 심장에서 뛰는 혈관의 물살과 닮았음. \n",
      "\n",
      "트럭이나 공사장 소리는 힘든 노동을 하고 있는 사람의 강한 심장 박동수에 비유가 가능합니다. 이 소음들은 도시의 리듬과 조화를 이루며 살아가고 있습니다.\n",
      "\n",
      "차의 엔진과 공용 전기 제품에서 나타나는 각종 음향은 공원에서 뛰는 어린이에 비유할  수 있습니다. 버스나 택시의 운행과 횡단보도의 안내 음향 등 여러 생활 소리는 어린 동식물이 무성하게 우거진 숲같기도 합니다.\n",
      "\n",
      "또 공사장의 크고 작은 건설 장비, 기계로부터 생산되는 잡음은 불규칙하여 예측할  수 없는 거친 야수의 숨소리처럼 울리어 공기를 진동시킵니다.\n",
      "\n",
      "대도시의 많은 사람들이 만들어 냅니다.\n",
      "\n",
      "이 도시 소음들을 일종의 생명체로 본다면, 이들은 도시 속 수많은 작은 생명의 모습이기 때문에 서로 뒤엉키고 어우러지며 생명과 무생물이 뒤섞여 유기적으로 운향하고, 상호작용하여 살아가는 하나의 생태계를 이룰겁니다. 이리하여 타박타박 박동의 박음은 도시가 생겨나는 과정인겁니다. 살아 있는 존재를 통해 감정과 맥박을 만들어냅니다.\n",
      "\n",
      "\"우와아앙, 앙앙앙~\"\n",
      "\n",
      "\"딩고임!\"\n",
      "\n",
      "자동차, 트\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 보수적인 설정: 논리적이고 일관된 서술\n",
    "llm_conservative = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY, \n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\", \n",
    "    temperature=0.1,         # 낮은 값(0.1): '확률의 폭'을 좁혀 가장 안전하고 흔한 단어를 선택합니다.\n",
    "                             # → 결과가 예측 가능하고 반복적일 수 있습니다. 마치 정해진 교과서처럼.\n",
    "    presence_penalty=-0.5,   # 음수 값(-0.5): 이미 등장했던 주제나 단어를 다시 사용하는 것을 권장합니다.\n",
    "                             # → 기존 패턴을 벗어나지 않고 일관성을 유지합니다.\n",
    "    frequency_penalty=-0.3,  # 음수 값(-0.3): 자주 등장한 단어에 대한 '벌칙'을 줄여, 동일한 표현의 반복을 허용합니다.\n",
    "                             # → 응답의 일관성이 높아지고, 핵심 주제에서 벗어나지 않습니다.\n",
    "    max_tokens=200,          # 응답의 최대 길이를 제한합니다. \n",
    "    top_p=0.3                # 낮은 값(0.3): 확률이 높은 상위 30% 토큰(단어)만 고려합니다.\n",
    "                             # → 모델의 '선택지'를 극도로 제한하여 예측 가능한 단어만 사용합니다.\n",
    ")\n",
    "\n",
    "# 창의적인 설정: 독창적이고 풍부한 비유와 은유\n",
    "llm_creative = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=1.5,         # 높은 값(1.5): '확률의 폭'을 넓혀 흔치 않은 단어까지 선택하게 합니다.\n",
    "                             # → 예측 불가능하고 독창적인 문장을 생성합니다. 마치 즉흥적인 시인처럼요.\n",
    "    presence_penalty=1.5,    # 양수 값(1.5): 이미 사용된 주제나 개념에 '벌칙'을 주어 새로운 것을 시도하게 합니다.\n",
    "                             # → 독창적인 아이디어나 관점을 강하게 유도합니다.\n",
    "    frequency_penalty=1.2,   # 양수 값(1.2): 자주 등장한 단어에 '벌칙'을 주어 반복을 강력하게 억제합니다.\n",
    "                             # → 표현의 다양성을 극대화하고 문장이 풍부해집니다.\n",
    "    max_tokens=350,          # 더 긴 창의적 서술을 허용하기 위해 최대 길이를 늘립니다.\n",
    "    top_p=0.95               # 높은 값(0.95): 확률이 낮은 95%의 모든 토큰을 고려합니다.\n",
    "                             # → 모델의 '선택지'를 거의 무제한으로 확장하여 최대의 창의성을 발휘합니다.\n",
    ")\n",
    "\n",
    "# 질문을 ChatPromptTemplate으로 정의하여 역할과 질문을 명확히 함\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 창의적인 작가입니다. 주어진 주제에 대해 풍부한 비유와 은유를 사용하여 서술해주세요.\"),\n",
    "    (\"human\", \"\"\"\n",
    "    \"도시의 소음\"을 생명체나 자연 현상에 빗대어 설명해주세요.\n",
    "    일상적인 소리가 아닌, 그 소리가 가진 생명력과 감정을 중심으로 묘사해주세요.\n",
    "    \"\"\"),\n",
    "])\n",
    "\n",
    "# 파서 설정\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 체인 구성: Prompt -> Model -> Parser\n",
    "chain_conservative = prompt | llm_conservative | parser\n",
    "chain_creative = prompt | llm_creative | parser\n",
    "\n",
    "# 모델 호출 및 결과 출력\n",
    "print(\"=\" * 60)\n",
    "print(\" 보수적 설정 (논리적, 일관적)\")\n",
    "print(\" → 일상적이고 일반적인 비유를 사용하여 안정적인 답변\")\n",
    "print(\"=\" * 60)\n",
    "response_conservative = chain_conservative.invoke({})\n",
    "print(response_conservative)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" 창의적 설정 (풍부한 비유와 은유)\")\n",
    "print(\" → 예상치 못한 독창적인 비유와 감각적인 표현 사용\")\n",
    "print(\"=\" * 60)\n",
    "response_creative = chain_creative.invoke({})\n",
    "print(response_creative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      " 보수적 설정 (객관적, 사실 기반)\n",
      " → 과학적이고 논리적인 장미의 특성 설명\n",
      "============================================================\n",
      "1. 객관적 관점  \n",
      "빨간 장미는 장미과(Rosaceae)에 속하는 낙엽 관목이다. 꽃잎은 5~60매로 겹겹이 포개져 있으며, 표면은 벨벳처럼 미세한 털로 덮여 빛을 살짝 삼킨 채 진홍색 파장(660 nm 부근)을 고스란히 반사한다. 줄기는 시가 5 mm가량의 둔각형 가시로 무장해 있어, ‘아름다움 곁엔 방어 기제가 함께 존재한다’는 생태적 사실을 입증한다. 꽃잎 한 장의 두께는 약 200 μm, 수분이 증발하면 세\n",
      "\n",
      "============================================================\n",
      " 창의적 설정 (문학적, 상상 기반)\n",
      " → 은유와 비유를 활용한 장미의 감성적 묘사\n",
      "============================================================\n",
      "### **장미: 객관적 관점과 문학적 관점**\n",
      "\n",
      "## **1. 객관적 관점: 물리적 특성 및 상징적 의미**\n",
      "\n",
      "장미는 장미과에 속하는 식물의 하나로, 주로 봄과 여름에 피는 꽃입니다. '빨간 장미'는 꽃송이가 진한 붉은색인 장미를 의미합니다.\n",
      "\n",
      " 장미의 물리적 특징으로는 가시 있는 줄기와 풍부한 생명력을 지녔기에, **사랑과 영원한 결혼, 감사의 상징**으로 여겨지기도 합니다.\n",
      "\n",
      " 특히 '빨간 장미'는 **사랑, 열정, 강렬한 감정,** 등을 상징합니다.\n",
      "\n",
      "-   **객관적 관점에서의 물리적 특성: ** 장미는 다양한 색상의 꽃을 가지고 있으며, 빨간 장미는 그 중에서도 특유의 진한 붉은색으로 유명합니다. 흔히 **욕망과 정열, 열애의 상징**으로 이용 되기도 합니다.\n",
      "\n",
      "-   장미의 가시는 또한 **보호, 방자함 혹은 경호원의 존재처럼 의미**를 가져 사람들을 때로 두려움에 떨릴 수도 있습니다.\n",
      "\n",
      "\n",
      "\n",
      "## **2. 문학적 관점: 상징적 의미 및 감정 표현**\n",
      "\n",
      "빨간 장미는 다양한 비유와 은유를 사용하여 설명할 수 있습니다.\n",
      "\n",
      " 빨간 장미를 **고운 연인의 피부 혹은 사랑에 빠진 두 마음으로 묘사**될 뿐만 아니라, 다음과 같은 상징으로도 여겨립니다:\n",
      "\n",
      "*   **사랑의 상징**: 장미는 종종 **사랑, 열망, 감정***을 표현하는데 사용됩니다.  아름답고 화려한 외형\n"
     ]
    }
   ],
   "source": [
    "# 질문을 담은 템플릿\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 주어진 주제에 대해 풍부한 비유와 은유를 사용하여 서술하는 전문가입니다. 답변의 관점을 명확히 구분하여 설명해주세요.\"),\n",
    "    (\"human\", \"\"\"\n",
    "    \"빨간 장미\"를 두 가지 관점에서 묘사해주세요.\n",
    "    1. **객관적 관점:** 장미의 물리적 특성과 상징적 의미를 중심으로 설명해주세요.\n",
    "    2. **문학적 관점:** 장미를 사람이나 감정에 빗대어 자유롭고 시적으로 묘사해주세요.\n",
    "    \"\"\"),\n",
    "])\n",
    "\n",
    "# 파서 설정\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 체인 구성: Prompt -> Model -> Parser\n",
    "chain_conservative = prompt | llm_conservative | parser\n",
    "chain_creative = prompt | llm_creative | parser\n",
    "\n",
    "# 모델 호출 및 결과 출력\n",
    "print(\"=\" * 60)\n",
    "print(\" 보수적 설정 (객관적, 사실 기반)\")\n",
    "print(\" → 과학적이고 논리적인 장미의 특성 설명\")\n",
    "print(\"=\" * 60)\n",
    "response_conservative = chain_conservative.invoke({})\n",
    "print(response_conservative)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\" 창의적 설정 (문학적, 상상 기반)\")\n",
    "print(\" → 은유와 비유를 활용한 장미의 감성적 묘사\")\n",
    "print(\"=\" * 60)\n",
    "response_creative = chain_creative.invoke({})\n",
    "print(response_creative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model의 종류에 따라 결과 값이 다름\n",
    "* gpt-4o vs gpt-3.5-turbo-0125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------\n",
      "\n",
      " After (창의적인 응답, 새로운 아이디어 포함)\n",
      "한국에는 다양한 문화유산과 자연경관이 있습니다. 여러 여행지 중에서도 서울에 위치한 경복궁, 경주에 있는 불국사, 안동에 있는 하회마을, 계양산, 한국민속촌 등을 추천해 드립니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 변경된 설정 (더 창의적인 답변, 새로운 아이디어 유도)\n",
    "#llm_after = ChatOpenAI(model=\"gpt-4o\", temperature=1.0, presence_penalty=1.5)\n",
    "#llm_after = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=1.0, presence_penalty=1.5)\n",
    "llm_after = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=1.0,\n",
    "    presence_penalty=1.5\n",
    ")\n",
    "\n",
    "# 질문 설정\n",
    "question = \"한국에서 가볼 만한 여행지를 추천해 주세요.\"\n",
    "\n",
    "# 모델 호출\n",
    "response_after = llm_after.invoke(question)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n-------------------------\\n\")\n",
    "print(\" After (창의적인 응답, 새로운 아이디어 포함)\")\n",
    "print(response_after.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-1) 모델에 직접 파라미터를 전달 (모델 생성 시점)\n",
    "##### Before / After 파라미터 차이\n",
    "* temperature: Before(0.7) → 다양성 높은 추천 / After(0.3) → 정확한 일정 제공\n",
    "* max_tokens: Before(300) → 간략한 응답 / After(800) → 세부 일정 포함\n",
    "* frequency_penalty: Before(0.5) → 단어 반복 억제 / After(0.2) → 좀 더 자연스러운 응답\n",
    "* presence_penalty: Before(0.5) → 다양한 장소 추천 / After(0.3) → 새로운 정보 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Before] 모델 결과\n",
      "가족 단위(어린 아동∼부모님 세대)가 3박 4일 동안 “서울베이스”로 이동 동선이 겹치지 않도록 여유 있게 즐길 수 있는 일정을 지역별·테마별로 구성했습니다. 대중교통(지하철·버스·택시) 기준, 휠체어·유모차도 90 % 구간 이용 가능합니다. 숙소는 ‘도심 한복판(종로·명동·홍대·강남)’에 두고, 하루는 ‘1시간대 근교(남양주·가평)’로 나갔다 오는 방식입니다.\n",
      "\n",
      "-------------------------------------------------\n",
      "여행 키워드\n",
      "• 한국 정통 문화 체험(궁·한옥·전통시장)\n",
      "• 키즈·노인 모두 즐기는 테마파크·휴양\n",
      "• 한강·호수·계곡 등 쉬엄쉬엄 자연 풍경\n",
      "• 대중교통 최소 환승, 짐 털기 최소화\n",
      "-------------------------------------------------\n",
      "3박 4일 전체 루트(동선 흐름)\n",
      "D1 서울 중심(역사·문화) → D2 근교(남양주 물의정원·구름산책) → D3 서울 테마파크(롯데월드·잠실) → D4 한강·올림픽공원·공항行\n",
      "-------------------------------------------------\n",
      "D1  서울, 한옥·궁·시장으로 만나는 ‘느림의 미학’\n",
      "*숙소 위치: 종로구(광화문·안국역) 권장 – 공항철도 환승 1번, D2~D4 동선 방향성 좋음\n",
      "\n",
      "09:00  김포공항(또는 인천공항) → 공항철도 → 숙소(30~50분)  \n",
      "        → 짐 풀고 가벼운 복장 준비\n",
      "\n",
      "10:30  경복궁(창덕궁도 OK)  \n",
      "        ‑ 매시 정시 수문장 교대식(10:00/14:00)  \n",
      "        ‑ 자동화된 한국어·영어·중국어 음성도어 있음  \n",
      "        ‑ 키즈: 한복 대여 4천원~, 궁길 따라 ‘작은 숨은그림찾기’\n",
      "\n",
      "12:00  점심 – 통인시장 계란빵·빈대떡·육전(시장 상품권 5천원권 구매)\n",
      "\n",
      "13:30  북촌한옥마을 느린 산책  \n",
      "        ‑ 8경 포토스팟 지도(관광안내소 무료)  \n",
      "        ‑ 김서방집(공방), 한지체험(1만원) – 40분  \n",
      "        ‑ 찻집(차와 다식) 휴식\n",
      "\n",
      "15:30  삼청동 길 – 카페·갤러\n",
      "\n",
      "================================================================================\n",
      "\n",
      " [After] 모델 결과\n",
      "가족 단위(어린아이∼부모님 세대까지)가 3박 4일 동안 “대중교통으로도 편리하고, 이동 거리는 짧되, 볼거리·먹거리·쉴거리”를 모두 갖춘 곳을 원하신다면, 개인적으로 “전주×군산×익산” 삼각 벨트를 가장 먼저 권합니다. 서울/수도권에서 KTX로 1시간 30분~2시간이면 도착하고, 지역 간 거리가 30~40 km로 짧아 택시/버스/렌터카 모두 부담이 없습니다. 아래는 실제 가족 단위로 테스트한 “느긋한 3박 4일” 기준표입니다.\n",
      "\n",
      "-------------------------------------------------\n",
      "여행 기본 정보\n",
      "-------------------------------------------------\n",
      "지역 : 전북 전주·군산·익산  \n",
      "기간 : 3박 4일(서울 기준 오전 7~9시 출발→4일차 저녕 7~9시 귀경)  \n",
      "동반 구성 : 성인 2~4명 + 어린이 1~2명(유모차 가능)  \n",
      "이동 수단 : KTX(왕복) + 현지 버스/택시/단기 렌터카(1일 4만 원대)  \n",
      "숙소 : 전주 한옥마을 내 가족형 한옥스테이(4인 기준 1박 12~18만 원) 3박 고정  \n",
      "가방 : 캐리어 1개 + 배납 1개(한옥 계단 많음)  \n",
      "예산 : 4인 기준 왕복 KTX 20만 원 + 숙소 50만 원 + 식비·체험·기념품 40만 원 = 총 110만 원 안팎\n",
      "\n",
      "-------------------------------------------------\n",
      "일정표(동선 중심)\n",
      "-------------------------------------------------\n",
      "DAY 1  서울 → 전주, 한옥마을 속으로  \n",
      "07:30  서울역 KTX 555호(예매 시 A석 2+2)  \n",
      "09:10  전주역 도착 → 택시 15분(1만 2천 원) → 한옥스테이 짐 풀기  \n",
      "10:30  전주 한옥마을 느린 걷기(유모차 OK)  \n",
      "        - 경기전(이조왕의 사당) → 전동성당(한국 최초 고딕) → 맞춤한복 대여(1만 원/4시간)  \n",
      "12:00  점심 : 외갓집식당(대표 메뉴 한옥마을 대표 비빔밥)  \n",
      "13:30  한옥마을 체험 : 한지공예 체험관(부채·램프 만들기 1만 원)  \n",
      "15:00  커피&디저트 : 명가꽃빵(단팥빵) + 커피한잔  \n",
      "16:30  숙소 휴식(어린이 낮잠)  \n",
      "18:00  저녁 : 농부의집(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "#  모델 파라미터 (Before: 기본적인 추천 / After: 맞춤형 세부 정보 추가)\n",
    "before_params = {\n",
    "    \"temperature\": 0.7,         # 랜덤성을 적절히 유지 (다양한 답변 유도)\n",
    "    \"max_tokens\": 800,          # 응답 길이를 적절히 조절\n",
    "    \"frequency_penalty\": 0.5,   # 반복 단어 억제\n",
    "    \"presence_penalty\": 0.5,    # 새로운 단어 포함 장려\n",
    "}\n",
    "\n",
    "after_params = {\n",
    "    \"temperature\": 0.3,         # 창의성을 낮추고 정확한 답변 유도\n",
    "    \"max_tokens\": 800,          # 더 긴 답변을 생성 (세부 정보 포함)\n",
    "    \"top_p\": 0.85,              # 확률 기반 샘플링 (일관성과 다양성 균형)\n",
    "    \"frequency_penalty\": 0.2,   # 반복 단어 감소 (자연스러운 답변)\n",
    "    \"presence_penalty\": 0.3,    # 새로운 정보 포함 장려\n",
    "}\n",
    "\n",
    "#  두 개의 모델 생성 (Before / After)\n",
    "#before_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", **before_params)\n",
    "before_model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    **before_params\n",
    ")\n",
    "#after_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", **after_params)\n",
    "after_model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    **after_params\n",
    ")\n",
    "\n",
    "#  프롬프트 구성 (올바른 ChatMessagePromptTemplate 사용)\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"당신은 여행 전문가입니다. 사용자의 요청에 맞는 최적의 여행지를 추천해 주세요.\"\n",
    ")\n",
    "\n",
    "user_message = HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message, user_message])\n",
    "\n",
    "#  체인 생성 (Before / After)\n",
    "before_chain = chat_prompt | before_model\n",
    "after_chain = chat_prompt | after_model\n",
    "\n",
    "#  질문 설정 (Before / After의 차이점을 비교할 수 있도록 변경)\n",
    "test_question = \"가족과 함께 3박 4일 동안 한국에서 여유롭게 여행할 수 있는 일정을 동선을 고려하여 자세하게 추천해 주세요.\"\n",
    "\n",
    "#  Before 모델 실행\n",
    "before_response = before_chain.invoke({\"user_input\": test_question})\n",
    "\n",
    "#  After 모델 실행\n",
    "after_response = after_chain.invoke({\"user_input\": test_question})\n",
    "\n",
    "#  결과 출력\n",
    "print(\" [Before] 모델 결과\")\n",
    "print(before_response.content)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")  # 가독성을 위한 구분선\n",
    "print(\" [After] 모델 결과\")\n",
    "print(after_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2) 모델에 추가적인 파라미터를 전달\n",
    "- bind() 메서드를 사용\n",
    "- max_tokens=50 (기본) / max_tokens=150 (상세한 설명) \n",
    "- stop=[\".\"] → 첫 번째 마침표에서 응답을 중단\n",
    "- temperature=0.8 → 보다 창의적인 답변을 생성함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [Before] 기본 max_tokens=150 (기본 답변)\n",
      "Python 프로그래밍을 배우고자 하는 초보자를 위한 학습 단계는 다음과 같습니다.\n",
      "\n",
      "### **1. Python의 기본 개념 이해하기**\n",
      "\n",
      "*   **변수, 데이터 타입, 연산자, 제어문, 함수** 등을 학습하세요. Python의 공식 문서나 온라인 강의에서 기본 문법을 배울 수 있습니다. \n",
      "*   **기본 문법**을 이해하고 숙지하는 것은 매우 중요합니다.\n",
      "\n",
      "### **2. 프로그래밍 환경 설정하기**\n",
      "\n",
      "*   Python 공식 웹사이트에서 **Python을 다운로드**하고 설치하세요. 또한, **코드 편집기**나 **통합 개발 환경(IDE)**를 설치해서 프로그래밍 환경을 설정하세요. \n",
      "*   **IDE** 선택: PyCharm, Visual Studio Code 등 인기 있는\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      " [After] max_tokens=150, stop=['.'] (첫 번째 마침표에서 응답 중단)\n",
      "Python 프로그래밍을 처음 접하는 사람들을 위한 학습 단계는 다음과 같습니다\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      " [After] max_tokens=150, temperature=0.8 (창의적인 답변)\n",
      "1.  **기초 문법 학습**: *   **자료 구조**: 리스트, 튜플, 딕셔너리, 세트 등 기본적인 자료 구조를 익혀 변수에 할당하고 조작하는 방법을 배우세요. *   **제어 흐름**: 조건문(if/else), 반복문(for/while), 함수 정의 등 프로그램의 흐름을 제어하는 문법을 학습하세요. *   **함수**: 함수의 정의와 호출 방법을 익혀 코드 재사용성을 높여보세요.\n",
      "\n",
      "2.  **실습을 통한 연습**: *   **온라인 플랫폼**: LeetCode, HackerRank, CodeWars와 같은 웹사이트를 통해 다양한 문제들을 풀어보세요. *   **프로젝트**: 간단한\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "#  프롬프트 설정 (천문학 질문에 대한 답변을 생성하는 시스템)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"이 시스템은 천문학 질문에 대해 명확하고 자세한 답변을 제공할 수 있습니다.\"),\n",
    "    (\"user\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "#  기본 모델 설정 (기본적인 답변 생성)\n",
    "#base_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", max_tokens=150)  # 150 토큰 제한\n",
    "base_model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "#  질문 설정\n",
    "# 1. MAX_TOKENS 차이를 보여주는 질문 (길이 제한 효과)\n",
    "max_tokens_question = \"인공지능의 발전이 미래 사회에 미칠 영향을 긍정적 측면과 부정적 측면으로 나누어 자세히 설명해 주세요.\"\n",
    "\n",
    "# 2. STOP 파라미터 차이를 보여주는 질문 (중단점 효과)\n",
    "stop_question = \"Python 프로그래밍을 배우는 초보자에게 추천하는 학습 단계를 순서대로 설명해 주세요. 각 단계별로 구체적인 방법과 팁을 포함해서 답변해 주세요.\"\n",
    "\n",
    "# 3. TEMPERATURE 차이를 보여주는 질문 (창의성 vs 정확성)\n",
    "temperature_question = \"시간 여행이 가능하다면 과거의 어느 시대로 가고 싶은지와 그 이유를 창의적으로 설명해 주세요.\"\n",
    "\n",
    "# 4. 복합적 비교를 위한 질문 (모든 파라미터 효과)\n",
    "complex_question = \"화성에 인류가 정착하기 위해 필요한 기술과 준비사항들을 단계별로 설명하고, 각 단계에서 예상되는 도전과제와 해결방안을 제시해 주세요.\"\n",
    "\n",
    "question = stop_question\n",
    "\n",
    "#  Before (기본 max_tokens=150)\n",
    "messages = prompt.format_messages(user_input=question)\n",
    "before_answer = base_model.invoke(messages)\n",
    "\n",
    "#  Before 출력\n",
    "print(\"\\n [Before] 기본 max_tokens=150 (기본 답변)\")\n",
    "print(before_answer.content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100 + \"\\n\")  # 가독성을 위한 구분선\n",
    "\n",
    "#  After (파라미터 조정 후 비교)\n",
    "stop_chain = prompt | base_model.bind(max_tokens=150, stop=[\".\"])  # 첫 번째 마침표에서 중단\n",
    "temp_chain = prompt | base_model.bind(max_tokens=150, temperature=0.8)  # 창의적인 답변 유도\n",
    "\n",
    "stop_answer = stop_chain.invoke({\"user_input\": question})\n",
    "temp_answer = temp_chain.invoke({\"user_input\": question})\n",
    "\n",
    "#  After 출력 (stop vs temperature 비교)\n",
    "print(\" [After] max_tokens=150, stop=['.'] (첫 번째 마침표에서 응답 중단)\")\n",
    "print(stop_answer.content)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100 + \"\\n\")  # 가독성을 위한 구분선\n",
    "\n",
    "print(\" [After] max_tokens=150, temperature=0.8 (창의적인 답변)\")\n",
    "print(temp_answer.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
