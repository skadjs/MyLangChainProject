{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate \n",
    "* [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html#langchain_core.prompts.prompt.PromptTemplate)\n",
    "* [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "* [ChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatMessagePromptTemplate.html#langchain_core.prompts.chat.ChatMessagePromptTemplate)\n",
    "* [FewShotPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html#langchain_core.prompts.few_shot.FewShotPromptTemplate)\n",
    "* PartialPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_3\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) PromptTemplate 의 from_template() 함수 사용\n",
    "* 주로 LLM(텍스트 완성형 모델, ex. Ollama, GPT-3.5)과 함께 사용\n",
    "* 하나의 문자열 프롬프트를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatGPT는 인터넷에서 수집한 방대한 텍스트를 바탕으로 단어들이 나올 확률을 학습합니다.  \\n'\n",
      " '학습 과정에서 사람의 도움을 받아 더 나은 답을 선택하도록 보상을 주는 강화학습 방식을 사용합니다.  \\n'\n",
      " '결과적으로 입력된 질문에 가장 적절한 단어들을 순차적으로 예측해 문장을 만들어 답변합니다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    #model=\"openai/gpt-oss-120b\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) PromptTemplate 결합하기\n",
    "* 동일한 Prompt 패턴을 사용하지만 여러 개의 질문을 작성해서 LLM을 실행할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['count', 'language', 'model_name'] input_types={} partial_variables={} template='{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.'\n",
      "('ChatGPT는 인터넷의 방대한 텍스트를 바탕으로 다음 토큰을 예측하도록 사전학습(pre-training)한 뒤, 인간의 대화 데이터로 '\n",
      " '미세조정(fine-tuning)해 질문에 자연스럽고 유용하게 답하도록 만듭니다.  \\n'\n",
      " '이 과정에서 트랜스포머 아키텍처의 어텐션 메커니즘이 문맥을 기억·활용하게 되며, 강화학습 기반의 RLHF가 사람의 선호도를 반영해 '\n",
      " '안전성과 정확성을 높입니다.  \\n'\n",
      " '결국 통계적 패턴 매칭으로 사고나 의식 없이 단어 확률을 계산해 문장을 생성하는 것이 핵심 원리입니다.\\n'\n",
      " '\\n'\n",
      " 'ChatGPT 모델의 장점 요약\\n'\n",
      " '- 문맥 이해·유지가 뛰어나 긴 대화·복잡한 지시도 자연스럽게 처리  \\n'\n",
      " '- 다국어·다분야(코딩, 번역, 요약, 창작 등)에 즉시 활용 가능한 범용성  \\n'\n",
      " '- 별도 학습 없이 프롬프트만으로 빠르게 맞춤형 답변 생성  \\n'\n",
      " '- 인간 피드백 강화학습(RLHF)로 유해·편향 출력을 줄여 안전성↑  \\n'\n",
      " '- API·플러그인·자동화 툴과 쉽게 연결돼 생산성 도구·서비스 통합이 간편\\n'\n",
      " '\\n'\n",
      " 'ChatGPT와 비슷한 AI 모델(한국어 명칭)\\n'\n",
      " '- 구글 젬마이(Gemini)\\n'\n",
      " '- 안트로픽 클라우드(Claude)\\n'\n",
      " '- 메타 라마(Llama)\\n'\n",
      " '- 마이크로소프트 코파일럿(Copilot)')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"한국어\")\n",
    "print(combined_prompt)\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"한국어\"})\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PromptTemplate 의 파라미터를 배열 형태로 하여 여러개 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.', 'Gemini 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.', 'Claude 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.']\n",
      "<class 'str'> GPT-4 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.\n",
      "('GPT-4는 방대한 텍스트 데이터에서 다음 토큰을 예측하도록 훈련된 트랜스포머 기반 언어 모델입니다.  \\n'\n",
      " '학습 과정에서는 인간의 피드백을 반영한 강화학습(RLHF)을 추가로 적용해 유용하고 안전한 응답을 만들어냅니다.  \\n'\n",
      " '결국 통계적 패턴을 학습해 주어진 문맥에 가장 적합한 단어를 순차적으로 생성하는 방식으로 작동합니다.')\n",
      "<class 'str'> Gemini 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Gemini는 대규모 텍스트·코드·이미지·음성·영상을 동시에 학습하는 멀티모달 Transformer로, 시퀀스 전체를 한 번에 처리하는 '\n",
      " '‘Attention’ 메커니즘으로 패턴을 익힙니다.  \\n'\n",
      " '학습 단계에서는 다음 토큰을 맞추는 사전 학습(pre-training)과 인간 피드백 강화학습(RLHF)으로 정렬을 거쳐, 지식과 '\n",
      " '안전성을 동시에 높입니다.  \\n'\n",
      " 'Mixture-of-Experts(MoE) 구조로 필요한 파라미터만 활성화해 효율을 높였고, TPU 클러스터에서 대규모 배치·정밀도 '\n",
      " '최적화를 반복해 글로벌한 언어·도메인 데이터를 압축합니다.  \\n'\n",
      " '결과적으로 Gemini는 텍스트 생성뿐 아니라 이미지·영상 이해·생성까지 가능한 통합 모델로, 새로운 입력에 대해 내부 표현을 유연하게 '\n",
      " '조합해 답을 만들어냅니다.')\n",
      "<class 'str'> Claude 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Claude는 방대한 텍스트 데이터를 미리 학습해 언어의 패턴을 학습한 대규모 언어 모델이다.  \\n'\n",
      " '사용자 입력을 토큰 단위로 잘게 쪼개 이전 토큰들을 기반으로 다음 토큰의 확률을 예측하면서 답변을 생성한다.  \\n'\n",
      " '이때 가중치凍結된 사전 학습 모델 위에 강화학습·인간 피드백(RLHF)으로 보정을 거쳐 유용하고 안전한 응답을 만들어낸다.  \\n'\n",
      " '결국 통계적 패턴 매칭에 불과하지만, 대화 맥락을 유지하며 사람이 선호하는 스타일로 자연스러운 문장을 순차적으로 확장해 나간다.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 3},\n",
    "    {\"model_name\": \"Gemini\", \"count\": 4},\n",
    "    {\"model_name\": \"Claude\", \"count\": 4}\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions] #파이썬에서 파라미터로 딕셔너리 받을 때 아스타(*) 2개 씀\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    print(type(prompt), prompt)\n",
    "    response = llm.invoke(prompt)\n",
    "    pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) ChatPromptTemplate\n",
    "* Tuple 형태의 system, user, assistant 메시지 지원\n",
    "* 여러 개의 메시지를 조합하여 LLM에게 전달 가능\n",
    "* 간결성과 가독성이 높고 단순한 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='This system is an expert in answering questions about AI. Please provide clear and detailed explanations.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ChatGPT 모델의 학습 원리를 설명해 주세요.', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "ChatGPT는 ‘Generative Pre-trained Transformer’의 약자로, 세 단계에 걸쳐 ‘말을 만들어 내는 능력’을 익힌다. 핵심 흐름을 짚어 보면 다음과 같다.\n",
      "\n",
      "1. Pre-training(사전 학습) – “인터넷 글을 그대로 암기하지 않고, 패턴을 잡아 머릿속에 압축해 넣는 단계”\n",
      "   • 목표  \n",
      "     – 다음 단어를 맞추는 “확률 퍼즐”을 엄청 많이 풀면서, ‘언어의 통계적 구조’를 학습한다.  \n",
      "   • 입력  \n",
      "     – 웹, 책, 위키 등 대량의 텍스트를 토큰(token, 단어나 부분 단어) 단위로 자른 뒤, 이 토큰 시퀀스를 Transformer 블록에 넣는다.  \n",
      "   • 모델 구조  \n",
      "     – 12~96개 층(layer)의 Transformer 디코더 스택.  \n",
      "     – 셀프 어텐션(self-attention)이 문장 안의 모든 토큰 사이 ‘의존 관계’를 한꺼번에 계산.  \n",
      "     – Feed-forward 네트워크가 각 토큰의 ‘다음에 나올 법한 토큰 점수’를 출력.  \n",
      "   • 손실 함수  \n",
      "     – Cross-entropy: “정답 토큰에 주어진 확률을 1에 가깝게, 나머지는 0에 가깝게.”  \n",
      "   • 결과  \n",
      "     – ‘커다란 언어 모델’ 완성. 질문-답, 번역, 요약 등 어떤 텍스트도 ‘자연스럽게 이어 쓰는’ 기초 능력 보유.  \n",
      "   • 특징  \n",
      "     – 지도 레이블 없이(Self-supervised) 학습 → 방대한 데이터 활용 가능.  \n",
      "     – 단, 인터넷에 있는 ‘모든 편향·허위·폭력 표현’도 그대로 흡수할 위험.\n",
      "\n",
      "2. Supervised Fine-Tuning(SFT, 지도 미세 조정) – “대화 예시로 ‘인간이 원하는 스타일’을 가르치는 단계”\n",
      "   • 데이터  \n",
      "     – 사람이 직접 쓴 프롬프트-응답 쌍 1~10만 개.  \n",
      "   • 목표  \n",
      "     – “도움 되고, 안전하고, 간결하게” 말하도록 확률 분포를 다시 조정.  \n",
      "   • 방법  \n",
      "     – 앞서 학습한 ‘기본 언어 모델’의 가중치를 미세 조정.  \n",
      "     – 여전히 ‘다음 토큰 예측’ 방식이지만, 이제 ‘정답’은 인간이 선별한 ‘좋은 대화’다.  \n",
      "   • 효과  \n",
      "     – 갑자기 “As an AI, I don’t have feelings…”처럼 ‘공손하고 안전한’ 말투를 갖춤.  \n",
      "     – 하지만 여전히 ‘틀린 답·유해한 답’이 나올 수 있음.\n",
      "\n",
      "3. Reinforcement Learning from Human Feedback(RLHF) – “좋은 답·나쁜 답을 점수 매기며, ‘인간 선호도’를 확률에 주입하는 단계”\n",
      "   3-1. 보상 모델(Reward Model) 만들기  \n",
      "       – 동일 프롬프트에 대해 모델이 만든 2~9개의 답을 사람이 “A가 B보다 낫다”고 비교.  \n",
      "       – 이 비교 쌍을 수십만 건 모아, Transformer에 ‘입력=프롬프트+답변, 출력=스칼라 점수’로 학습 → ‘보상 모델’ 완성.  \n",
      "   3-2. 강화 학습로 파라미터 업데이트  \n",
      "       – 기본 모델을 정책(Policy)으로 보고, PPO(Proximal Policy Optimization) 알고리즘 사용.  \n",
      "       – 매 스텝:  \n",
      "         1) 정책이 답변 생성 →  \n",
      "         2) 보상 모델이 점수 매김 →  \n",
      "         3) 점수를 최대화하도록 파라미터 미세 조정.  \n",
      "       – KL 페널티: “원본 모델과 너무 멀어지지 마라” 제약 → 말이 이상해지거나 사실을 망각하는 걸 방지.  \n",
      "   • 결과  \n",
      "     – 허위·유해 응답 확률 낮아지고, 도움 지표(Helpfulness), 무해 지표(Harmlessness), 정직 지표(Honesty) 동시 상승.  \n",
      "     – 단, 보상 모델이 ‘사람이 선호하는’ 것과 ‘객관적 사실’이 항상 일치하지는 않으므로, 여전히 환경(프롬프트)에 따라 오답·착각 발생.\n",
      "\n",
      "4. 추론(Inference) – 실제 서비스에서의 작동 원리\n",
      "   • 입력 프롬프트를 토큰화 → 학습된 확률 분포 P(token|context)를 반복抽样(샘플링).  \n",
      "   • 샘플링 전략: temperature(top_p, top_k) 조절로 ‘창의성 vs 확실성’ 트레이드오프.  \n",
      "   • 출력은 문장이 완성될 때까지(또는 최대 길이) 자동 회귀적 생성.  \n",
      "   • 내부적으론 ‘확률’일 뿐이지만, 외부적으례 ‘한 번에 한 글자씩 생각 없이 써 내려가는 듯’ 보임.\n",
      "\n",
      "5. 요약 정리\n",
      "   1) Self-supervised Pre-training → ‘언어의 통계’ 잡음.  \n",
      "   2) Supervised Fine-tuning → ‘인간이 선호하는 스타일’ 기초 학습.  \n",
      "   3) RLHF → ‘인간의 가치/선호도’를 확률 모델에 주입.  \n",
      "   4) 추론 시 자동 회귀 생성 → 문장 생성.  \n",
      "\n",
      "이렇게 ‘확률적 패턴 압축 → 스타일 조정 → 인간 피드백 반영’의 3단계를 거쳐, ChatGPT는 ‘자연스러운 대화를 하면서도 상당한 지식을 반영’하는 모습을 보인다.\n"
     ]
    }
   ],
   "source": [
    "# 2-튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    # role, message\n",
    "    (\"system\", \"This system is an expert in answering questions about {topic}. Please provide clear and detailed explanations.\"),\n",
    "    (\"human\", \"{model_name} 모델의 학습 원리를 설명해 주세요.\"),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", model_name=\"ChatGPT\")\n",
    "print(messages)\n",
    "\n",
    "# 생성한 메시지를 바로 주입하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "ChatGPT의 학습은 “두 단계”로 압축할 수 있습니다.  \n",
      "1) ‘언어 모델’로서의 능력을 먼저 길러 놓고,  \n",
      "2) 사람의 의도를 따르는 방향으로 ‘미세 조정’합니다.  \n",
      "각 단계에서 쓰이는 데이터, 목적함수, 최적화 기법이 다르며, 모든 학습은 **결국 “다음 토큰을 얼마나 잘 맞히느냐”** 를 기준으로 이뤄집니다.\n",
      "\n",
      "----------------------------------------\n",
      "1단계. 사전학습(Pre-training)  \n",
      "- 목표: 인터넷에 있는 방대한 텍스트를 읽고, 통계적 패턴을 내면화해 일반적인 ‘언어 표현’을 얻는다.  \n",
      "- 데이터: 웹페이지, 위키, 책, 논문 등 수십~수백 GB(1~2조 토큰).  \n",
      "- 모델: Transformer 디코더(예: 175B 파라미터 GPT-3).  \n",
      "- 최적화:  \n",
      "  – 입력 토큰 시퀀스 x1 … xT 가 주어졌을 때,  \n",
      "    L(θ) = –Σ log Pθ(xt | x<t) 를 Gradient Descent로 최소화.  \n",
      "  – 분산·병렬 학습(DDP, ZeRO, FSDP) + 혼합 정밀도(FP16/BF16)로 수천 개 GPU에서 수 주~수개월.  \n",
      "- 결과: ‘세상의 글’은 거의 다 읽었지만, 사람 질문에 대해 “정직하게” 답하거나, “안전·정책”을 고려하지 않음.  \n",
      "  → 따라서 2단계가 필요.\n",
      "\n",
      "----------------------------------------\n",
      "2단계. 보상 기반 미세 조정(RLHF)  \n",
      "OpenAI는 2022년 논문 “InstructGPT”에서 소개한 3-단계 절차를 그대로 확장해 ChatGPT에 적용했다.\n",
      "\n",
      "Step 1. 지도 미세 조정(SFT, Supervised Fine-Tuning)  \n",
      "- 데이터: 프롬프트(질문, 지시)–응답 쌍 1~10만 개를 인간 라벨러가 작성.  \n",
      "- 목적: 최대우도(negative log-likelihood) 최소화.  \n",
      "- 결과: 프롬프트 형식은 맞추지만, 품질·안전·허위 여부는 사람이 매긴 ‘보상 값’을 반영하지 않음.\n",
      "\n",
      "Step 2. 보상 모델 학습(RM, Reward Model)  \n",
      "- 동일한 프롬프트에 대해 모델이 생성한 4~9개의 답변을 사람이 “좋음/나쁨”으로 비교·순위 매김.  \n",
      "- Bradley–Terry 모델: RM은 scalar reward rθ(x, y)를 출력하도록 학습.  \n",
      "  L_RM = –Σ log σ(rθ(x, y_w) – rθ(x, y_l)).  \n",
      "- RM 파라미터는 SFT 모델의 최종 Transformer representation 위에 ‘추가 헤드’ 몇 개만 붙여 가볍게 학습.\n",
      "\n",
      "Step 3. 강화학습 최적화(PPO)  \n",
      "- 정책 πφ(y|x): SFT 모델 파라미터를 초기값으로.  \n",
      "- 목적함수:  \n",
      "  J(φ) = E[ rθ(x, y) – β·log(πφ/π_SFT) ]  \n",
      "  – rθ는 RM이 주는 보상,  \n",
      "  – KL 패널티(β)로 인간 데이터 분포에서 너무 벗어나지 않도록 제약.  \n",
      "- 알고리즘: Proximal Policy Optimization(PPO) – importance sampling 클리핑으로 안정적 업데이트.  \n",
      "- 반복: πφ로 샘플 → RM 보상 → PPO 업데이트 → (선택적) 새 비교 데이터 수집 → RM 재학습 → 다시 PPO.  \n",
      "  보통 수십 회 에포크.\n",
      "\n",
      "----------------------------------------\n",
      "추가 기법  \n",
      "- Rejection Sampling + RM 재순위: 생성된 여러 후보 중 보상이 가장 높은 것 선택(추론 시점).  \n",
      "- Constitutional AI, RLAIF: 사람 대신 AI가 원칙(Constitution)에 따라 선호도를 매겨 스케일 확대.  \n",
      "- Safety & Alignment 필터: RM 학습 데이터에 ‘거절해야 할 프롬프트’에 대한 낮은 보상을 명시.  \n",
      "- System message & 시야 제한: 대화 맥락을 “여기까지 기억” 범위로 제한해 노이즈 감소.\n",
      "\n",
      "----------------------------------------\n",
      "정리  \n",
      "1. 사전학습 → “글 잘 쓰는 모델”  \n",
      "2. SFT → “지시 형식 맞추기”  \n",
      "3. RM → “사람의 선호를 수치화”  \n",
      "4. PPO → “선호도를 최대화하며, 원본과 너무 멀어지지 않도록”\n",
      "\n",
      "이렇게 학습된 ChatGPT는 사용자 입력(프롬프트)을 토큰 단위로 잘게 쪼개,  \n",
      "“지금까지 나온 토큰들”을 Transformer에 넣어 다음 토큰의 확률 분포를 계산하고,  \n",
      "temperature, top-p 샘플링 등의 전략으로 실제 토큰을 선택해 응답을 만들어 냅니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인을 생성하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"topic\":\"AI\", \"model_name\":\"ChatGPT\"})\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) ChatPromptTemplate\n",
    "* SystemMessagePromptTemplate와 HumanMessagePromptTemplate 클래스 사용\n",
    "* 객체 지향적 접근 - Message 객체를 독립적으로 생성 가능\n",
    "* 여러 조건에 따라 다른 시스템 메시지 선택\n",
    "\n",
    "```python\n",
    "if user_is_beginner:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"초보자를 위한 설명: {topic}\")\n",
    "else:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"전문가를 위한 상세 분석: {topic}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (The prompt is not asking you to write an essay yourself; it is asking for a clear, detailed explanation.)\n",
      "\n",
      "Deep learning is a sub-field of machine learning that uses artificial neural networks with many layers (hence “deep”) to learn patterns directly from large amounts of data. Whereas traditional machine-learning models often rely on carefully hand-engineered features, deep-learning models learn the features themselves by adjusting millions (sometimes billions) of numeric parameters called weights. Once trained, these models can map new inputs (images, audio waveforms, text, sensor data, etc.) to desired outputs (class labels, translated sentences, steering angles, etc.) with high accuracy.\n",
      "\n",
      "Key ideas behind deep learning:\n",
      "\n",
      "1. Representation learning  \n",
      "   Each layer in a deep network learns a representation of the data that makes the next layer’s job easier. Early layers usually capture low-level features (e.g., edges in images, phonemes in speech), while deeper layers compose these into higher-level concepts (faces, words, objects). Because the model discovers these representations automatically, domain experts no longer need to craft feature extractors by hand.\n",
      "\n",
      "2. End-to-end optimization  \n",
      "   A deep network is trained by minimizing a loss function that measures the difference between the network’s predictions and the ground-truth labels. Through back-propagation, the gradient of this loss is propagated backward through every layer, and all weights are updated simultaneously. This end-to-end learning lets the model exploit subtle statistical structure that might be missed if the pipeline were broken into separate, hand-tuned stages.\n",
      "\n",
      "3. Scalability with data and compute  \n",
      "   Deep learning’s performance generally improves as data and model size grow. Larger datasets reduce overfitting, and larger models (more layers and parameters) can capture more intricate patterns. Modern breakthroughs (vision, speech, language) became possible once GPUs/TPUs supplied enough compute power to train very large networks on very large data sets.\n",
      "\n",
      "4. Architectural innovations  \n",
      "   - Convolutional Neural Networks (CNNs) exploit spatial locality in images, video, and even protein structures.  \n",
      "   - Recurrent Neural Networks (RNNs) and Transformers handle sequential data such as text or time-series.  \n",
      "   - Generative models (VAEs, GANs, diffusion models) learn to synthesize realistic data.  \n",
      "   - Reinforcement-learning agents use deep networks to learn policies for games, robotics, and recommendation systems.\n",
      "\n",
      "5. Transfer learning and foundation models  \n",
      "   Pre-training on huge corpora (images, text, multi-modal data) produces “foundation” models whose learned features can be fine-tuned quickly on smaller downstream tasks. This dramatically reduces the amount of task-specific data and training time required.\n",
      "\n",
      "Typical training pipeline:\n",
      "\n",
      "1. Collect and clean a large labeled data set (or use self-supervised signals).  \n",
      "2. Choose an architecture (ResNet, Transformer, U-Net, etc.).  \n",
      "3. Initialize weights (often randomly or via pre-training).  \n",
      "4. Forward-propagate mini-batches of data, compute loss.  \n",
      "5. Back-propagate gradients and update weights with stochastic gradient descent (or variants like Adam).  \n",
      "6. Regularize (dropout, weight decay, data augmentation) to avoid overfitting.  \n",
      "7. Validate, tune hyper-parameters, monitor for convergence, and finally test on held-out data.\n",
      "\n",
      "Limitations to keep in mind:\n",
      "\n",
      "- Data hunger: Many deep models need thousands to millions of examples.  \n",
      "- Compute cost: Training large models can require weeks on expensive hardware.  \n",
      "- Interpretability: Deep networks are black boxes; understanding why they make a specific prediction is an active research area.  \n",
      "- Robustness: Small, imperceptible input changes (adversarial examples) can fool networks.  \n",
      "- Bias and fairness: Models can absorb and amplify biases present in training data.\n",
      "\n",
      "Despite these challenges, deep learning has become the state-of-the-art approach in computer vision, speech recognition, natural-language understanding, drug discovery, game playing, and many scientific computing tasks, and it continues to drive the current wave of AI advances.\n"
     ]
    }
   ],
   "source": [
    "# ChatMessagePromptTemplate 활용\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI expert in {topic}. Please provide clear and detailed explanations.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"What is deep learning?\")\n",
    "\n",
    "# LLM 호출\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatMessagePromptTemplate는 여러 종류의 메시지(시스템, 인간, AI)를 조합하여 복잡한 프롬프트를 생성할 때 유용합니다.\n",
    "* SystemMessagePromptTemplate: 이 템플릿은 AI 모델에게 역할을 부여하거나 전반적인 규칙을 설정하는 시스템 메시지를 만듭니다. 위의 예시에서는 \"번역을 도와주는 유용한 도우미\"라는 역할을 지정합니다.\n",
    "* HumanMessagePromptTemplate: 이 템플릿은 사용자의 질문이나 요청을 담는 인간 메시지를 만듭니다. 아래의 예시에서는 번역할 텍스트를 입력받습니다.\n",
    "* ChatPromptTemplate.from_messages: 이 클래스 메서드는 시스템 메시지, 인간 메시지 등 여러 종류의 MessagePromptTemplate 객체들을 리스트로 받아 하나의 채팅 프롬프트 템플릿으로 통합합니다.\n",
    "* format_messages: 이 메서드는 정의된 템플릿에 실제 값을 채워 넣어 [SystemMessage, HumanMessage] 형태의 리스트를 반환합니다. 이 리스트는 채팅 모델(Chat Model) 에 바로 전달될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant that translates English to Korean.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I love programming.', additional_kwargs={}, response_metadata={})]\n",
      "나는 프로그래밍을 사랑해요.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 1. SystemMessagePromptTemplate와 HumanMessagePromptTemplate 생성\n",
    "# SystemMessagePromptTemplate는 모델의 페르소나 또는 기본 지침을 설정합니다.\n",
    "system_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# HumanMessagePromptTemplate는 사용자로부터 받는 입력 프롬프트를 정의합니다.\n",
    "human_template = \"{text_to_translate}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 2. ChatPromptTemplate 생성\n",
    "# 위에서 만든 두 템플릿을 리스트로 묶어 ChatPromptTemplate을 만듭니다.\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# 3. 프롬프트 포맷팅\n",
    "# chat_prompt_template.format_messages()를 사용하여 최종 메시지 리스트를 생성합니다.\n",
    "# 이 함수는 딕셔너리 형태의 입력 변수를 받습니다.\n",
    "formatted_prompt = chat_prompt_template.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Korean\",\n",
    "    text_to_translate=\"I love programming.\"\n",
    ")\n",
    "\n",
    "# 4. 결과 출력\n",
    "print(formatted_prompt)\n",
    "\n",
    "# LLM 호출\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) FewShotPromptTemplate\n",
    "* FewShotPromptTemplate은 모델이 특정 형식을 따르게 하거나, 일관된 응답을 생성하도록 유도할 때 유용합니다.\n",
    "* 도메인 지식이 필요하거나, AI가 오답을 줄이고 더 신뢰할 만한 답변을 생성하도록 해야 할 때 효과적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1) PromptTemplate을 사용하지 않는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "태양계 행성(해왕성 안쪽)을 **내행성·외행성**으로 나누어 한 줄씩 정리하면 다음과 같습니다.\n",
      "\n",
      "1. **수성** – 태양에 가장 가까운 암석형 행성  \n",
      "2. **금성** – 두꺼운 대권·온실효과로 표면이 가장 뜨거운 행성  \n",
      "3. **지구** – 유일하게 생명이 확인된 행성  \n",
      "4. **화성** – ‘붉은 행성’, 얼음·흔적 강물이 있는 암석형 행성  \n",
      "5. **목성** – 태양계 최대 기체행성, 90개 이상 위성(대표 간선 이오·목위일)  \n",
      "6. **토성** – 환상적인 고리, 밀도가 물보다 낮음  \n",
      "7. **천왕성** – 거꾸로 누운 자전축, 고리·위성 27개  \n",
      "8. **해왕성** – 태양계 최대 폭풍, 달 트리톤은 역행궤도\n"
     ]
    }
   ],
   "source": [
    "# PromptTemplate을 사용하지 않는 경우\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"태양계의 행성들을 간략히 정리해 주세요.\")\n",
    "\n",
    "print(type(result))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-2) FewShotChatMessagePromptTemplate 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': '뉴턴의 운동 법칙을 요약해 주세요.', 'output': '### 뉴턴의 운동 법칙\\n1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\\n2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\\n3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.'}, {'input': '지구의 대기 구성 요소를 알려주세요.', 'output': '### 지구 대기의 구성\\n- **질소 (78%)**: 대기의 대부분을 차지합니다.\\n- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\\n- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\\n- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x1227cd610>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1227d7e10>, root_client=<openai.OpenAI object at 0x1227cf650>, root_async_client=<openai.AsyncOpenAI object at 0x1227cf8d0>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "# 초등학생도 이해하는 ‘양자컴퓨터’ 이야기\n",
      "\n",
      "## 1. 일반 컴퓨터 vs 양자 컴퓨터\n",
      "- 보통 컴퓨터는 ‘0 아니면 1’만 기억해요.  \n",
      "- 양자 컴퓨터는 ‘0과 1이 동시에’ 될 수 있는 특별한 동전(=큐비트)을 사용해요.  \n",
      "  → 한 번에 여러 길을 동시에 볼 수 있어서, 어려운 문제를 훨씬 빨리 풀 수 있어요.\n",
      "\n",
      "## 2. 신기한 능력 3가지\n",
      "1. **중첩**: 동전이 앞·뒤 동시에 떠 있듯, 0과 1이 한꺼번에 존재  \n",
      "2. **얽힘**: 두 동전이 멀리 떨어져 있어도 한쪽을 뒤집으면 다른 쪽도 즉시 반응(마법 같은 연결)  \n",
      "3. **간섭**: 잘못된 답은 서로 없애고, 맞는 답은 키워서 마지막에 하나만 남김\n",
      "\n",
      "## 3. 어디에 쓸까?\n",
      "- 날씨 예측, 신약 개발, 교통 최적화, 암호 해독 등 아주 복잡한 계산을 순식간에!\n",
      "\n",
      "## 4. 아직은 유치원 수준\n",
      "지금 양자 컴퓨터는 ‘기능이 덜 자란 아기’예요. 더 키워야 우리가 실생활에서 매일 쓸 수 있어요.\n",
      "\n",
      "## 요약 한 줄\n",
      "양자 컴퓨터는 ‘마법 동전’을 써서 여러 길을 한 번에 보고, 엄청 복잡한 문제를 슝-하고 푸는 미래형 컴퓨터예요!\n"
     ]
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate 사용하는 경우\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "chain = final_prompt | llm\n",
    "print(chain)\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"양자컴퓨팅에 대하여 설명해 주세요.\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1) PartialPrompt \n",
    "* 프롬프트를 더 동적으로 활용할 수 있으며, AI 응답을 더 일관성 있게 조정 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 가을에 일어나는 대표적인 지구과학 현상은 태풍 발생이 맞나요? 가을에 주로 발생하는 지구과학 현상을 3개 알려주세요\n",
      " 모델 응답: 가을에 일어나는 **대표적인 지구과학 현상**은 **태풍 발생**이 맞긴 하지만, **태풍은 여름~가을에 걸쳐 발생**하며 **가을에도 빈번**하게 발생합니다. 따라서 **가을에 주로 발생하거나 뚜렷하게 나타나는 지구과학 현상**을 다음과 같이 정리할 수 있습니다:\n",
      "\n",
      "---\n",
      "\n",
      "### ✅ 가을에 주로 발생하거나 뚜렷하게 나타나는 지구과학 현상 3가지\n",
      "\n",
      "1. **태풍의 고위도 이동 (가을 태풍)**  \n",
      "   - 여름보다 **고위도(한반도, 일본 등)**로 이동할 확률이 높아짐.  \n",
      "   - 예: **태풍 링링(2019)**, **태풍 힌남노(2022)** 등.\n",
      "\n",
      "2. **기압골의 활성화 (활성 기압골)**  \n",
      "   - **차가운 북서계절풍**과 **따뜻한 남서풍**이 충돌하면서 **기압골이 발달**  \n",
      "   - 이로 인해 **비가 오고 기온이 급감**하는 **가을철 냉전선** 형성\n",
      "\n",
      "3. **단풍과 관련된 기온 변화 (일교차 확대)**  \n",
      "   - **낮과 밤의 기온 차이가 크게 벌어지며**, 이는 **식물의 색소 변화(클로로필→안토시아닌)**를 유도  \n",
      "   - **지구과학적 관점**에서는 **기온 변화가 생태계에 미치는 영향**으로 볼 수 있음\n",
      "\n",
      "---\n",
      "\n",
      "### 🔍 요약\n",
      "| 현상 | 가을 특징 |\n",
      "|------|------------|\n",
      "| **태풍** | 고위도로 이동, 한반도 직접 영향 가능 |\n",
      "| **기압골** | 냉전선 형성, 비와 급격한 기온 하강 |\n",
      "| **일교차 확대** | 단풍 유발, 생태계 변화의 지표 |\n",
      "\n",
      "---\n",
      "\n",
      "필요하시면 이 중 하나를 더 깊게 설명드릴게요.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# 프롬프트 템플릿 정의 (부분 변수 적용)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{season}에 일어나는 대표적인 지구과학 현상은 {phenomenon}이 맞나요? {season}에 주로 발생하는 지구과학 현상을 3개 알려주세요\",\n",
    "    input_variables=[\"phenomenon\"],  # 사용자 입력 필요\n",
    "    partial_variables={\"season\": get_current_season()}  # 동적으로 계절 값 할당\n",
    ")\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "# 특정 계절의 현상 질의\n",
    "query = prompt.format(phenomenon=\"태풍 발생\")\n",
    "result = llm.invoke(query)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\" 프롬프트: {query}\")\n",
    "print(f\" 모델 응답: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 계절: 가을\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# Step 1: 현재 계절 결정\n",
    "season_name = get_current_season()  # 계절 값 얻기\n",
    "print(f\"현재 계절: {season_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 가을에 발생하는 자연 현상:\n",
      "1.  **성운**: 성운은 가스와 먼지가 많은 천체를 뜻합니다. 가스 성분은 우주에서 가장 가벼운 원소인 수소, 그리고 헬륨입니다. 성운은 별의 생성과 소멸의 과정에 중요한 역할을 합니다. 대표적인 성운으로는 오리온 성운, 카리나 성운, 에타 카리나별 등이 있습니다. \n",
      "2.  **은하수**: 밤하늘에서 은하수를 보면 길게 뺨처럼 생긴 띠가 있는 것을 볼 수 있습니다. 이 은하수는 태양계가 속한 은하인 우리 은하의 중심에 있는 별들을 밤하늘에서 바라본 모습입니다. 지구가 속해있는 우리 은하는 나선형 은하로, 밤하늘에서 보이는 은하수는 우리 은하의 중심부 별들은 우리가 중심을 향해 바라본 모습이기 때문에 길게 띠처럼 보이는 것입니다. \n",
      "3.  **페르세우스자리 유성우**: 페르세우스자리 유성우는 가을에 주로 관측할 수 있는 유성우입니다. 유성우는 어떤 천체가 지구 대기에 진입하여 불타면서 떨어지는 현상으로 흔히 말하는 별똥별을 의미합니다. 가을밤의 하늘이 맑으면 페르세우스자리 유성우를 한 밤에 최대 50개까지도 관측할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: 해당 계절의 자연 현상 추천\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{season}에 주로 발생하는 대표적인 지구과학 현상 3가지를 알려주세요. \"\n",
    "    \"각 현상에 대해 간단한 설명을 포함해주세요.\"\n",
    ")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "##llm = ChatOpenAI(\n",
    "##    #api_key=OPENAI_API_KEY,\n",
    "##    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "##    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "##    temperature=0.0\n",
    "##)\n",
    "\n",
    "# 체인 2: 자연 현상 추천 (입력: 계절 → 출력: 자연 현상 목록)\n",
    "chain2 = (\n",
    "    {\"season\": lambda x : season_name}  # chain1의 출력을 season 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: 현재 계절에 따른 자연 현상 추천\n",
    "response = chain2.invoke({})\n",
    "print(f\"\\n {season_name}에 발생하는 자연 현상:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2) PartialPrompt \n",
    "* API 호출 데이터, 시간 정보, 사용자 정보 등을 반영할 때 매우 유용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 현재 1달러 = 1377.98원 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\n",
      " 모델 응답: ## 2024년 5월 8일 환율 분석\n",
      "\n",
      "2024년 5월 8일, 1달러는 1377.98원으로 환산됩니다. 이는 2024년 5월 8일 한국은행이 고시한 환율에 따른 정보이며, 실제 거래 시 소매환율(환전 시 적용되는 환율)이 적용됩니다.\n",
      "\n",
      "* 전일 환율: 1달러 = 1376.7원 \n",
      "* 상승/하락: 상승 (전일 대비 1.28원 상승) \n",
      "* 거래량: (해당 정보는 실시간으로 제공되지 않으므로, 별도로 확인 필요) \n",
      "\n",
      "## 환율에 영향을 주는 요인들\n",
      "\n",
      "1. **경제 지표**: 미국의 비농업 부문 고용 지표, GDP 성장률, 인플레이션율 등 경제 지표는 환율에 큰 영향을 미칩니다. \n",
      "2. **글로벌 경제 상황**: 세계 경제의 불확실성, 무역 전쟁, 국제 유가 변동 등도 환율에 영향을 줍니다. \n",
      "3. **통화 정책**: 미국 연방준비제도(Fed)의 금리 결정과 한국은행의 통화 정책도 환율 변동에 영향을 미치는 중요한 요인입니다. \n",
      "4. **정치적 요인**: 정치적 불확실성이나 지정학적 리스크도 환율에 영향을 줄 수 있습니다.\n",
      "\n",
      "## 최근 환율 동향\n",
      "\n",
      "2024년 5월 8일 기준, 원화 가치는 미국 달러 대비 소폭 상승한 것으로 나타납니다. (전일 대비 1.28원 상승한 1377.98원) \n",
      "\n",
      "이는 최근 글로벌 경제의 불확실성이 다소 완화되고, 한국 경제에 대한 긍정적인 전망이 반영된 결과일 수 있습니다.\n",
      "\n",
      "하지만, 환율은 다양한 요인에 의해 변동성이 크므로, 지속적인 모니터링이 필요합니다. 특히, 미국의 통화 정책과 글로벌 경제 상황의 변화는 원화 가치에 큰 영향을 미칠 것입니다.\n",
      "\n",
      "## 전망\n",
      "\n",
      "향후 환율 전망은 여러 가지 요인에 따라 달라질 수 있습니다. \n",
      "* 미국의 금리 인하 가능성\n",
      "* 한국의 경제 성장률\n",
      "* 글로벌 무역 상황\n",
      "\n",
      "등을 고려해야 합니다.\n",
      "\n",
      "## 요약\n",
      "\n",
      "2024년 5월 8일, 1달러는 1377.98원으로 환산되며, 전일 대비 소폭 상승한 수치입니다. 환율은 경제 지표, 글로벌 경제 상황, 통화 정책 등 다양한 요인에 의해 영향을 받습니다. 향후 환율 전망은 지속적인 모니터링이 필요하며, 전문가의 분석과 경제 지표 발표에 주목할 필요가 있습니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 실시간 환율을 가져오는 함수\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1달러 = {data['rates']['KRW']}원\"\n",
    "\n",
    "# Partial Prompt 활용\n",
    "prompt = PromptTemplate(\n",
    "    template=\"현재 {info} 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\",\n",
    "    input_variables=[],  # 사용자 입력 없음\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # API에서 가져온 데이터 자동 반영\n",
    ")\n",
    "\n",
    "# LLM 모델 설정\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "# 모델에 프롬프트 전달 및 응답 받기\n",
    "response = llm.invoke(prompt.format())\n",
    "\n",
    "# 결과 출력\n",
    "print(\" 프롬프트:\", prompt.format())\n",
    "print(\" 모델 응답:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
