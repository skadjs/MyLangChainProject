{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate \n",
    "* [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html#langchain_core.prompts.prompt.PromptTemplate)\n",
    "* [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "* [ChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatMessagePromptTemplate.html#langchain_core.prompts.chat.ChatMessagePromptTemplate)\n",
    "* [FewShotPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html#langchain_core.prompts.few_shot.FewShotPromptTemplate)\n",
    "* PartialPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_T\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) PromptTemplate 의 from_template() 함수 사용\n",
    "* 주로 LLM(텍스트 완성형 모델, ex. Ollama, GPT-3.5)과 함께 사용\n",
    "* 하나의 문자열 프롬프트를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eon/skRookies/myLangChain/mylangchain-app/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatGPT는 인터넷의 방대한 텍스트에서 단어와 문장의 등장 패턴을 학습합니다.  \\n'\n",
      " '학습 과정에서 입력된 문맥에 따라 다음에 올 단어를 예측하도록 훈련됩니다.  \\n'\n",
      " '이러한 확률 기반 예측 방식으로, 자연스럽고 유창한 대화를 생성할 수 있게 됩니다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    #model=\"openai/gpt-oss-120b\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) PromptTemplate 결합하기\n",
    "* 동일한 Prompt 패턴을 사용하지만 여러 개의 질문을 작성해서 LLM을 실행할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['count', 'language', 'model_name'] input_types={} partial_variables={} template='{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.'\n",
      "('1. ChatGPT는 인터넷 글을 대량으로 읽고 다음에 올 단어를 맞히는 ‘예측’ 훈련을 되풀이해 스스로 언어 규칙을 익힙니다.  \\n'\n",
      " '2. 사람이 질문-답을 평가해 좋은 대답에 점수를 주면, 이 점수로 모델을 다시 조정해 정답 방향을 학습합니다.  \\n'\n",
      " '3. 위 두 과정을 거듭해 모델은 맥락을 파악하고 자연스러운 대화를 만들어내게 됩니다.\\n'\n",
      " '\\n'\n",
      " 'ChatGPT의 장점 요약  \\n'\n",
      " '- 다양한 주제에 대해 논리적이고 일관된 글을 즉시 생성  \\n'\n",
      " '- 질의의 맥락을 기억하며 이어지는 대화 가능  \\n'\n",
      " '- 코드 작성·번역·요약 등 다재다능하며, 영어는 물론 한국어 등 여러 언어에 능숙  \\n'\n",
      " '- 추가 학습·미세 조정으로 특정 업무(고객 응대, 자료 요약 등)에 특화 가능  \\n'\n",
      " '- 대화 형태라 초보자도 별도 코딩 없이 바로 활용 가능  \\n'\n",
      " '\\n'\n",
      " 'ChatGPT와 비슷한 AI 모델  \\n'\n",
      " '구글 바드, 클로드, LLaMA, PaLM, 코그뷰, 블룸')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"한국어\")\n",
    "print(combined_prompt)\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"한국어\"})\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PromptTemplate 의 파라미터를 배열 형태로 하여 여러개 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.', 'Gemini 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.', 'Claude 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.']\n",
      "<class 'str'> GPT-4 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.\n",
      "('GPT-4는 방대한 텍스트 데이터에서 다음 단어를 예측하도록 Transformer 신경망을 학습합니다.  \\n'\n",
      " '학습 과정에서 단어의 위치와 문맥을 함께 고려해 자기회귀 방식으로 가중치를 조정합니다.  \\n'\n",
      " '이렇게 얻은 확률 분포를 바탕으로 인간이 이해할 수 있는 자연스러운 문장을 생성합니다.')\n",
      "<class 'str'> Gemini 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Gemini는 텍스트·이미지·오디오·코드 등 다양한 데이터를 동시에 처리하는 멀티모달 아키텍처로, Transformer 기반의 '\n",
      " '인코더-디코더 구조를 확장해 학습합니다.  \\n'\n",
      " '대규모 코퍼스에서 다음 토큰 예측과 동시에 교차 모달 정렬 작업을 수행해 서로 다른 데이터 간 의미를 정렬합니다.  \\n'\n",
      " '학습 과정에서 전문가 혼합(MoE) 기법으로 일부 네트워크만 활성화해 계산 효율을 높이고, 강화학습과 인간 피드백(RLHF)으로 응답 '\n",
      " '품질을 추가로 향상시킵니다.  \\n'\n",
      " '결과적으로 Gemini는 단일 모델로 텍스트 생성, 이미지 이해, 코드 작성 등 다양한 작업을 통합적으로 수행할 수 있습니다.')\n",
      "<class 'str'> Claude 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Claude는 방대한 텍스트 데이터를 학습해 언어의 확률 분포를 익히는 트랜스포머 기반 대규모 언어 모델입니다.  \\n'\n",
      " '학습 단계에서는 수십억 개의 파라미터를 조정해 다음 토큰이 무엇일지 예측하는 방식으로 최적화됩니다.  \\n'\n",
      " '인간 피드백 강화학습(RLHF) 단계에서는 사람이 선호하는 답변 순위를 바탕으로 보상 모델을 만들어, 모델 스스로 정답에 가까운 응답을 '\n",
      " '생성하도록 미세 조정됩니다.  \\n'\n",
      " '결과적으로 Claude는 단순히 다음 단어를 맞추는 것이 아니라, 사용자의 의도에 맞고 유용하며 안전한 문장을 생성하도록 학습됩니다.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 3},\n",
    "    {\"model_name\": \"Gemini\", \"count\": 4},\n",
    "    {\"model_name\": \"Claude\", \"count\": 4}\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions] #파이썬에서 파라미터로 딕셔너리 받을 때 아스타(*) 2개 씀\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    print(type(prompt), prompt)\n",
    "    response = llm.invoke(prompt)\n",
    "    pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) ChatPromptTemplate\n",
    "* Tuple 형태의 system, user, assistant 메시지 지원\n",
    "* 여러 개의 메시지를 조합하여 LLM에게 전달 가능\n",
    "* 간결성과 가독성이 높고 단순한 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='This system is an expert in answering questions about AI. Please provide clear and detailed explanations.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ChatGPT 모델의 학습 원리를 설명해 주세요.', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "ChatGPT는 “GPT(Generative Pre-trained Transformer)” 계열의 언어 모델로,  \n",
      "“거대한 텍스트를 보고 다음 단어를 예측하도록 학습한 뒤, 사람이 좋아할 행동을 최대화하도록 미세 조정했다”는 한 줄 요약을 풀어 쓴 것이 전체 학습 원리입니다. 아래에 단계별로, 수식·코드 없이 핵심 메커니즘을 설명합니다.\n",
      "\n",
      "-------------------------------------------------\n",
      "1. 두 단계 파이프라인\n",
      "1) Pre-training(사전 학습)  \n",
      "2) RLHF 미세 조정(후속 학습)  \n",
      "두 단계가 모두 끝나야 ‘채팅처럼 말을 잇는’ ChatGPT가 됩니다.\n",
      "\n",
      "-------------------------------------------------\n",
      "2. 사전 학습(Pre-training) 단계\n",
      "목표  \n",
      "“주어진 앞 문장을 보고, 다음에 나올 단어의 확률 분포를 맞춰라.”  \n",
      "즉, ‘자연어를 압축해서 내부 파라미터에 저장하라’는 뜻입니다.\n",
      "\n",
      "데이터  \n",
      "웹, 위키, 책 등 1조 토큰(단어·부분 단어) 이상.\n",
      "\n",
      "모델 구조  \n",
      "트랜스포머 디코더(Transformer decoder) 블록 96개, 1750억 개 가중치.  \n",
      "Self-attention이 문맥 안의 모든 토큰 간 관계를 한 번에 계산해 ‘글로벌 맥락’을 잡습니다.\n",
      "\n",
      "학습 방법  \n",
      "1) 랜덤 초기화 → 2) 다음 토큰 예측 → 3) 오차 역전파 → 4) 파라미터 갱신.  \n",
      "이 과정을 수청만 번 반복하면서, 모델은 사실·추론·문법·세계 지식을 통계적으로 획득합니다.\n",
      "\n",
      "결과  \n",
      "‘기본(Base) 모델’이 생김.  \n",
      "특징:  \n",
      "- 긴 글도 자연스럽게 잇지만, 지시사항(Instruction)을 따르는 능력은 떨어짐.  \n",
      "- 유해·편향·홀루시네이션(허위 생성) 가능성이 있음.\n",
      "\n",
      "-------------------------------------------------\n",
      "3. 지시 학습(Supervised Fine-Tuning, SFT) 단계\n",
      "데이터  \n",
      "‘질문-답’, ‘지시-응답’ 형태의 대화 쌍 1~2만 건(품질 높은 인간 작성).\n",
      "\n",
      "목표  \n",
      "“지시형 프롬프트를 받으면, 사람이 쓴 ‘좋은’ 응답을 그대로 생성하도록 하라.”  \n",
      "즉, 다음 토큰 예측 손실을 줄이되, 데이터 분포를 ‘지시→응답’에 맞춤.\n",
      "\n",
      "결과  \n",
      "지시를 따르는 ‘SFT 모델’이 생김.  \n",
      "그러나 여전히 ‘거부해야 할 부적절한 요청’을 거절하지 못하거나, 지나치게 길게 늘어지는 등의 문제가 남음.\n",
      "\n",
      "-------------------------------------------------\n",
      "4. RLHF 미세 조정(강화학습 기반 인간 피드백)\n",
      "핵심 아이디어  \n",
      "“사람이 선호하는 응답 순위를 보고 보상(reward)을 만들어, 이 보상을 최대화하는 정책을 강화학습으로 찾는다.”\n",
      "\n",
      "4-1. 보상 모델(Reward Model, RM) 만들기  \n",
      "- 같은 프롬프트에 대해 4~9개의 서로 다른 SFT 모델 응답을 사람이 1~5점 또는 상대 순위로 평가.  \n",
      "- (프롬프트, 응답1, 응답2) + ‘사람이 응답1이 더 낫다’는 레이블 → RM이 ‘응답이 얼마나 좋은가’를 회귀하도록 학습.  \n",
      "- RM은 6B 규모의 트랜스포머로, ‘응답 전체’를 받아 단일 스칼라 보상값을 출력.\n",
      "\n",
      "4-2. 정책 최적화(PPO)  \n",
      "- SFT 모델을 ‘정책(policy)’으로 본다.  \n",
      "- 이 정책이 생성한 응답에 대해 RM이 보상 r을 줌.  \n",
      "- PPO(Proximal Policy Optimization) 알고리즘이 ‘보상 r’을 높이면서도 ‘SFT 모델과 너무 멀리 가지 않도록(KL 페널티)’ 파라미터를 업데이트.  \n",
      "- 수천만 건의 프롬프트·응답 쌍으로 반복.\n",
      "\n",
      "보완 기법  \n",
      "- ‘보상 해킹’ 방지: RM 출력 clipping, KL 페널티, adversarial 프롬프트 재학습.  \n",
      "- Rejection Sampling: 생성한 후 보상 낮으면 폐기, 높은 것만 파인튜닝에 재사용.\n",
      "\n",
      "결과  \n",
      "‘RLHF 모델’이 생김.  \n",
      "특징:  \n",
      "- 유해·편향 응답 확률 ↓  \n",
      "- 지시 정합성 ↑  \n",
      "- 간결·친화적 톤 ↑  \n",
      "- 허위 정보는 여전히 생성 가능(홀루시네이션 문제는 남음).\n",
      "\n",
      "-------------------------------------------------\n",
      "5. 추론(인퍼런스) 단계\n",
      "1) 사용자 입력 토큰화  \n",
      "2) 트랜스포머 디코더 순회  \n",
      "3) Softmax 확률로 다음 토큰 샘플링(온도·top-p·top-k 조절)  \n",
      "4) 〈end〉 토큰 나올 때까지 반복  \n",
      "5) 토큰→문자열 복원 후 사용자에게 반환\n",
      "\n",
      "-------------------------------------------------\n",
      "6. 핵심 요약\n",
      "1. 다음 단어 예측(사전 학습) → 세계 지식과 언어 문법을 내재화.  \n",
      "2. 지시-응답 쌍 학습(SFT) → 지시 따르기 능력 부여.  \n",
      "3. 인간 피드백 기반 강화학습(RLHF) → 인간 기호에 맞는 안전·유용성 확보.  \n",
      "\n",
      "바로 이 3단 조합이 ‘그냥 글 잇기’에서 ‘사람이 편리하게 쓰는 챗봇’으로 변신하는 ChatGPT 학습 원리입니다.\n"
     ]
    }
   ],
   "source": [
    "# 2-튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    # role, message\n",
    "    (\"system\", \"This system is an expert in answering questions about {topic}. Please provide clear and detailed explanations.\"),\n",
    "    (\"human\", \"{model_name} 모델의 학습 원리를 설명해 주세요.\"),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", model_name=\"ChatGPT\")\n",
    "print(messages)\n",
    "\n",
    "# 생성한 메시지를 바로 주입하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "ChatGPT는 “GPT” 계열 모델의 대화 특화판이므로, GPT가 어떻게 학습하는지를 먼저 이해해야 합니다. GPT-3.5·GPT-4 같은 모델은 3단계 파이프라인으로 만들어집니다.\n",
      "\n",
      "1단계: Pre-training (사전학습)  \n",
      "2단계: Supervised Fine-tuning (SFT, 지도 미세조정)  \n",
      "3단계: Reinforcement Learning with Human Feedback (RLHF, 인간 피드백 기반 강화학습)\n",
      "\n",
      "아래에 각 단계에서 어떤 데이터·목적함수·알고리즘이 쓰이는지, 그리고 왜 “대화”가 가능해지는지를 수식과 함께 설명합니다.\n",
      "\n",
      "-------------------------------------------------\n",
      "1. Pre-training: “인터넷 글을 읽으며 다음 토큰 예측하기”\n",
      "-------------------------------------------------\n",
      "목표  \n",
      "최대한 많은 텍스트에서 통계적 패턴을 포착해 “주어진 앞 토큰 시퀀스 x₁…xₜ가 있을 때, 다음 토큰 xₜ₊₁의 확률”을 정확히 추정하는 것입니다.\n",
      "\n",
      "모델 구조  \n",
      "- Transformer 디코더(마스크드 셀프어텐션)  \n",
      "- 입력 임베딩 + 위치 임베딩  \n",
      "- L개의 트랜스포머 블록 → 최종 은닉 상태 h_L  \n",
      "- 언어 모델 헤드: Pθ(xₜ₊₁|x≤ₜ) = softmax(W·h_L)\n",
      "\n",
      "학습 목적함수  \n",
      "L(θ) = – Σ_{t=1}^{T} log Pθ(xₜ | x₁…xₜ₋₁)  \n",
      "즉, 전체 시퀀스에 대한 음의 로그 우도를 최소화합니다.\n",
      "\n",
      "데이터  \n",
      "웹페이지, 책, 위키피디아, GitHub 코드 등 수천억 토큰.  \n",
      "GPT-3.5는 300B 토큰, GPT-4는 아직 공개되지 않았지만 그 이상으로 추정됩니다.\n",
      "\n",
      "결과  \n",
      "이 시점에서 모델은 “글쓰기 스타일”은 잘 흉내 내지만, 질문-답 형식은 거의 없고, 안전성/유용성도 낮습니다.\n",
      "\n",
      "-------------------------------------------------\n",
      "2. Supervised Fine-tuning (SFT): “지시문-응답 쌍을 그대로 복제”\n",
      "-------------------------------------------------\n",
      "목표  \n",
      "대화 형식을 주입하고, 지시(Instruction)를 따르는 능력을 길러 주는 것입니다.\n",
      "\n",
      "데이터  \n",
      "수십만~수백만 개의 (지시문, 이상적 응답) 쌍.  \n",
      "예:  \n",
      "지시: “다음 문장을 한국어로 번역하라.”  \n",
      "응답: “Translate this sentence into Korean.”\n",
      "\n",
      "학습 방식  \n",
      "Pre-trained 가중치 θ₀를 초기값으로, 동일한 최대우도(MLM) 손실로 미세조정합니다.  \n",
      "L_SFT(θ) = – Σ log Pθ(y|x)  \n",
      "x=지시문, y=정답(응답)\n",
      "\n",
      "결과  \n",
      "지시를 따르는 모습이 나오지만, 여전히 “잘못된 정보”, “유해한 말”, “거절 못함” 같은 문제가 남습니다.\n",
      "\n",
      "-------------------------------------------------\n",
      "3. RLHF: “인간의 선호도를 보상으로 삼아 정책 최적화”\n",
      "-------------------------------------------------\n",
      "3-1. 보상 모델(RM) 만들기  \n",
      "- 동일한 지시문 x에 대해 모델이 생성한 4~9개의 응답 쌍(yᵢ, yⱼ)을 인간이 “어느 쪽이 더 나은가?”로 비교.  \n",
      "- 이 pairwise 데이터로 Bradley-Terry 모델을 학습해 scalar 보상 r_ϕ(x,y)를 만듭니다.  \n",
      "  L_RM = – log σ(r_ϕ(x,y_w) – r_ϕ(x,y_l))\n",
      "\n",
      "3-2. 강화학습 단계  \n",
      "- 정책 π_RL: SFT 모델의 가중치를 초기값으로.  \n",
      "- 목적함수(Proximal Policy Optimization, PPO):  \n",
      "  L_PPO = 𝔼[min(rₜ·Âₜ, clip(rₜ,1±ε)·Âₜ)] – β·KL(π_RL||π_SFT)  \n",
      "  rₜ = π_RL(y|x) / π_SFT(y|x) (importance weight)  \n",
      "  Âₜ: advantage = r_ϕ(x,y) – V(x) (critic 네트워크로 baseline 추정)  \n",
      "  KL 패널티는 “SFT 모델과 너무 멀어지지 말라”는 제약.\n",
      "\n",
      "결과  \n",
      "허위 정보 줄이기, 거절 능력 향상, 유해 응답 감소, 인간 선호도 ↑\n",
      "\n",
      "-------------------------------------------------\n",
      "4. 추론(인퍼런스) 단계\n",
      "-------------------------------------------------\n",
      "주어진 대화 기록을 토큰 시퀀스로 변환 →  \n",
      "Transformer가 한 토큰씩 확률 분산 출력 →  \n",
      "temperature·top-p 샘플링으로 다음 토큰 선택 →  \n",
      "반복하여 종료 토큰 나올 때까지 생성.\n",
      "\n",
      "-------------------------------------------------\n",
      "왜 “대화”가 되는가?\n",
      "-------------------------------------------------\n",
      "1. 학습 데이터에 “Human: … Assistant: …” 형식이 SFT/RLHF에 포함돼 있어서 프롬프트만 이렇게 주면 “대화”처럼 작동.  \n",
      "2. RLHF에서 인간은 ‘정보가 틀리지 않고, 간결하고, 예의 바르고, 거절할 줄 아는’ 응답에 높은 점수를 주므로, 그런 성향이 정책에 녹아듦.  \n",
      "3. 시스템 프롬프트(“You are a helpful assistant…”)를 앞에 붙여두면, 모델은 이 맥락을 계속 유지하면서 생성.\n",
      "\n",
      "-------------------------------------------------\n",
      "정리\n",
      "-------------------------------------------------\n",
      "ChatGPT =  \n",
      "(1) 대규모 코퍼스로 다음 토큰 예측을 학습한 트랜스포머  \n",
      "(2) 지시-응답 쌍으로 미세조정  \n",
      "(3) 인간의 선호 비교 데이터로 학습한 보상 모델을 이용한 PPO 강화학습  \n",
      "\n",
      "이 3단계를 거치면 “대화를 하며 지시를 따르고, 유해성은 줄이고, 유용성은 높인” 생성 모델이 됩니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인을 생성하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"topic\":\"AI\", \"model_name\":\"ChatGPT\"})\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) ChatPromptTemplate\n",
    "* SystemMessagePromptTemplate와 HumanMessagePromptTemplate 클래스 사용\n",
    "* 객체 지향적 접근 - Message 객체를 독립적으로 생성 가능\n",
    "* 여러 조건에 따라 다른 시스템 메시지 선택\n",
    "\n",
    "```python\n",
    "if user_is_beginner:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"초보자를 위한 설명: {topic}\")\n",
    "else:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"전문가를 위한 상세 분석: {topic}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ChatMessagePromptTemplate 활용\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI expert in {topic}. Please provide clear and detailed explanations.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"What is deep learning?\")\n",
    "\n",
    "# LLM 호출\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatMessagePromptTemplate는 여러 종류의 메시지(시스템, 인간, AI)를 조합하여 복잡한 프롬프트를 생성할 때 유용합니다.\n",
    "* SystemMessagePromptTemplate: 이 템플릿은 AI 모델에게 역할을 부여하거나 전반적인 규칙을 설정하는 시스템 메시지를 만듭니다. 위의 예시에서는 \"번역을 도와주는 유용한 도우미\"라는 역할을 지정합니다.\n",
    "* HumanMessagePromptTemplate: 이 템플릿은 사용자의 질문이나 요청을 담는 인간 메시지를 만듭니다. 아래의 예시에서는 번역할 텍스트를 입력받습니다.\n",
    "* ChatPromptTemplate.from_messages: 이 클래스 메서드는 시스템 메시지, 인간 메시지 등 여러 종류의 MessagePromptTemplate 객체들을 리스트로 받아 하나의 채팅 프롬프트 템플릿으로 통합합니다.\n",
    "* format_messages: 이 메서드는 정의된 템플릿에 실제 값을 채워 넣어 [SystemMessage, HumanMessage] 형태의 리스트를 반환합니다. 이 리스트는 채팅 모델(Chat Model) 에 바로 전달될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant that translates English to Korean.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I love programming.', additional_kwargs={}, response_metadata={})]\n",
      "나는 프로그래밍을 사랑해요.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 1. SystemMessagePromptTemplate와 HumanMessagePromptTemplate 생성\n",
    "# SystemMessagePromptTemplate는 모델의 페르소나 또는 기본 지침을 설정합니다.\n",
    "system_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# HumanMessagePromptTemplate는 사용자로부터 받는 입력 프롬프트를 정의합니다.\n",
    "human_template = \"{text_to_translate}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 2. ChatPromptTemplate 생성\n",
    "# 위에서 만든 두 템플릿을 리스트로 묶어 ChatPromptTemplate을 만듭니다.\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# 3. 프롬프트 포맷팅\n",
    "# chat_prompt_template.format_messages()를 사용하여 최종 메시지 리스트를 생성합니다.\n",
    "# 이 함수는 딕셔너리 형태의 입력 변수를 받습니다.\n",
    "formatted_prompt = chat_prompt_template.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Korean\",\n",
    "    text_to_translate=\"I love programming.\"\n",
    ")\n",
    "\n",
    "# 4. 결과 출력\n",
    "print(formatted_prompt)\n",
    "\n",
    "# LLM 호출\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) FewShotPromptTemplate\n",
    "* FewShotPromptTemplate은 모델이 특정 형식을 따르게 하거나, 일관된 응답을 생성하도록 유도할 때 유용합니다.\n",
    "* 도메인 지식이 필요하거나, AI가 오답을 줄이고 더 신뢰할 만한 답변을 생성하도록 해야 할 때 효과적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1) PromptTemplate을 사용하지 않는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "태양계 행성(태양에서부터의 순서)\n",
      "\n",
      "1. 수성(Mercury) – 가장 작고, 가까우며, 표면 온도 변화가 극심  \n",
      "2. 금성(Venus) – 두꺼운 이산화탄소 대기, 지름·질량은 지구와 비슷하지만 표면 460 °C  \n",
      "3. 지구(Earth) – 유일한 액체 해양과 생명체 보유  \n",
      "4. 화성(Mars) – 붉은 사막·극冠, 얇은 대기, 탐사 로봇 상주  \n",
      "5. 목성(Jupiter) – 태양계 최대 기체 행성, 대적점·79개 이상 위성(가니메데 등)  \n",
      "6. 토성(Saturn) – 눈에 띄는 고리계, 밀도는 물보다 낮음, 80개 이상 위성(타이탄 등)  \n",
      "7. 천왕성(Uranus) – 옆으로 누운 자전축, 얼음·가스 혼합, 약한 고리  \n",
      "8. 해왕성(Neptune) – 태양계 궤도가 가장 긴 기체 행성, 강한 바람(초속 600 m)\n",
      "\n",
      "※ 작은 행성(지구형) 4개 → 큰 행성(목성형) 4개  \n",
      "※ 2006년 명왕성은 ‘왜행성’으로 분류됨\n"
     ]
    }
   ],
   "source": [
    "# PromptTemplate을 사용하지 않는 경우\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"태양계의 행성들을 간략히 정리해 주세요.\")\n",
    "\n",
    "print(type(result))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-2) FewShotChatMessagePromptTemplate 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': '뉴턴의 운동 법칙을 요약해 주세요.', 'output': '### 뉴턴의 운동 법칙\\n1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\\n2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\\n3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.'}, {'input': '지구의 대기 구성 요소를 알려주세요.', 'output': '### 지구 대기의 구성\\n- **질소 (78%)**: 대기의 대부분을 차지합니다.\\n- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\\n- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\\n- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x12c473e00>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x12ce50980>, root_client=<openai.OpenAI object at 0x12c471550>, root_async_client=<openai.AsyncOpenAI object at 0x12ce506e0>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "### 양자컴퓨터가 뭔가요?\n",
      "\n",
      "1. **우리가 쓰는 컴퓨터**  \n",
      "   - 전기 스위치가 0 또는 1 하나만 보여요.  \n",
      "   - 이 스위치를 “비트”라고 해요.\n",
      "\n",
      "2. **양자 컴퓨터**  \n",
      "   - 스위치가 0과 1을 “동시에” 볼 수 있어요.  \n",
      "   - 이런 마법 스위치를 “큐비트”라고 불러요.\n",
      "\n",
      "3. **왜 마법일까?**  \n",
      "   - 0과 1을 동시에 쓰면 길이 3짜리 비밀번호(000~111)를 한 번에 다 확인할 수 있어요.  \n",
      "   - 문제가 커질수록 더 많은 길을 “한방에” 찾아서 빨리 끝내요.\n",
      "\n",
      "4. **하지만 아직은…**  \n",
      "   - 큐비트가 아주 예민해서 조금만 흔들려도 깨져 버려요.  \n",
      "   - 지금은 실험실에서만 작동해요. 과학자들이 더 튼튼하게 만드는 중!\n",
      "\n",
      "→ **요약**  \n",
      "양자 컴퓨터는 0과 1을 ‘동시에’ 쓰는 특별한 계산기로, 아주 어려운 퍼즐을閃电처럼 풀어 줄 미래의 컴퓨터예요.\n"
     ]
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate 사용하는 경우\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "chain = final_prompt | llm\n",
    "print(chain)\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"양자컴퓨팅에 대하여 설명해 주세요.\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1) PartialPrompt \n",
    "* 프롬프트를 더 동적으로 활용할 수 있으며, AI 응답을 더 일관성 있게 조정 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 가을에 일어나는 대표적인 지구과학 현상은 태풍 발생이 맞나요? 가을에 주로 발생하는 지구과학 현상을 3개 알려주세요\n",
      " 모델 응답: 가을에 **\"태풍 발생\"**은 **정확히 맞지 않습니다**.  \n",
      "태풍은 **여름철(7~9월)**에 **가장 많이 발생**하지만, **가을에도 발생할 수는 있습니다**—특히 9~10월에는 **고도 발달한 강력한 태풍(예: 가을 태풍)**이 자주 오지만, **가을에 \"주로\" 발생하는 현상은 아닙니다**.\n",
      "\n",
      "---\n",
      "\n",
      "### ✅ 가을에 **주로 발생하는 대표적인 지구과학 현상 3가지**:\n",
      "\n",
      "1. **대기 안정화로 인한 **가을 고기압** 형성**  \n",
      "   → 여름철의 불안정한 대기가 안정되면서 **고기압이 강화**되고, **맑고 건조한 날씨**가 계속됨.\n",
      "\n",
      "2. **기온 역전 현상 (Radiation inversion)**  \n",
      "   → 밤이 길어지고 지면이 빠르게 식으면서 **지표 근처의 기온이 상층보다 낮아지는 현상**이 빈번해짐.  \n",
      "   → **안개**, **서리**, **이슬**이 자주 발생.\n",
      "\n",
      "3. **단풍과 낙엽의 계절적 변화 (식생 계절성)**  \n",
      "   → 기온 하강과 일조 시간 감소로 **나무의 활동이 줄어들고**, **잎의 색소 변화(단풍)**가 일어남.  \n",
      "   → 이는 **기후학적 계절 변화**의 일부로, **지구과학적으로도 중요한 현상**입니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 요약\n",
      "- 태풍은 **여름철 주요 현상**, 가을엔 **드물게 강력한 가을 태풍**이 올 뿐.\n",
      "- 가을에는 **고기압 강화**, **기온 역전**, **단풍/낙엽** 같은 **계절적 지구과학 현상**이 대표적입니다.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# 프롬프트 템플릿 정의 (부분 변수 적용)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{season}에 일어나는 대표적인 지구과학 현상은 {phenomenon}이 맞나요? {season}에 주로 발생하는 지구과학 현상을 3개 알려주세요\",\n",
    "    input_variables=[\"phenomenon\"],  # 사용자 입력 필요\n",
    "    partial_variables={\"season\": get_current_season()}  # 동적으로 계절 값 할당\n",
    ")\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "# 특정 계절의 현상 질의\n",
    "query = prompt.format(phenomenon=\"태풍 발생\")\n",
    "result = llm.invoke(query)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\" 프롬프트: {query}\")\n",
    "print(f\" 모델 응답: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 계절: 가을\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# Step 1: 현재 계절 결정\n",
    "season_name = get_current_season()  # 계절 값 얻기\n",
    "print(f\"현재 계절: {season_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 가을에 발생하는 자연 현상:\n",
      "가을철에 뚜렷하게 나타나는 지구과학 현상 3가지를 꼽으면 다음과 같습니다.\n",
      "\n",
      "1. 시베리아 고기압의 발달  \n",
      "   아시아 대륙이 급속히 식으면서 시베리아-몽골 부근에 강한 고기압이 형성됩니다. 이 고기압이 남하하면서 한반도에 맑고 건조한 가을 날씨를 만들고, 남쪽으로 진출할 때는 겨울철 북서 계절풍의 ‘전초부’ 역할을 합니다.\n",
      "\n",
      "2. 기압골 주도의 이상고온(가을 늦더위)  \n",
      "   중국 대륙에서 동진하는 기압골이 한반도 상공을 지나면 대기가 강한 하강气流(하강气流)를 타고 압축·가열됩니다. 이때 하층의 동풍이 뜨거진 야산성(야간 산성) 기류를 내륙으로 끌어들여 9∼10월에 30 ℃ 안팎의 ‘가을 늦더위’를 발생시킵니다.\n",
      "\n",
      "3. 산간 계곡에서의 복사(輻射) 안개  \n",
      "   밤이 길어지고 지면이 맑게 감기면서 계곡 바닥은 대기보다 훨씬 차가워집니다. 이에 따라 인근 공기가 수증화 포화 상태에 이르러 수증기가 응결·부유하면서 연무(안개)가 깊게 깔리는 현상이 자주 관측됩니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: 해당 계절의 자연 현상 추천\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{season}에 주로 발생하는 대표적인 지구과학 현상 3가지를 알려주세요. \"\n",
    "    \"각 현상에 대해 간단한 설명을 포함해주세요.\"\n",
    ")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "##llm = ChatOpenAI(\n",
    "##    #api_key=OPENAI_API_KEY,\n",
    "##    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "##    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "##    temperature=0.0\n",
    "##)\n",
    "\n",
    "# 체인 2: 자연 현상 추천 (입력: 계절 → 출력: 자연 현상 목록)\n",
    "chain2 = (\n",
    "    {\"season\": lambda x : season_name}  # chain1의 출력을 season 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: 현재 계절에 따른 자연 현상 추천\n",
    "response = chain2.invoke({})\n",
    "print(f\"\\n {season_name}에 발생하는 자연 현상:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2) PartialPrompt \n",
    "* API 호출 데이터, 시간 정보, 사용자 정보 등을 반영할 때 매우 유용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 현재 1달러 = 1406.48원 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\n",
      " 모델 응답: 현재 환율 1달러 = 1,406.48원은 **역대 최고 수준**에 근접한 수치로, 단순한 '약세'를 넘어 **심각한 원화 취약 증후군**이 본격화된 신호로 읽히는 구간입니다. 아래에 5가지 측면에서 구조적·정책적 함의를 정리해 드립니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. 수치로 본 위치\n",
      "- **고점 대비 상승률**: 2017년 1,050원 대비 약 34% 절상(원화 약세)  \n",
      "- **작년 동기 대비**: 2023년 5월 1,320원 → 1년 새 약 6.5% 추가 약세  \n",
      "- **트리플 디지트 심리선**: 1,400원 돌파는 서울·워싱턴 양쪽 모두 '사안'이 될 수준\n",
      "\n",
      "---\n",
      "\n",
      "### 2. 원화 약세의 3대 구조적 책임 요인\n",
      "| 요인 | 설명 | 비고 |\n",
      "|---|---|---|\n",
      "| **1) 수출 구조 전환** | 반도체·배터리 등 대형 품목이 수출 둔화, 중국 베이스 이격↑ | 한국은행 기준, 2024년 1-4월 수출 YoY -6.5% |\n",
      "| **2) 안전자산 선호** | 미국 10년물 4.5% vs 한국 10년물 3.5% → 차익거래 자금 지속 유출 | 외국인 채권투자 2024년 누적 –8조원 |\n",
      "| **3) 경상수지 구조 변화** | 2022년 이후 에너지·식품 역외 가격↑에도 불구, 재정건전성 우선 → 재정소비 억제 | 2023년 경상수지 흑자 29.8bn$ → 2024년 13bn$ 전망(하락) |\n",
      "\n",
      "---\n",
      "\n",
      "### 3. 금통위·재정당국의 선택지\n",
      "1. **외환건전성 부담**  \n",
      "   - 한국은행이 1,400원 '심리선'을 사실상 방치 → 시장 \"라인 인 더 샌드\" 신뢰 하락  \n",
      "   - 실효성 있는 방어는 1) 1조+ 달러 매도(외환보유액 4,100억$ 대비 2.5% 수준) 2) 양적 긴축(통화안정증권 발행 확대) 3) 재정·금융당국 합동 '변동성 완화' 선언  \n",
      "\n",
      "2. **물가·가계부담**  \n",
      "   - 원화 약세 10% → 수입물가지수 6~7%↑ → CPI 0.4~0.5%p 가산  \n",
      "   - 1인당 국민소득 3만$ 시대, 체감 구매력 하락이 실질소득보다 빠르게 나타남\n",
      "\n",
      "3. **기업 재무**  \n",
      "   - 달러 부채 비중 높은 항공·조선·석유화학 업종은 환손익 개선, 반대로 내수형 제조·유통업은 원자재비↑  \n",
      "   - 2024년 1분기 상장사 30%가 환차손(별도 기준) 기록, 역대 최대\n",
      "\n",
      "---\n",
      "\n",
      "### 4. 국제 시각\n",
      "- **미 재무부 통화보고서**에서는 '관찰대상국' 요건(대미 흑자 150억$, 경상흑자 2% 초과) 중 하나라도 충족 시 **환율저격성 간주** 가능  \n",
      "- 현재 한국은 대미 흑자 2023년 440억$, 경상흑자 1.4% → **간발의 차이**로 '관찰대상국' 회피\n",
      "\n",
      "---\n",
      "\n",
      "### 5. 앞으로의 시나리오(6개월 시야)\n",
      "| 시나리오 | 환율 구간 | 핵심 조건 |\n",
      "|---|---|---|\n",
      "| **A. 소프트 랜딩** | 1,350~1,380 | ① 연준 9월 인하 1회, ② 중국 경기 반등, ③ 한은 CPI 2% 안착 |\n",
      "| **B. 베이스 케이스** | 1,380~1,430 | ① 연준 연내 0~1회 인하, ② 수출 회복 느림, ③ 한은 CPI 2% 초반 |\n",
      "| **C. 리스크 오프** | 1,450~1,500+ | ① 중동·러-우크 전장 확대, ② 미 경기 침체, ③ 한·중 수출 동반 급감 |\n",
      "\n",
      "---\n",
      "\n",
      "### 6. 투자·운용 포인트\n",
      "1. **헤지 비율**  \n",
      "   - 수입의 60% 이상이 달러·엔·위안화 → 3개월 이내 결제물량 기준 50%±10% 선물·스왑 헤지 권장(변동성 12% 기준)\n",
      "\n",
      "2. **자산 배분**  \n",
      "   - 원화 표면 수익률이 높은 채권(예: 5년 만기 국고채 3.6%)은 환헤지 후 실질수익 ↓ → **달러 표시 글로벌 투자등급 채권**이나 **단기 미국 국채(T-Bill 5.2%)**가 실질 매력도 우위\n",
      "\n",
      "3. **주식 섹터**  \n",
      "   - 환율 1,400원 이후 3개월간 **반도체 대형주(삼성전자, SK하이닉스)**는 평균 10% 초과수익, **내수형 유통·건설주**는 –5% 수준 → 섹터 로테이션 유효\n",
      "\n",
      "---\n",
      "\n",
      "### 7. 결론 & 액션 아이템\n",
      "\"1,400원 이상의 환율은 단순한 '경고등'이 아니라 **경제·정치·외교 전방위에 걸친 전략적 리스크**다.\"\n",
      "\n",
      "- 기업CFO: 6개월~1년간 달러 수요를 선반(先販)·선입(先入) 헤지 비중 30%p 확대  \n",
      "- 가계·개인: 해외 직구·여행 소비 20% 절감, **달러 표시 MMF·단기 채권**으로 현금성 자산 10~20% 편입  \n",
      "- 정책당국:  \n",
      "  1) 외환유동성 공급 프로그램(FX swap line) 재개 검토  \n",
      "  2) 물가 안정을 위한 수입관세·특별할당 할인 한시복귀  \n",
      "  3) '관찰대상국' 회피를 위한 대미 흑자 축소 로드맵(에너지·방위산업 협상) 수립\n",
      "\n",
      "이상으로, **1,406.48원은 원화가 맞닥뜨린 '새로운 정상'이자 동시에 '새로운 위험'**이라는 점을 염두에 두고 재무·투자·정책 포트폴리오를 재정비할 시점이라고 판단됩니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 실시간 환율을 가져오는 함수\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1달러 = {data['rates']['KRW']}원\"\n",
    "\n",
    "# Partial Prompt 활용\n",
    "prompt = PromptTemplate(\n",
    "    template=\"현재 {info} 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\",\n",
    "    input_variables=[],  # 사용자 입력 없음\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # API에서 가져온 데이터 자동 반영\n",
    ")\n",
    "\n",
    "# LLM 모델 설정\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "# 모델에 프롬프트 전달 및 응답 받기\n",
    "response = llm.invoke(prompt.format())\n",
    "\n",
    "# 결과 출력\n",
    "print(\" 프롬프트:\", prompt.format())\n",
    "print(\" 모델 응답:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
