{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "#### LangSmith 기본 예제\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "##### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [],
   "source": [
    "# poetry add langsmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "##### 2) OpenAI 인증키 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_T\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "##### LangSmith와 LangChain을 활용한 기본 로깅 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 [AI 답변]:\n",
      "LangGraph와 LangChain은 모두 언어 모델을 활용하여 애플리케이션을 구축하기 위한 프레임워크이지만, 두 프레임워크는 다른 디자인 철학과 사용 사례에 중점을 둡니다.\n",
      "\n",
      "LangChain:\n",
      "\n",
      "LangChain은 언어 모델을 사용하여 애플리케이션을 구축하기 위한 오픈 소스 프레임워크입니다. 주요 목표는 개발자가 언어 모델을 쉽게 통합하고 확장 가능하며 효율적인 애플리케이션을 구축할 수 있도록 하는 것입니다. LangChain은 언어 모델, 메모리 및 외부 세계와의 상호 작용을 관리하는 모듈식 아키텍처를 제공합니다.\n",
      "\n",
      "LangGraph:\n",
      "\n",
      "LangGraph는 LangChain을 만든 동일한 팀에서 개발한 고급 워크플로우 엔진 및 에이전트 플랫폼입니다. LangGraph를 사용하면 여러 도구, 데이터 소스 및 언어 모델을 사용하여 복잡한 애플리케이션과 워크플로를 구축할 수 있습니다. LangGraph는 에이전트 기반 시뮬레이션, 다중 단계 추론 및 동적 워크플로 관리에 중점을 둡니다.\n",
      "\n",
      "주요 차이점:\n",
      "\n",
      "1. 목적:\n",
      "    * LangChain: 확장 가능하고 효율적인 애플리케이션을 구축하기 위한 언어 모델 통합에 중점을 둡니다.\n",
      "    * LangGraph: 여러 도구와 언어 모델을 사용하여 복잡한 워크플로 및 에이전트 기반 애플리케이션을 관리하는 고급 워크플로 엔진 및 에이전트 플랫폼을 제공하는 것을 목표로 합니다.\n",
      "2. 아키텍처:\n",
      "    * LangChain: 언어 모델, 메모리 및 외부 세계와의 상호 작용을 관리하는 모듈식 아키텍처를 제공합니다.\n",
      "    * LangGraph: 에이전트 기반 시뮬레이션, 다중 단계 추론 및 동적 워크플로 관리를 지원하는 고급 워크플로 엔진으로 설계되었습니다.\n",
      "3. 사용 사례:\n",
      "    * LangChain: 챗봇, 언어 번역 및 텍스트 요약과 같은 애플리케이션에 적합합니다.\n",
      "    * LangGraph: 여러 에이전트, 도구 및 데이터 소스가 포함된 복잡한 워크플로가 필요한 시뮬레이션, 자동화 및 의사 결정과 같은 애플리케이션에 적합합니다.\n",
      "\n",
      "요약하면 LangChain은 언어 모델 통합을 위한 보다 일반적인 프레임워크인 반면 LangGraph는 복잡한 워크플로 및 에이전트 기반 애플리케이션을 구축하기 위한 특수 플랫폼입니다. LangGraph는 LangChain을 기반으로 구축되었으며 두 프레임워크는 서로 보완적인 것으로 간주될 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langsmith import traceable\n",
    "\n",
    "# LangSmith API Key 설정\n",
    "os.environ[\"LANGSMITH_TRACING\"] = os.getenv(\"LANGSMITH_TRACING\")  # LangSmith 활성화\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")  # API Key 불러오기\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = os.getenv(\"LANGSMITH_PROJECT\")   # 프로젝트 이름 설정\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = os.getenv(\"LANGSMITH_ENDPOINT\")   # EndPoint 설정\n",
    "\n",
    "# LLM 모델 설정 (OpenAI 사용)\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# LangSmith로 실행 추적\n",
    "@traceable(run_type=\"chain\", name=\"Simple_Chain\")\n",
    "def ask_question(question: str):\n",
    "\n",
    "    # 개별 메시지 템플릿 정의\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\n",
    "        \"당신은 유용한 AI 비서입니다.\"\n",
    "    )\n",
    "    user_message = HumanMessagePromptTemplate.from_template(\n",
    "        \"{question}\"\n",
    "    )\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        system_message,\n",
    "        user_message,\n",
    "    ])\n",
    "    \n",
    "    messages = chat_prompt.format_messages(question=question)\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    return response.content\n",
    "\n",
    "# 테스트 실행\n",
    "question = \"LangGraph와 LangChain의 차이점은 무엇인가요?\"\n",
    "answer = ask_question(question)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n🔹 [AI 답변]:\")\n",
    "print(answer)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mylangchain-app-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
