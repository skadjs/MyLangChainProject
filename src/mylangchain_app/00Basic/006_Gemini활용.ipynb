{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb0fa4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8264ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIza\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "print(GOOGLE_API_KEY[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d93f00ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758777588.312820 2334887 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Google Gemini Response:\n",
      "네, AI 전문가로서 LangChain과 LangGraph에 대해 명확하고 깊이 있게 설명해 드리겠습니다.\n",
      "\n",
      "이 둘은 서로 밀접하게 관련되어 있지만, 목적과 구조에서 중요한 차이가 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. LangChain (랭체인): LLM 애플리케이션의 '레고 블록'\n",
      "\n",
      "**LangChain은 한마디로, 대규모 언어 모델(LLM)을 활용한 애플리케이션을 더 쉽고 강력하게 만들 수 있도록 도와주는 개발 프레임워크입니다.**\n",
      "\n",
      "LLM 자체는 단순히 텍스트를 입력받아 텍스트를 생성하는 기능만 가지고 있습니다. 하지만 우리가 원하는 것은 'PDF 문서를 읽고 질문에 답하는 챗봇', '최신 뉴스 기사를 요약하고 이메일로 보내주는 에이전트'와 같은 복잡한 애플리케이션입니다. LangChain은 이러한 애플리케이션을 만들기 위한 다양한 구성 요소(Component)들을 '레고 블록'처럼 제공하고, 이들을 연결(Chaining)하여 원하는 기능을 구현하도록 돕습니다.\n",
      "\n",
      "#### 핵심 구성 요소 (레고 블록)\n",
      "\n",
      "*   **Models**: OpenAI의 GPT, Anthropic의 Claude 등 다양한 LLM 모델과 쉽게 연동할 수 있는 인터페이스를 제공합니다.\n",
      "*   **Prompts**: LLM에 전달할 지시문(프롬프트)을 효과적으로 관리하고, 동적으로 생성할 수 있는 템플릿 기능을 제공합니다.\n",
      "*   **Chains**: LangChain의 핵심 개념으로, LLM 호출과 다른 구성 요소들을 순차적으로 연결하는 것을 의미합니다. (예: 사용자 질문 받기 → 관련 문서 검색 → 검색된 문서와 질문을 LLM에 전달 → 답변 생성)\n",
      "*   **Indexes (Retrieval)**: LLM이 알지 못하는 외부 데이터(PDF, DB, 웹사이트 등)를 가져와 LLM이 참고할 수 있도록 만드는 기능입니다. **RAG(Retrieval-Augmented Generation, 검색 증강 생성)**의 핵심 요소입니다.\n",
      "*   **Agents**: LLM을 '추론 엔진'으로 사용하여 어떤 도구(Tool, 예: 구글 검색, 계산기, API 호출)를 사용해야 할지 스스로 결정하고 행동하게 만드는 기능입니다.\n",
      "*   **Memory**: 대화의 이전 내용을 기억하게 하여, 챗봇 등이 맥락을 유지하며 대화할 수 있도록 지원합니다.\n",
      "\n",
      "> **비유:** LangChain은 **'조립식 주방 키트'**와 같습니다. 싱크대, 가스레인지, 수납장 등 개별 부품(구성 요소)들이 있고, 개발자는 이들을 설명서(Chain)에 따라 순서대로 조립하여 멋진 주방(LLM 애플리케이션)을 완성할 수 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. LangGraph (랭그래프): 복잡하고 순환적인 '의사결정 흐름도'\n",
      "\n",
      "**LangGraph는 LangChain의 확장 라이브러리로, 에이전트(Agent)와 같이 복잡하고, 상태(State)를 가지며, 순환(Cycle)이 가능한 워크플로우를 만들기 위해 설계되었습니다.**\n",
      "\n",
      "기존 LangChain의 `Chain`이나 `AgentExecutor`는 대부분 **선형적(A→B→C)**이거나 정해진 흐름을 따릅니다. 하지만 더 발전된 AI 시스템은 다음과 같은 복잡한 작업이 필요합니다.\n",
      "\n",
      "*   \"결과가 만족스럽지 않으면, 다른 도구를 사용해서 다시 시도해봐.\" (**순환/루프**)\n",
      "*   \"A와 B 두 가지 방법 중, 상황에 더 적합한 것을 선택해.\" (**조건부 분기**)\n",
      "*   \"초안을 작성하고, 비평가에게 검토를 요청한 뒤, 피드백을 반영하여 수정해. 이 과정을 만족할 때까지 반복해.\" (**다중 에이전트 협업**)\n",
      "*   \"중요한 결정을 내리기 전에는, 사람에게 먼저 확인을 받아.\" (**인간의 개입, Human-in-the-loop**)\n",
      "\n",
      "LangGraph는 이러한 복잡한 '의사결정 흐름'을 **그래프(Graph)** 형태로 표현합니다.\n",
      "\n",
      "#### 핵심 개념\n",
      "\n",
      "*   **State (상태)**: 그래프 전체에서 공유되는 데이터 객체입니다. 각 단계(노드)를 거치면서 이 상태값이 계속 업데이트됩니다.\n",
      "*   **Nodes (노드)**: 그래프의 각 단계를 의미하며, 특정 작업을 수행하는 함수나 LangChain 컴포넌트입니다. (예: '웹 검색 노드', 'LLM 호출 노드')\n",
      "*   **Edges (엣지)**: 노드와 노드를 연결하는 선입니다. LangGraph의 핵심은 이 엣지에 **조건부 논리**를 추가할 수 있다는 것입니다. 즉, 이전 노드의 결과에 따라 다음에 어떤 노드로 이동할지 결정할 수 있습니다.\n",
      "\n",
      "> **비유:** LangGraph는 **'고도로 숙련된 셰프 팀의 요리 과정'**과 같습니다. 정해진 레시피(Chain)만 따르는 것이 아니라, \"수프 맛을 보고, 싱거우면 소금을 더 넣고(순환), 메인 요리로 생선과 고기 중 손님이 원하는 것을 선택하며(분기), 플레이팅은 다른 셰프에게 검토받는(협업)\" 것과 같은 동적이고 지능적인 작업 흐름을 설계할 수 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 핵심 차이점 및 언제 사용해야 할까?\n",
      "\n",
      "| 구분 | **LangChain** | **LangGraph** |\n",
      "| :--- | :--- | :--- |\n",
      "| **구조** | **선형적 (Chains)** | **순환적, 비선형적 (Graphs)** |\n",
      "| **제어 흐름** | 단순, 순차적 | 복잡, 조건부 분기, 루프(순환) 가능 |\n",
      "| **상태 관리** | 각 단계별로 데이터를 전달하는 방식 | 중앙 집중화된 `State` 객체를 통해 명시적으로 관리 |\n",
      "| **주요 사용 사례** | - 문서 기반 Q&A 챗봇 (RAG)<br>- 텍스트 요약, 번역<br>- 간단한 순차적 작업 자동화 | - **다중 에이전트 협업 시스템**<br>- **자기 수정/개선이 가능한 에이전트**<br>- **인간의 승인/개입이 필요한 워크플로우**<br>- 복잡한 의사결정이 필요한 시스템 |\n",
      "\n",
      "### 결론\n",
      "\n",
      "*   **LangChain**은 LLM 애플리케이션을 만들기 위한 **기본적인 부품과 조립 설명서**를 제공하는 포괄적인 프레임워크입니다. 대부분의 LLM 기반 애플리케이션은 LangChain으로 시작합니다.\n",
      "*   **LangGraph**는 LangChain의 부품들을 사용하여, 단순한 조립을 넘어 **스스로 생각하고, 수정하고, 협업하는 고도의 지능형 시스템(에이전트)을 만들기 위한 고급 설계도**입니다.\n",
      "\n",
      "따라서 개발자는 먼저 LangChain으로 기본 구성 요소를 익히고, 더 복잡하고 자율적인 에이전트 시스템을 구축해야 할 때 LangGraph를 도입하는 것이 일반적인 수순입니다. 이 둘은 대체 관계가 아닌, **기본과 심화의 관계**라고 이해하시면 가장 정확합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "    \n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 모델 초기화\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    #model=\"gemini-1.5-flash\",\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    temperature=0.3    \n",
    ")\n",
    "\n",
    "# 프롬프트 설정\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 AI 전문가입니다.\"),\n",
    "    (\"human\", \"{topic}은(는) 무엇인가요?\")\n",
    "])\n",
    "\n",
    "# 체인 실행\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\"topic\": \"LangChain과 LangGraph\"})\n",
    "\n",
    "print(\" Google Gemini Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99bcfff",
   "metadata": {},
   "source": [
    "#### Gemini 모델별 특징\n",
    "\n",
    "* gemini-1.5-flash: 빠른 응답, 일반적인 작업에 적합\n",
    "* gemini-2.5-pro: 더 정확하고 복잡한 추론 작업\n",
    "* gemini-pro-vision: 이미지 처리 및 멀티모달 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37613cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "예제 1: 기본 대화형 챗봇\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758777625.704281 2334887 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답: 안녕하세요! 파이썬으로 리스트를 정렬하는 방법을 찾고 계시는군요. 아주 좋은 질문이에요! 파이썬에서는 리스트를 정렬하는 대표적인 두 가지 방법이 있습니다.\n",
      "\n",
      "바로 `sort()` 메소드와 `sorted()` 내장 함수인데요, 각각의 특징과 사용법을 예제와 함께 쉽고 자세하게 알려드릴게요.\n",
      "\n",
      "### 1. `list.sort()` 메소드: 원본 리스트를 직접 수정\n",
      "\n",
      "이 방법은 리스트 객체 자체가 가지고 있는 메소드입니다. 가장 큰 특징은 **원본 리스트를 그 자리에서 바로 정렬**한다는 점입니다. 그래서 반환되는 값은 없고(`None`), 원본 리스트가 변경됩니다.\n",
      "\n",
      "**기본 사용법 (오름차순)**\n",
      "\n",
      "```python\n",
      "numbers = [3, 1, 4, 1, 5, 9, 2]\n",
      "print(f\"정렬 전: {numbers}\")\n",
      "\n",
      "# numbers 리스트 자체를 정렬합니다. 반환값은 없습니다.\n",
      "numbers.sort()\n",
      "\n",
      "print(f\"정렬 후: {numbers}\")\n",
      "```\n",
      "\n",
      "**실행 결과:**\n",
      "\n",
      "```\n",
      "정렬 전: [3, 1, 4, 1, 5, 9, 2]\n",
      "정렬 후: [1, 1, 2, 3, 4, 5, 9]\n",
      "```\n",
      "\n",
      "### 2. `sorted()` 내장 함수: 새로운 정렬된 리스트를 반환\n",
      "\n",
      "이 함수는 파이썬의 내장 함수로, 어떤 반복 가능한(iterable) 객체든 인자로 받을 수 있습니다. 가장 큰 특징은 **원본 리스트는 그대로 두고, 정렬된 새로운 리스트를 생성하여 반환**한다는 점입니다. 원본 데이터를 유지해야 할 때 매우 유용합니다.\n",
      "\n",
      "**기본 사용법 (오름차순)**\n",
      "\n",
      "```python\n",
      "numbers = [3, 1, 4, 1, 5, 9, 2]\n",
      "print(f\"정렬 전 원본 리스트: {numbers}\")\n",
      "\n",
      "# numbers 리스트를 기반으로 새로운 정렬된 리스트를 생성합니다.\n",
      "new_sorted_list = sorted(numbers)\n",
      "\n",
      "print(f\"새로 생성된 정렬 리스트: {new_sorted_list}\")\n",
      "print(f\"정렬 후 원본 리스트: {numbers}\") # 원본은 그대로 유지됩니다!\n",
      "```\n",
      "\n",
      "**실행 결과:**\n",
      "\n",
      "```\n",
      "정렬 전 원본 리스트: [3, 1, 4, 1, 5, 9, 2]\n",
      "새로 생성된 정렬 리스트: [1, 1, 2, 3, 4, 5, 9]\n",
      "정렬 후 원본 리스트: [3, 1, 4, 1, 5, 9, 2]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### `sort()` vs `sorted()`: 핵심 차이점 정리\n",
      "\n",
      "| 특징 | `list.sort()` | `sorted()` |\n",
      "| :--- | :--- | :--- |\n",
      "| **형태** | 리스트 객체의 메소드 (`my_list.sort()`) | 내장 함수 (`sorted(my_list)`) |\n",
      "| **원본 수정** | **수정함** (in-place) | **수정하지 않음** |\n",
      "| **반환값** | `None` | 정렬된 **새로운 리스트** |\n",
      "| **적용 대상** | 리스트에만 사용 가능 | 리스트, 튜플 등 모든 반복 가능한 객체에 사용 가능 |\n",
      "\n",
      "---\n",
      "\n",
      "### 다양한 정렬 옵션 (내림차순, 특정 기준으로 정렬)\n",
      "\n",
      "두 방법 모두 추가 옵션을 통해 더 다양한 정렬을 할 수 있습니다.\n",
      "\n",
      "#### 1. 내림차순 정렬 (`reverse=True`)\n",
      "\n",
      "오름차순이 아닌 내림차순(역순)으로 정렬하고 싶을 때는 `reverse=True` 옵션을 사용합니다.\n",
      "\n",
      "```python\n",
      "# sort() 사용\n",
      "numbers = [3, 1, 4, 5, 2]\n",
      "numbers.sort(reverse=True)\n",
      "print(f\"sort() 내림차순: {numbers}\") # [5, 4, 3, 2, 1]\n",
      "\n",
      "# sorted() 사용\n",
      "numbers = [3, 1, 4, 5, 2]\n",
      "new_list = sorted(numbers, reverse=True)\n",
      "print(f\"sorted() 내림차순: {new_list}\") # [5, 4, 3, 2, 1]\n",
      "```\n",
      "\n",
      "#### 2. 특정 기준으로 정렬 (`key` 옵션)\n",
      "\n",
      "숫자나 알파벳 순서가 아닌, 자신만의 특별한 기준으로 정렬하고 싶을 때 `key` 옵션을 사용합니다. `key`에는 정렬의 기준이 될 값을 반환하는 함수를 지정해줍니다. 보통 간단한 `lambda` 함수를 많이 사용합니다.\n",
      "\n",
      "**예시 1: 문자열 길이를 기준으로 정렬하기**\n",
      "\n",
      "```python\n",
      "fruits = [\"banana\", \"apple\", \"kiwi\", \"cherry\"]\n",
      "\n",
      "# 각 단어의 길이를 기준으로 정렬\n",
      "sorted_by_length = sorted(fruits, key=len)\n",
      "print(sorted_by_length)\n",
      "```\n",
      "\n",
      "**실행 결과:** (길이가 짧은 순서대로 정렬)\n",
      "\n",
      "```\n",
      "['kiwi', 'apple', 'banana', 'cherry']\n",
      "```\n",
      "\n",
      "**예시 2: 리스트 안의 튜플, 두 번째 요소를 기준으로 정렬하기**\n",
      "\n",
      "```python\n",
      "student_scores = [('Alice', 88), ('Bob', 95), ('Charlie', 76)]\n",
      "\n",
      "# 각 튜플의 2번째 요소(인덱스 1)를 기준으로 정렬\n",
      "# lambda student: student[1]는 각 요소를 student로 받아 student[1]을 반환하라는 의미\n",
      "sorted_by_score = sorted(student_scores, key=lambda student: student[1])\n",
      "print(sorted_by_score)\n",
      "```\n",
      "\n",
      "**실행 결과:** (점수가 낮은 순서대로 정렬)\n",
      "\n",
      "```\n",
      "[('Charlie', 76), ('Alice', 88), ('Bob', 95)]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### 언제 무엇을 사용해야 할까요?\n",
      "\n",
      "*   **`list.sort()`**: 원본 리스트를 굳이 보존할 필요가 없고, 메모리를 효율적으로 사용하고 싶을 때 사용합니다. (예: 정렬 후 바로 사용하고 버릴 리스트)\n",
      "*   **`sorted()`**: **원본 리스트를 유지**하면서 정렬된 버전이 필요할 때 사용합니다. 더 안전하고 직관적이어서 **일반적으로 더 많이 추천**됩니다.\n",
      "\n",
      "이해가 잘 되셨나요? 궁금한 점이 또 있으시면 언제든지 다시 물어보세요! 😊\n",
      "\n",
      "==================================================\n",
      "예제 2: JSON 구조화 출력\n",
      "==================================================\n",
      "JSON 결과: ```json\n",
      "{\n",
      "  \"name\": \"네이버\",\n",
      "  \"year\": 1999,\n",
      "  \"location\": \"경기도 성남\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 기본 모델 설정\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    #model=\"gemini-1.5-flash\",\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"예제 1: 기본 대화형 챗봇\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 대화형 프롬프트\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 친근하고 도움이 되는 AI 어시스턴트입니다.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "chat_chain = chat_prompt | llm | StrOutputParser()\n",
    "response1 = chat_chain.invoke({\"user_input\": \"파이썬으로 리스트를 정렬하는 방법은?\"})\n",
    "print(\"응답:\", response1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 2: JSON 구조화 출력\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "json_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "다음 정보를 JSON 형태로 변환하세요:\n",
    "{company_info}\n",
    "\n",
    "형식: {{\"name\": \"회사명\", \"year\": \"연도\", \"location\": \"위치\"}}\n",
    "\"\"\",\n",
    "    input_variables=[\"company_info\"]\n",
    ")\n",
    "\n",
    "json_chain = json_prompt | llm | StrOutputParser()\n",
    "company_text = \"네이버는 1999년에 설립된 한국의 IT 기업이며 본사는 경기도 성남에 있습니다.\"\n",
    "response2 = json_chain.invoke({\"company_info\": company_text})\n",
    "print(\"JSON 결과:\", response2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331af30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "예제 3: 번역 체인\n",
      "==================================================\n",
      "번역 결과: 물론입니다. \"Hello, how are you today?\"는 상황과 상대방에 따라 여러 가지로 번역할 수 있습니다.\n",
      "\n",
      "**가장 일반적이고 격식 있는 표현:**\n",
      "\n",
      "*   **안녕하세요, 오늘 하루 어떠세요?** (Annyeonghaseyo, oneul haru eotteoseyo?)\n",
      "\n",
      "**다른 표현들:**\n",
      "\n",
      "*   **안녕하세요, 오늘 어떻게 지내세요?** (Annyeonghaseyo, oneul eotteoke jinaeseyo?) - 직역에 가까운 표현입니다.\n",
      "*   **안녕하세요? 잘 지내시죠?** (Annyeonghaseyo? Jal jinaesijyo?) - 안부를 묻는 자연스러운 표현입니다.\n",
      "\n",
      "**친한 친구나 아랫사람에게 사용하는 비격식적인 표현:**\n",
      "\n",
      "*   **안녕, 오늘 어때?** (Annyeong, oneul eottae?)\n",
      "\n",
      "==================================================\n",
      "예제 4: 감정 분석\n",
      "==================================================\n",
      "감정 분석: 분석 결과: **긍정**\n",
      "\n",
      "감정 점수: **9/10**\n",
      "\n",
      "**이유:** '성공적으로 완료', '정말 기쁩니다'와 같은 표현은 매우 긍정적인 성취감과 기쁨을 명확하게 나타냅니다.\n",
      "\n",
      "==================================================\n",
      "예제 5: 코드 생성\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 32.673820957s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 32\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 30.456357952s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 30\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 26.244664524s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 26\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 18.021739668s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 18\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "생성된 코드:\n",
      "물론입니다. Python으로 두 숫자의 최대공약수(GCD, Greatest Common Divisor)를 구하는 몇 가지 간단한 방법을 소개해 드리겠습니다.\n",
      "\n",
      "### 1. `math` 모듈 사용 (가장 간단하고 권장되는 방법)\n",
      "\n",
      "Python 3.5 버전부터 `math` 모듈에 `gcd()` 함수가 내장되어 있어 가장 쉽게 사용할 수 있습니다.\n",
      "\n",
      "```python\n",
      "import math\n",
      "\n",
      "# 두 숫자를 정의합니다.\n",
      "num1 = 54\n",
      "num2 = 24\n",
      "\n",
      "# math.gcd() 함수를 사용하여 최대공약수를 계산합니다.\n",
      "result = math.gcd(num1, num2)\n",
      "\n",
      "print(f\"{num1}과(와) {num2}의 최대공약수는 {result}입니다.\")\n",
      "\n",
      "# 출력 결과:\n",
      "# 54과(와) 24의 최대공약수는 6입니다.\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### 2. 유클리드 호제법(Euclidean Algorithm)을 직접 구현하는 방법\n",
      "\n",
      "`math` 모듈을 사용하지 않고, 최대공약수를 구하는 가장 효율적인 알고리즘인 유클리드 호제법을 직접 구현할 수도 있습니다.\n",
      "\n",
      "**원리:**\n",
      "두 수 a, b가 있을 때 (a > b), `a`와 `b`의 최대공약수는 `b`와 `a를 b로 나눈 나머지`의 최대공약수와 같습니다. 이 과정을 나머지가 0이 될 때까지 반복하면, 그 때의 나누는 수가 최대공약수가 됩니다.\n",
      "\n",
      "#### 반복문(while)을 이용한 구현\n",
      "\n",
      "```python\n",
      "def gcd_euclidean(a, b):\n",
      "  \"\"\"\n",
      "  유클리드 호제법(반복문)을 사용하여 최대공약수를 구하는 함수\n",
      "  \"\"\"\n",
      "  while b:  # b가 0이 될 때까지 반복\n",
      "    a, b = b, a % b\n",
      "  return a\n",
      "\n",
      "# 두 숫자를 정의합니다.\n",
      "num1 = 54\n",
      "num2 = 24\n",
      "\n",
      "# 직접 만든 함수를 호출합니다.\n",
      "result = gcd_euclidean(num1, num2)\n",
      "\n",
      "print(f\"{num1}과(와) {num2}의 최대공약수는 {result}입니다.\")\n",
      "\n",
      "# 출력 결과:\n",
      "# 54과(와) 24의 최대공약수는 6입니다.\n",
      "```\n",
      "*   `a, b = b, a % b`는 Python의 튜플 패킹/언패킹을 이용한 간결한 표현입니다.\n",
      "*   `temp = b`, `b = a % b`, `a = temp` 와 동일한 작업을 한 줄로 처리합니다.\n",
      "\n",
      "#### 재귀 함수(Recursion)를 이용한 구현\n",
      "\n",
      "유클리드 호제법의 원리를 재귀적으로 표현하면 코드가 더 직관적일 수 있습니다.\n",
      "\n",
      "```python\n",
      "def gcd_recursive(a, b):\n",
      "  \"\"\"\n",
      "  유클리드 호제법(재귀)을 사용하여 최대공약수를 구하는 함수\n",
      "  \"\"\"\n",
      "  if b == 0:\n",
      "    return a\n",
      "  else:\n",
      "    return gcd_recursive(b, a % b)\n",
      "\n",
      "# 두 숫자를 정의합니다.\n",
      "num1 = 54\n",
      "num2 = 24\n",
      "\n",
      "# 직접 만든 함수를 호출합니다.\n",
      "result = gcd_recursive(num1, num2)\n",
      "\n",
      "print(f\"{num1}과(와) {num2}의 최대공약수는 {result}입니다.\")\n",
      "\n",
      "# 출력 결과:\n",
      "# 54과(와) 24의 최대공약수는 6입니다.\n",
      "```\n",
      "\n",
      "### 요약\n",
      "\n",
      "| 방법 | 장점 | 단점 | 추천 대상 |\n",
      "|---|---|---|---|\n",
      "| **`math.gcd()`** | **가장 간단하고 빠름**, Python 표준 라이브러리 기능 | Python 3.5 이상에서만 사용 가능 | **모든 사용자에게 가장 먼저 권장** |\n",
      "| **유클리드 호제법 (반복)** | 라이브러리 없이 구현 가능, 효율적 | 직접 코드를 작성해야 함 | 알고리즘 학습 또는 구버전 Python 환경 |\n",
      "| **유클리드 호제법 (재귀)** | 알고리즘의 수학적 원리를 잘 표현, 코드가 간결함 | 숫자가 매우 클 경우 재귀 깊이 제한에 걸릴 수 있음 | 알고리즘 학습, 재귀적 사고 연습 |\n",
      "\n",
      "==================================================\n",
      "예제 6: 창의적 콘텐츠 생성\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 3: 번역 체인\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "translate_prompt = ChatPromptTemplate.from_template(\n",
    "    \"다음 텍스트를 {target_language}로 번역하세요: {text}\"\n",
    ")\n",
    "\n",
    "translate_chain = translate_prompt | llm | StrOutputParser()\n",
    "original = \"Hello, how are you today?\"\n",
    "translated = translate_chain.invoke({\n",
    "    \"text\": original, \n",
    "    \"target_language\": \"한국어\"\n",
    "})\n",
    "print(\"번역 결과:\", translated)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 4: 감정 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "emotion_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "텍스트: {text}\n",
    "감정을 분석하고 [긍정/부정/중립]과 1-10점수를 매기세요.\n",
    "\"\"\")\n",
    "\n",
    "emotion_chain = emotion_prompt | llm | StrOutputParser()\n",
    "test_text = \"오늘 프로젝트가 성공적으로 완료되어서 정말 기쁩니다!\"\n",
    "emotion_result = emotion_chain.invoke({\"text\": test_text})\n",
    "print(\"감정 분석:\", emotion_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 5: 코드 생성\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "code_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "{language}로 {task} 기능을 구현하는 간단한 코드를 작성하세요.\n",
    "\"\"\")\n",
    "\n",
    "code_chain = code_prompt | llm | StrOutputParser()\n",
    "code_result = code_chain.invoke({\n",
    "    \"language\": \"Python\",\n",
    "    \"task\": \"두 숫자의 최대공약수를 구하는\"\n",
    "})\n",
    "print(\"생성된 코드:\")\n",
    "print(code_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 6: 창의적 콘텐츠 생성\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "001da18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1758777753.313155 2334887 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "창의적 아이디어: ## 하늘을 나는 도시: 초고속 자기 부상 열차 네트워크\n",
      "\n",
      "**개요:** 지상의 교통 체증 문제를 해결하고, 도시 간 이동 시간을 획기적으로 단축하기 위한 혁신적인 교통 시스템입니다.  하늘을 나는 도시라는 비전 아래, 자기 부상 기술을 기반으로 한 초고속 열차 네트워크를 구축하여 지상 교통과의 완벽한 통합을 이루는 것을 목표로 합니다.\n",
      "\n",
      "**핵심 기술:**\n",
      "\n",
      "* **초고속 자기 부상 기술:** 기존 자기 부상 열차의 한계를 극복한,  초전도체를 이용한 고속 자기 부상 기술을 적용합니다. 이를 통해 시속 1,000km 이상의 속도를 달성하고, 안정성과 효율성을 극대화합니다.\n",
      "* **고정밀 항공 제어 시스템:** 다수의 열차가 동시에 운행되는 환경에서 안전을 보장하기 위한 고정밀 항공 제어 시스템을 개발합니다. 레이저 기반 위치 탐지, 인공지능 기반 교통 관리 시스템,  실시간 위험 감지 시스템 등을 통합하여 안전 운행을 보장합니다.\n",
      "* **모듈식 건설 시스템:**  경량화된 모듈식 구조물을 이용하여  건설 시간과 비용을 최소화합니다.  3D 프린팅 기술과 로봇 공학을 활용하여 효율적인 건설을 추진합니다.\n",
      "* **지상과의 통합 시스템:** 기존 대중교통 시스템과 연계하여,  열차 역사와 지하철, 버스 등과의 원활한 환승 시스템을 구축합니다. 승객들은 스마트폰 애플리케이션을 통해 최적의 경로를 안내 받고, 예약 및 결제를 편리하게 이용할 수 있습니다.\n",
      "* **지속 가능한 에너지원:**  태양광, 풍력 등 지속 가능한 에너지원을 활용하여 환경 친화적인 교통 시스템을 구현합니다.  에너지 효율을 극대화하는 설계를 통해  운영 비용을 절감하고 탄소 배출량을 최소화합니다.\n",
      "\n",
      "\n",
      "**실현 가능성:**\n",
      "\n",
      "* **단계적 접근:**  일부 구간을 우선적으로 건설하여 기술 검증 및 시스템 안정화를 거친 후 단계적으로 확장합니다.\n",
      "* **민관 합동 투자:**  정부의 적극적인 지원과 민간 투자 유치를 통해 자금을 확보합니다.\n",
      "* **국제 협력:**  해외 선진 기술과의 협력을 통해 기술 개발과 건설을 효율적으로 추진합니다.\n",
      "\n",
      "\n",
      "**기대 효과:**\n",
      "\n",
      "* 도시 간 이동 시간 획기적 단축 (서울-부산 30분 이내)\n",
      "* 교통 체증 해소 및 교통 사고 감소\n",
      "* 경제적 효과 창출 (관광, 물류 등)\n",
      "* 환경 오염 감소 및 지속 가능한 사회 구축\n",
      "\n",
      "**결론:** 하늘을 나는 도시 프로젝트는 단순한 교통 시스템 개선을 넘어, 미래 사회의 지속 가능한 발전에 기여할 혁신적인 비전입니다.  단계적인 접근과 국제적인 협력을 통해  이 야심찬 프로젝트의 성공적인 실현을 기대합니다.\n",
      "\n",
      "==================================================\n",
      "Gemini 모델 옵션\n",
      "==================================================\n",
      "• gemini-1.5-flash: 빠른 응답, 일반 작업\n",
      "• gemini-1.5-pro: 정확한 분석, 복잡한 추론\n",
      "• gemini-pro-vision: 이미지 처리 가능\n",
      "• temperature: 0.1(정확) ~ 0.9(창의적)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 창의적 생성용 높은 temperature\n",
    "llm_creative = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.9\n",
    ")\n",
    "\n",
    "creative_prompt = ChatPromptTemplate.from_template(\n",
    "    \"{topic}에 대한 창의적인 {content_type}를 {style} 스타일로 작성하세요.\"\n",
    ")\n",
    "\n",
    "creative_chain = creative_prompt | llm_creative | StrOutputParser()\n",
    "creative_result = creative_chain.invoke({\n",
    "    \"topic\": \"미래의 교통수단\",\n",
    "    \"content_type\": \"아이디어\",\n",
    "    \"style\": \"혁신적이고 실현 가능한\"\n",
    "})\n",
    "print(\"창의적 아이디어:\", creative_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Gemini 모델 옵션\")\n",
    "print(\"=\" * 50)\n",
    "print(\"• gemini-1.5-flash: 빠른 응답, 일반 작업\")\n",
    "print(\"• gemini-1.5-pro: 정확한 분석, 복잡한 추론\")\n",
    "print(\"• gemini-pro-vision: 이미지 처리 가능\")\n",
    "print(\"• temperature: 0.1(정확) ~ 0.9(창의적)\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
