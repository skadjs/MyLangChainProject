{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate \n",
    "* [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html#langchain_core.prompts.prompt.PromptTemplate)\n",
    "* [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "* [ChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatMessagePromptTemplate.html#langchain_core.prompts.chat.ChatMessagePromptTemplate)\n",
    "* [FewShotPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html#langchain_core.prompts.few_shot.FewShotPromptTemplate)\n",
    "* PartialPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_T\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) PromptTemplate ì˜ from_template() í•¨ìˆ˜ ì‚¬ìš©\n",
    "* ì£¼ë¡œ LLM(í…ìŠ¤íŠ¸ ì™„ì„±í˜• ëª¨ë¸, ex. Ollama, GPT-3.5)ê³¼ í•¨ê»˜ ì‚¬ìš©\n",
    "* í•˜ë‚˜ì˜ ë¬¸ìì—´ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eon/skRookies/myLangChain/mylangchain-app/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatGPTëŠ” ì¸í„°ë„·ì˜ ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ì—ì„œ ë‹¨ì–´ì™€ ë¬¸ì¥ì˜ ë“±ì¥ íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤.  \\n'\n",
      " 'í•™ìŠµ ê³¼ì •ì—ì„œ ì…ë ¥ëœ ë¬¸ë§¥ì— ë”°ë¼ ë‹¤ìŒì— ì˜¬ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í›ˆë ¨ë©ë‹ˆë‹¤.  \\n'\n",
      " 'ì´ëŸ¬í•œ í™•ë¥  ê¸°ë°˜ ì˜ˆì¸¡ ë°©ì‹ìœ¼ë¡œ, ìì—°ìŠ¤ëŸ½ê³  ìœ ì°½í•œ ëŒ€í™”ë¥¼ ìƒì„±í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    #model=\"openai/gpt-oss-120b\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) PromptTemplate ê²°í•©í•˜ê¸°\n",
    "* ë™ì¼í•œ Prompt íŒ¨í„´ì„ ì‚¬ìš©í•˜ì§€ë§Œ ì—¬ëŸ¬ ê°œì˜ ì§ˆë¬¸ì„ ì‘ì„±í•´ì„œ LLMì„ ì‹¤í–‰í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['count', 'language', 'model_name'] input_types={} partial_variables={} template='{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\\n\\n ê·¸ë¦¬ê³  {model_name} ëª¨ë¸ì˜ ì¥ì ì„ ìš”ì•½ ì •ë¦¬í•´ ì£¼ì„¸ìš”\\n\\n {model_name} ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ AI ëª¨ë¸ì€ ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”? ëª¨ë¸ëª…ì€ {language}ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.'\n",
      "('1. ChatGPTëŠ” ì¸í„°ë„· ê¸€ì„ ëŒ€ëŸ‰ìœ¼ë¡œ ì½ê³  ë‹¤ìŒì— ì˜¬ ë‹¨ì–´ë¥¼ ë§íˆëŠ” â€˜ì˜ˆì¸¡â€™ í›ˆë ¨ì„ ë˜í’€ì´í•´ ìŠ¤ìŠ¤ë¡œ ì–¸ì–´ ê·œì¹™ì„ ìµí™ë‹ˆë‹¤.  \\n'\n",
      " '2. ì‚¬ëŒì´ ì§ˆë¬¸-ë‹µì„ í‰ê°€í•´ ì¢‹ì€ ëŒ€ë‹µì— ì ìˆ˜ë¥¼ ì£¼ë©´, ì´ ì ìˆ˜ë¡œ ëª¨ë¸ì„ ë‹¤ì‹œ ì¡°ì •í•´ ì •ë‹µ ë°©í–¥ì„ í•™ìŠµí•©ë‹ˆë‹¤.  \\n'\n",
      " '3. ìœ„ ë‘ ê³¼ì •ì„ ê±°ë“­í•´ ëª¨ë¸ì€ ë§¥ë½ì„ íŒŒì•…í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ë§Œë“¤ì–´ë‚´ê²Œ ë©ë‹ˆë‹¤.\\n'\n",
      " '\\n'\n",
      " 'ChatGPTì˜ ì¥ì  ìš”ì•½  \\n'\n",
      " '- ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•´ ë…¼ë¦¬ì ì´ê³  ì¼ê´€ëœ ê¸€ì„ ì¦‰ì‹œ ìƒì„±  \\n'\n",
      " '- ì§ˆì˜ì˜ ë§¥ë½ì„ ê¸°ì–µí•˜ë©° ì´ì–´ì§€ëŠ” ëŒ€í™” ê°€ëŠ¥  \\n'\n",
      " '- ì½”ë“œ ì‘ì„±Â·ë²ˆì—­Â·ìš”ì•½ ë“± ë‹¤ì¬ë‹¤ëŠ¥í•˜ë©°, ì˜ì–´ëŠ” ë¬¼ë¡  í•œêµ­ì–´ ë“± ì—¬ëŸ¬ ì–¸ì–´ì— ëŠ¥ìˆ™  \\n'\n",
      " '- ì¶”ê°€ í•™ìŠµÂ·ë¯¸ì„¸ ì¡°ì •ìœ¼ë¡œ íŠ¹ì • ì—…ë¬´(ê³ ê° ì‘ëŒ€, ìë£Œ ìš”ì•½ ë“±)ì— íŠ¹í™” ê°€ëŠ¥  \\n'\n",
      " '- ëŒ€í™” í˜•íƒœë¼ ì´ˆë³´ìë„ ë³„ë„ ì½”ë”© ì—†ì´ ë°”ë¡œ í™œìš© ê°€ëŠ¥  \\n'\n",
      " '\\n'\n",
      " 'ChatGPTì™€ ë¹„ìŠ·í•œ AI ëª¨ë¸  \\n'\n",
      " 'êµ¬ê¸€ ë°”ë“œ, í´ë¡œë“œ, LLaMA, PaLM, ì½”ê·¸ë·°, ë¸”ë£¸')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# í…œí”Œë¦¿ì— ê°’ì„ ì±„ì›Œì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ì™„ì„±\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# ë¬¸ìì—´ í…œí”Œë¦¿ ê²°í•© (PromptTemplate + PromptTemplate + ë¬¸ìì—´)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n ê·¸ë¦¬ê³  {model_name} ëª¨ë¸ì˜ ì¥ì ì„ ìš”ì•½ ì •ë¦¬í•´ ì£¼ì„¸ìš”\")\n",
    "              + \"\\n\\n {model_name} ëª¨ë¸ê³¼ ë¹„ìŠ·í•œ AI ëª¨ë¸ì€ ì–´ë–¤ ê²ƒì´ ìˆë‚˜ìš”? ëª¨ë¸ëª…ì€ {language}ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"í•œêµ­ì–´\")\n",
    "print(combined_prompt)\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"í•œêµ­ì–´\"})\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PromptTemplate ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ë°°ì—´ í˜•íƒœë¡œ í•˜ì—¬ ì—¬ëŸ¬ê°œ ì‚¬ìš©í•˜ëŠ” ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 3 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.', 'Gemini ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.', 'Claude ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.']\n",
      "<class 'str'> GPT-4 ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 3 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n",
      "('GPT-4ëŠ” ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ Transformer ì‹ ê²½ë§ì„ í•™ìŠµí•©ë‹ˆë‹¤.  \\n'\n",
      " 'í•™ìŠµ ê³¼ì •ì—ì„œ ë‹¨ì–´ì˜ ìœ„ì¹˜ì™€ ë¬¸ë§¥ì„ í•¨ê»˜ ê³ ë ¤í•´ ìê¸°íšŒê·€ ë°©ì‹ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.  \\n'\n",
      " 'ì´ë ‡ê²Œ ì–»ì€ í™•ë¥  ë¶„í¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸ê°„ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ìƒì„±í•©ë‹ˆë‹¤.')\n",
      "<class 'str'> Gemini ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n",
      "('GeminiëŠ” í…ìŠ¤íŠ¸Â·ì´ë¯¸ì§€Â·ì˜¤ë””ì˜¤Â·ì½”ë“œ ë“± ë‹¤ì–‘í•œ ë°ì´í„°ë¥¼ ë™ì‹œì— ì²˜ë¦¬í•˜ëŠ” ë©€í‹°ëª¨ë‹¬ ì•„í‚¤í…ì²˜ë¡œ, Transformer ê¸°ë°˜ì˜ '\n",
      " 'ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°ë¥¼ í™•ì¥í•´ í•™ìŠµí•©ë‹ˆë‹¤.  \\n'\n",
      " 'ëŒ€ê·œëª¨ ì½”í¼ìŠ¤ì—ì„œ ë‹¤ìŒ í† í° ì˜ˆì¸¡ê³¼ ë™ì‹œì— êµì°¨ ëª¨ë‹¬ ì •ë ¬ ì‘ì—…ì„ ìˆ˜í–‰í•´ ì„œë¡œ ë‹¤ë¥¸ ë°ì´í„° ê°„ ì˜ë¯¸ë¥¼ ì •ë ¬í•©ë‹ˆë‹¤.  \\n'\n",
      " 'í•™ìŠµ ê³¼ì •ì—ì„œ ì „ë¬¸ê°€ í˜¼í•©(MoE) ê¸°ë²•ìœ¼ë¡œ ì¼ë¶€ ë„¤íŠ¸ì›Œí¬ë§Œ í™œì„±í™”í•´ ê³„ì‚° íš¨ìœ¨ì„ ë†’ì´ê³ , ê°•í™”í•™ìŠµê³¼ ì¸ê°„ í”¼ë“œë°±(RLHF)ìœ¼ë¡œ ì‘ë‹µ '\n",
      " 'í’ˆì§ˆì„ ì¶”ê°€ë¡œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.  \\n'\n",
      " 'ê²°ê³¼ì ìœ¼ë¡œ GeminiëŠ” ë‹¨ì¼ ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ ìƒì„±, ì´ë¯¸ì§€ ì´í•´, ì½”ë“œ ì‘ì„± ë“± ë‹¤ì–‘í•œ ì‘ì—…ì„ í†µí•©ì ìœ¼ë¡œ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')\n",
      "<class 'str'> Claude ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ 4 ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\n",
      "('ClaudeëŠ” ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í•™ìŠµí•´ ì–¸ì–´ì˜ í™•ë¥  ë¶„í¬ë¥¼ ìµíˆëŠ” íŠ¸ëœìŠ¤í¬ë¨¸ ê¸°ë°˜ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤.  \\n'\n",
      " 'í•™ìŠµ ë‹¨ê³„ì—ì„œëŠ” ìˆ˜ì‹­ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•´ ë‹¤ìŒ í† í°ì´ ë¬´ì—‡ì¼ì§€ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ìµœì í™”ë©ë‹ˆë‹¤.  \\n'\n",
      " 'ì¸ê°„ í”¼ë“œë°± ê°•í™”í•™ìŠµ(RLHF) ë‹¨ê³„ì—ì„œëŠ” ì‚¬ëŒì´ ì„ í˜¸í•˜ëŠ” ë‹µë³€ ìˆœìœ„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³´ìƒ ëª¨ë¸ì„ ë§Œë“¤ì–´, ëª¨ë¸ ìŠ¤ìŠ¤ë¡œ ì •ë‹µì— ê°€ê¹Œìš´ ì‘ë‹µì„ '\n",
      " 'ìƒì„±í•˜ë„ë¡ ë¯¸ì„¸ ì¡°ì •ë©ë‹ˆë‹¤.  \\n'\n",
      " 'ê²°ê³¼ì ìœ¼ë¡œ ClaudeëŠ” ë‹¨ìˆœíˆ ë‹¤ìŒ ë‹¨ì–´ë¥¼ ë§ì¶”ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì‚¬ìš©ìì˜ ì˜ë„ì— ë§ê³  ìœ ìš©í•˜ë©° ì•ˆì „í•œ ë¬¸ì¥ì„ ìƒì„±í•˜ë„ë¡ í•™ìŠµë©ë‹ˆë‹¤.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ {count} ë¬¸ì¥ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë‹µë³€í•´ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# PromptTemplate ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 3},\n",
    "    {\"model_name\": \"Gemini\", \"count\": 4},\n",
    "    {\"model_name\": \"Claude\", \"count\": 4}\n",
    "]\n",
    "\n",
    "# ì—¬ëŸ¬ ê°œì˜ í”„ë¡¬í”„íŠ¸ë¥¼ ë¯¸ë¦¬ ìƒì„±\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions] #íŒŒì´ì¬ì—ì„œ íŒŒë¼ë¯¸í„°ë¡œ ë”•ì…”ë„ˆë¦¬ ë°›ì„ ë•Œ ì•„ìŠ¤íƒ€(*) 2ê°œ ì”€\n",
    "print(formatted_prompts)  # ë¯¸ë¦¬ ìƒì„±ëœ ì§ˆë¬¸ ëª©ë¡ í™•ì¸\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    print(type(prompt), prompt)\n",
    "    response = llm.invoke(prompt)\n",
    "    pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) ChatPromptTemplate\n",
    "* Tuple í˜•íƒœì˜ system, user, assistant ë©”ì‹œì§€ ì§€ì›\n",
    "* ì—¬ëŸ¬ ê°œì˜ ë©”ì‹œì§€ë¥¼ ì¡°í•©í•˜ì—¬ LLMì—ê²Œ ì „ë‹¬ ê°€ëŠ¥\n",
    "* ê°„ê²°ì„±ê³¼ ê°€ë…ì„±ì´ ë†’ê³  ë‹¨ìˆœí•œ êµ¬ì¡°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='This system is an expert in answering questions about AI. Please provide clear and detailed explanations.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ChatGPT ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”.', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "ChatGPTëŠ” â€œGPT(Generative Pre-trained Transformer)â€ ê³„ì—´ì˜ ì–¸ì–´ ëª¨ë¸ë¡œ,  \n",
      "â€œê±°ëŒ€í•œ í…ìŠ¤íŠ¸ë¥¼ ë³´ê³  ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµí•œ ë’¤, ì‚¬ëŒì´ ì¢‹ì•„í•  í–‰ë™ì„ ìµœëŒ€í™”í•˜ë„ë¡ ë¯¸ì„¸ ì¡°ì •í–ˆë‹¤â€ëŠ” í•œ ì¤„ ìš”ì•½ì„ í’€ì–´ ì“´ ê²ƒì´ ì „ì²´ í•™ìŠµ ì›ë¦¬ì…ë‹ˆë‹¤. ì•„ë˜ì— ë‹¨ê³„ë³„ë¡œ, ìˆ˜ì‹Â·ì½”ë“œ ì—†ì´ í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜ì„ ì„¤ëª…í•©ë‹ˆë‹¤.\n",
      "\n",
      "-------------------------------------------------\n",
      "1. ë‘ ë‹¨ê³„ íŒŒì´í”„ë¼ì¸\n",
      "1) Pre-training(ì‚¬ì „ í•™ìŠµ)  \n",
      "2) RLHF ë¯¸ì„¸ ì¡°ì •(í›„ì† í•™ìŠµ)  \n",
      "ë‘ ë‹¨ê³„ê°€ ëª¨ë‘ ëë‚˜ì•¼ â€˜ì±„íŒ…ì²˜ëŸ¼ ë§ì„ ì‡ëŠ”â€™ ChatGPTê°€ ë©ë‹ˆë‹¤.\n",
      "\n",
      "-------------------------------------------------\n",
      "2. ì‚¬ì „ í•™ìŠµ(Pre-training) ë‹¨ê³„\n",
      "ëª©í‘œ  \n",
      "â€œì£¼ì–´ì§„ ì• ë¬¸ì¥ì„ ë³´ê³ , ë‹¤ìŒì— ë‚˜ì˜¬ ë‹¨ì–´ì˜ í™•ë¥  ë¶„í¬ë¥¼ ë§ì¶°ë¼.â€  \n",
      "ì¦‰, â€˜ìì—°ì–´ë¥¼ ì••ì¶•í•´ì„œ ë‚´ë¶€ íŒŒë¼ë¯¸í„°ì— ì €ì¥í•˜ë¼â€™ëŠ” ëœ»ì…ë‹ˆë‹¤.\n",
      "\n",
      "ë°ì´í„°  \n",
      "ì›¹, ìœ„í‚¤, ì±… ë“± 1ì¡° í† í°(ë‹¨ì–´Â·ë¶€ë¶„ ë‹¨ì–´) ì´ìƒ.\n",
      "\n",
      "ëª¨ë¸ êµ¬ì¡°  \n",
      "íŠ¸ëœìŠ¤í¬ë¨¸ ë””ì½”ë”(Transformer decoder) ë¸”ë¡ 96ê°œ, 1750ì–µ ê°œ ê°€ì¤‘ì¹˜.  \n",
      "Self-attentionì´ ë¬¸ë§¥ ì•ˆì˜ ëª¨ë“  í† í° ê°„ ê´€ê³„ë¥¼ í•œ ë²ˆì— ê³„ì‚°í•´ â€˜ê¸€ë¡œë²Œ ë§¥ë½â€™ì„ ì¡ìŠµë‹ˆë‹¤.\n",
      "\n",
      "í•™ìŠµ ë°©ë²•  \n",
      "1) ëœë¤ ì´ˆê¸°í™” â†’ 2) ë‹¤ìŒ í† í° ì˜ˆì¸¡ â†’ 3) ì˜¤ì°¨ ì—­ì „íŒŒ â†’ 4) íŒŒë¼ë¯¸í„° ê°±ì‹ .  \n",
      "ì´ ê³¼ì •ì„ ìˆ˜ì²­ë§Œ ë²ˆ ë°˜ë³µí•˜ë©´ì„œ, ëª¨ë¸ì€ ì‚¬ì‹¤Â·ì¶”ë¡ Â·ë¬¸ë²•Â·ì„¸ê³„ ì§€ì‹ì„ í†µê³„ì ìœ¼ë¡œ íšë“í•©ë‹ˆë‹¤.\n",
      "\n",
      "ê²°ê³¼  \n",
      "â€˜ê¸°ë³¸(Base) ëª¨ë¸â€™ì´ ìƒê¹€.  \n",
      "íŠ¹ì§•:  \n",
      "- ê¸´ ê¸€ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì‡ì§€ë§Œ, ì§€ì‹œì‚¬í•­(Instruction)ì„ ë”°ë¥´ëŠ” ëŠ¥ë ¥ì€ ë–¨ì–´ì§.  \n",
      "- ìœ í•´Â·í¸í–¥Â·í™€ë£¨ì‹œë„¤ì´ì…˜(í—ˆìœ„ ìƒì„±) ê°€ëŠ¥ì„±ì´ ìˆìŒ.\n",
      "\n",
      "-------------------------------------------------\n",
      "3. ì§€ì‹œ í•™ìŠµ(Supervised Fine-Tuning, SFT) ë‹¨ê³„\n",
      "ë°ì´í„°  \n",
      "â€˜ì§ˆë¬¸-ë‹µâ€™, â€˜ì§€ì‹œ-ì‘ë‹µâ€™ í˜•íƒœì˜ ëŒ€í™” ìŒ 1~2ë§Œ ê±´(í’ˆì§ˆ ë†’ì€ ì¸ê°„ ì‘ì„±).\n",
      "\n",
      "ëª©í‘œ  \n",
      "â€œì§€ì‹œí˜• í”„ë¡¬í”„íŠ¸ë¥¼ ë°›ìœ¼ë©´, ì‚¬ëŒì´ ì“´ â€˜ì¢‹ì€â€™ ì‘ë‹µì„ ê·¸ëŒ€ë¡œ ìƒì„±í•˜ë„ë¡ í•˜ë¼.â€  \n",
      "ì¦‰, ë‹¤ìŒ í† í° ì˜ˆì¸¡ ì†ì‹¤ì„ ì¤„ì´ë˜, ë°ì´í„° ë¶„í¬ë¥¼ â€˜ì§€ì‹œâ†’ì‘ë‹µâ€™ì— ë§ì¶¤.\n",
      "\n",
      "ê²°ê³¼  \n",
      "ì§€ì‹œë¥¼ ë”°ë¥´ëŠ” â€˜SFT ëª¨ë¸â€™ì´ ìƒê¹€.  \n",
      "ê·¸ëŸ¬ë‚˜ ì—¬ì „íˆ â€˜ê±°ë¶€í•´ì•¼ í•  ë¶€ì ì ˆí•œ ìš”ì²­â€™ì„ ê±°ì ˆí•˜ì§€ ëª»í•˜ê±°ë‚˜, ì§€ë‚˜ì¹˜ê²Œ ê¸¸ê²Œ ëŠ˜ì–´ì§€ëŠ” ë“±ì˜ ë¬¸ì œê°€ ë‚¨ìŒ.\n",
      "\n",
      "-------------------------------------------------\n",
      "4. RLHF ë¯¸ì„¸ ì¡°ì •(ê°•í™”í•™ìŠµ ê¸°ë°˜ ì¸ê°„ í”¼ë“œë°±)\n",
      "í•µì‹¬ ì•„ì´ë””ì–´  \n",
      "â€œì‚¬ëŒì´ ì„ í˜¸í•˜ëŠ” ì‘ë‹µ ìˆœìœ„ë¥¼ ë³´ê³  ë³´ìƒ(reward)ì„ ë§Œë“¤ì–´, ì´ ë³´ìƒì„ ìµœëŒ€í™”í•˜ëŠ” ì •ì±…ì„ ê°•í™”í•™ìŠµìœ¼ë¡œ ì°¾ëŠ”ë‹¤.â€\n",
      "\n",
      "4-1. ë³´ìƒ ëª¨ë¸(Reward Model, RM) ë§Œë“¤ê¸°  \n",
      "- ê°™ì€ í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ 4~9ê°œì˜ ì„œë¡œ ë‹¤ë¥¸ SFT ëª¨ë¸ ì‘ë‹µì„ ì‚¬ëŒì´ 1~5ì  ë˜ëŠ” ìƒëŒ€ ìˆœìœ„ë¡œ í‰ê°€.  \n",
      "- (í”„ë¡¬í”„íŠ¸, ì‘ë‹µ1, ì‘ë‹µ2) + â€˜ì‚¬ëŒì´ ì‘ë‹µ1ì´ ë” ë‚«ë‹¤â€™ëŠ” ë ˆì´ë¸” â†’ RMì´ â€˜ì‘ë‹µì´ ì–¼ë§ˆë‚˜ ì¢‹ì€ê°€â€™ë¥¼ íšŒê·€í•˜ë„ë¡ í•™ìŠµ.  \n",
      "- RMì€ 6B ê·œëª¨ì˜ íŠ¸ëœìŠ¤í¬ë¨¸ë¡œ, â€˜ì‘ë‹µ ì „ì²´â€™ë¥¼ ë°›ì•„ ë‹¨ì¼ ìŠ¤ì¹¼ë¼ ë³´ìƒê°’ì„ ì¶œë ¥.\n",
      "\n",
      "4-2. ì •ì±… ìµœì í™”(PPO)  \n",
      "- SFT ëª¨ë¸ì„ â€˜ì •ì±…(policy)â€™ìœ¼ë¡œ ë³¸ë‹¤.  \n",
      "- ì´ ì •ì±…ì´ ìƒì„±í•œ ì‘ë‹µì— ëŒ€í•´ RMì´ ë³´ìƒ rì„ ì¤Œ.  \n",
      "- PPO(Proximal Policy Optimization) ì•Œê³ ë¦¬ì¦˜ì´ â€˜ë³´ìƒ râ€™ì„ ë†’ì´ë©´ì„œë„ â€˜SFT ëª¨ë¸ê³¼ ë„ˆë¬´ ë©€ë¦¬ ê°€ì§€ ì•Šë„ë¡(KL í˜ë„í‹°)â€™ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸.  \n",
      "- ìˆ˜ì²œë§Œ ê±´ì˜ í”„ë¡¬í”„íŠ¸Â·ì‘ë‹µ ìŒìœ¼ë¡œ ë°˜ë³µ.\n",
      "\n",
      "ë³´ì™„ ê¸°ë²•  \n",
      "- â€˜ë³´ìƒ í•´í‚¹â€™ ë°©ì§€: RM ì¶œë ¥ clipping, KL í˜ë„í‹°, adversarial í”„ë¡¬í”„íŠ¸ ì¬í•™ìŠµ.  \n",
      "- Rejection Sampling: ìƒì„±í•œ í›„ ë³´ìƒ ë‚®ìœ¼ë©´ íê¸°, ë†’ì€ ê²ƒë§Œ íŒŒì¸íŠœë‹ì— ì¬ì‚¬ìš©.\n",
      "\n",
      "ê²°ê³¼  \n",
      "â€˜RLHF ëª¨ë¸â€™ì´ ìƒê¹€.  \n",
      "íŠ¹ì§•:  \n",
      "- ìœ í•´Â·í¸í–¥ ì‘ë‹µ í™•ë¥  â†“  \n",
      "- ì§€ì‹œ ì •í•©ì„± â†‘  \n",
      "- ê°„ê²°Â·ì¹œí™”ì  í†¤ â†‘  \n",
      "- í—ˆìœ„ ì •ë³´ëŠ” ì—¬ì „íˆ ìƒì„± ê°€ëŠ¥(í™€ë£¨ì‹œë„¤ì´ì…˜ ë¬¸ì œëŠ” ë‚¨ìŒ).\n",
      "\n",
      "-------------------------------------------------\n",
      "5. ì¶”ë¡ (ì¸í¼ëŸ°ìŠ¤) ë‹¨ê³„\n",
      "1) ì‚¬ìš©ì ì…ë ¥ í† í°í™”  \n",
      "2) íŠ¸ëœìŠ¤í¬ë¨¸ ë””ì½”ë” ìˆœíšŒ  \n",
      "3) Softmax í™•ë¥ ë¡œ ë‹¤ìŒ í† í° ìƒ˜í”Œë§(ì˜¨ë„Â·top-pÂ·top-k ì¡°ì ˆ)  \n",
      "4) ã€ˆendã€‰ í† í° ë‚˜ì˜¬ ë•Œê¹Œì§€ ë°˜ë³µ  \n",
      "5) í† í°â†’ë¬¸ìì—´ ë³µì› í›„ ì‚¬ìš©ìì—ê²Œ ë°˜í™˜\n",
      "\n",
      "-------------------------------------------------\n",
      "6. í•µì‹¬ ìš”ì•½\n",
      "1. ë‹¤ìŒ ë‹¨ì–´ ì˜ˆì¸¡(ì‚¬ì „ í•™ìŠµ) â†’ ì„¸ê³„ ì§€ì‹ê³¼ ì–¸ì–´ ë¬¸ë²•ì„ ë‚´ì¬í™”.  \n",
      "2. ì§€ì‹œ-ì‘ë‹µ ìŒ í•™ìŠµ(SFT) â†’ ì§€ì‹œ ë”°ë¥´ê¸° ëŠ¥ë ¥ ë¶€ì—¬.  \n",
      "3. ì¸ê°„ í”¼ë“œë°± ê¸°ë°˜ ê°•í™”í•™ìŠµ(RLHF) â†’ ì¸ê°„ ê¸°í˜¸ì— ë§ëŠ” ì•ˆì „Â·ìœ ìš©ì„± í™•ë³´.  \n",
      "\n",
      "ë°”ë¡œ ì´ 3ë‹¨ ì¡°í•©ì´ â€˜ê·¸ëƒ¥ ê¸€ ì‡ê¸°â€™ì—ì„œ â€˜ì‚¬ëŒì´ í¸ë¦¬í•˜ê²Œ ì“°ëŠ” ì±—ë´‡â€™ìœ¼ë¡œ ë³€ì‹ í•˜ëŠ” ChatGPT í•™ìŠµ ì›ë¦¬ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# 2-íŠœí”Œ í˜•íƒœì˜ ë©”ì‹œì§€ ëª©ë¡ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„± (type, content)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    # role, message\n",
    "    (\"system\", \"This system is an expert in answering questions about {topic}. Please provide clear and detailed explanations.\"),\n",
    "    (\"human\", \"{model_name} ëª¨ë¸ì˜ í•™ìŠµ ì›ë¦¬ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\"),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", model_name=\"ChatGPT\")\n",
    "print(messages)\n",
    "\n",
    "# ìƒì„±í•œ ë©”ì‹œì§€ë¥¼ ë°”ë¡œ ì£¼ì…í•˜ì—¬ í˜¸ì¶œí•˜ê¸°\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "ChatGPTëŠ” â€œGPTâ€ ê³„ì—´ ëª¨ë¸ì˜ ëŒ€í™” íŠ¹í™”íŒì´ë¯€ë¡œ, GPTê°€ ì–´ë–»ê²Œ í•™ìŠµí•˜ëŠ”ì§€ë¥¼ ë¨¼ì € ì´í•´í•´ì•¼ í•©ë‹ˆë‹¤. GPT-3.5Â·GPT-4 ê°™ì€ ëª¨ë¸ì€ 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë§Œë“¤ì–´ì§‘ë‹ˆë‹¤.\n",
      "\n",
      "1ë‹¨ê³„: Pre-training (ì‚¬ì „í•™ìŠµ)  \n",
      "2ë‹¨ê³„: Supervised Fine-tuning (SFT, ì§€ë„ ë¯¸ì„¸ì¡°ì •)  \n",
      "3ë‹¨ê³„: Reinforcement Learning with Human Feedback (RLHF, ì¸ê°„ í”¼ë“œë°± ê¸°ë°˜ ê°•í™”í•™ìŠµ)\n",
      "\n",
      "ì•„ë˜ì— ê° ë‹¨ê³„ì—ì„œ ì–´ë–¤ ë°ì´í„°Â·ëª©ì í•¨ìˆ˜Â·ì•Œê³ ë¦¬ì¦˜ì´ ì“°ì´ëŠ”ì§€, ê·¸ë¦¬ê³  ì™œ â€œëŒ€í™”â€ê°€ ê°€ëŠ¥í•´ì§€ëŠ”ì§€ë¥¼ ìˆ˜ì‹ê³¼ í•¨ê»˜ ì„¤ëª…í•©ë‹ˆë‹¤.\n",
      "\n",
      "-------------------------------------------------\n",
      "1. Pre-training: â€œì¸í„°ë„· ê¸€ì„ ì½ìœ¼ë©° ë‹¤ìŒ í† í° ì˜ˆì¸¡í•˜ê¸°â€\n",
      "-------------------------------------------------\n",
      "ëª©í‘œ  \n",
      "ìµœëŒ€í•œ ë§ì€ í…ìŠ¤íŠ¸ì—ì„œ í†µê³„ì  íŒ¨í„´ì„ í¬ì°©í•´ â€œì£¼ì–´ì§„ ì• í† í° ì‹œí€€ìŠ¤ xâ‚â€¦xâ‚œê°€ ìˆì„ ë•Œ, ë‹¤ìŒ í† í° xâ‚œâ‚Šâ‚ì˜ í™•ë¥ â€ì„ ì •í™•íˆ ì¶”ì •í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "ëª¨ë¸ êµ¬ì¡°  \n",
      "- Transformer ë””ì½”ë”(ë§ˆìŠ¤í¬ë“œ ì…€í”„ì–´í…ì…˜)  \n",
      "- ì…ë ¥ ì„ë² ë”© + ìœ„ì¹˜ ì„ë² ë”©  \n",
      "- Lê°œì˜ íŠ¸ëœìŠ¤í¬ë¨¸ ë¸”ë¡ â†’ ìµœì¢… ì€ë‹‰ ìƒíƒœ h_L  \n",
      "- ì–¸ì–´ ëª¨ë¸ í—¤ë“œ: PÎ¸(xâ‚œâ‚Šâ‚|xâ‰¤â‚œ) = softmax(WÂ·h_L)\n",
      "\n",
      "í•™ìŠµ ëª©ì í•¨ìˆ˜  \n",
      "L(Î¸) = â€“ Î£_{t=1}^{T} log PÎ¸(xâ‚œ | xâ‚â€¦xâ‚œâ‚‹â‚)  \n",
      "ì¦‰, ì „ì²´ ì‹œí€€ìŠ¤ì— ëŒ€í•œ ìŒì˜ ë¡œê·¸ ìš°ë„ë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤.\n",
      "\n",
      "ë°ì´í„°  \n",
      "ì›¹í˜ì´ì§€, ì±…, ìœ„í‚¤í”¼ë””ì•„, GitHub ì½”ë“œ ë“± ìˆ˜ì²œì–µ í† í°.  \n",
      "GPT-3.5ëŠ” 300B í† í°, GPT-4ëŠ” ì•„ì§ ê³µê°œë˜ì§€ ì•Šì•˜ì§€ë§Œ ê·¸ ì´ìƒìœ¼ë¡œ ì¶”ì •ë©ë‹ˆë‹¤.\n",
      "\n",
      "ê²°ê³¼  \n",
      "ì´ ì‹œì ì—ì„œ ëª¨ë¸ì€ â€œê¸€ì“°ê¸° ìŠ¤íƒ€ì¼â€ì€ ì˜ í‰ë‚´ ë‚´ì§€ë§Œ, ì§ˆë¬¸-ë‹µ í˜•ì‹ì€ ê±°ì˜ ì—†ê³ , ì•ˆì „ì„±/ìœ ìš©ì„±ë„ ë‚®ìŠµë‹ˆë‹¤.\n",
      "\n",
      "-------------------------------------------------\n",
      "2. Supervised Fine-tuning (SFT): â€œì§€ì‹œë¬¸-ì‘ë‹µ ìŒì„ ê·¸ëŒ€ë¡œ ë³µì œâ€\n",
      "-------------------------------------------------\n",
      "ëª©í‘œ  \n",
      "ëŒ€í™” í˜•ì‹ì„ ì£¼ì…í•˜ê³ , ì§€ì‹œ(Instruction)ë¥¼ ë”°ë¥´ëŠ” ëŠ¥ë ¥ì„ ê¸¸ëŸ¬ ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "ë°ì´í„°  \n",
      "ìˆ˜ì‹­ë§Œ~ìˆ˜ë°±ë§Œ ê°œì˜ (ì§€ì‹œë¬¸, ì´ìƒì  ì‘ë‹µ) ìŒ.  \n",
      "ì˜ˆ:  \n",
      "ì§€ì‹œ: â€œë‹¤ìŒ ë¬¸ì¥ì„ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ë¼.â€  \n",
      "ì‘ë‹µ: â€œTranslate this sentence into Korean.â€\n",
      "\n",
      "í•™ìŠµ ë°©ì‹  \n",
      "Pre-trained ê°€ì¤‘ì¹˜ Î¸â‚€ë¥¼ ì´ˆê¸°ê°’ìœ¼ë¡œ, ë™ì¼í•œ ìµœëŒ€ìš°ë„(MLM) ì†ì‹¤ë¡œ ë¯¸ì„¸ì¡°ì •í•©ë‹ˆë‹¤.  \n",
      "L_SFT(Î¸) = â€“ Î£ log PÎ¸(y|x)  \n",
      "x=ì§€ì‹œë¬¸, y=ì •ë‹µ(ì‘ë‹µ)\n",
      "\n",
      "ê²°ê³¼  \n",
      "ì§€ì‹œë¥¼ ë”°ë¥´ëŠ” ëª¨ìŠµì´ ë‚˜ì˜¤ì§€ë§Œ, ì—¬ì „íˆ â€œì˜ëª»ëœ ì •ë³´â€, â€œìœ í•´í•œ ë§â€, â€œê±°ì ˆ ëª»í•¨â€ ê°™ì€ ë¬¸ì œê°€ ë‚¨ìŠµë‹ˆë‹¤.\n",
      "\n",
      "-------------------------------------------------\n",
      "3. RLHF: â€œì¸ê°„ì˜ ì„ í˜¸ë„ë¥¼ ë³´ìƒìœ¼ë¡œ ì‚¼ì•„ ì •ì±… ìµœì í™”â€\n",
      "-------------------------------------------------\n",
      "3-1. ë³´ìƒ ëª¨ë¸(RM) ë§Œë“¤ê¸°  \n",
      "- ë™ì¼í•œ ì§€ì‹œë¬¸ xì— ëŒ€í•´ ëª¨ë¸ì´ ìƒì„±í•œ 4~9ê°œì˜ ì‘ë‹µ ìŒ(yáµ¢, yâ±¼)ì„ ì¸ê°„ì´ â€œì–´ëŠ ìª½ì´ ë” ë‚˜ì€ê°€?â€ë¡œ ë¹„êµ.  \n",
      "- ì´ pairwise ë°ì´í„°ë¡œ Bradley-Terry ëª¨ë¸ì„ í•™ìŠµí•´ scalar ë³´ìƒ r_Ï•(x,y)ë¥¼ ë§Œë“­ë‹ˆë‹¤.  \n",
      "  L_RM = â€“ log Ïƒ(r_Ï•(x,y_w) â€“ r_Ï•(x,y_l))\n",
      "\n",
      "3-2. ê°•í™”í•™ìŠµ ë‹¨ê³„  \n",
      "- ì •ì±… Ï€_RL: SFT ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì´ˆê¸°ê°’ìœ¼ë¡œ.  \n",
      "- ëª©ì í•¨ìˆ˜(Proximal Policy Optimization, PPO):  \n",
      "  L_PPO = ğ”¼[min(râ‚œÂ·Ã‚â‚œ, clip(râ‚œ,1Â±Îµ)Â·Ã‚â‚œ)] â€“ Î²Â·KL(Ï€_RL||Ï€_SFT)  \n",
      "  râ‚œ = Ï€_RL(y|x) / Ï€_SFT(y|x) (importance weight)  \n",
      "  Ã‚â‚œ: advantage = r_Ï•(x,y) â€“ V(x) (critic ë„¤íŠ¸ì›Œí¬ë¡œ baseline ì¶”ì •)  \n",
      "  KL íŒ¨ë„í‹°ëŠ” â€œSFT ëª¨ë¸ê³¼ ë„ˆë¬´ ë©€ì–´ì§€ì§€ ë§ë¼â€ëŠ” ì œì•½.\n",
      "\n",
      "ê²°ê³¼  \n",
      "í—ˆìœ„ ì •ë³´ ì¤„ì´ê¸°, ê±°ì ˆ ëŠ¥ë ¥ í–¥ìƒ, ìœ í•´ ì‘ë‹µ ê°ì†Œ, ì¸ê°„ ì„ í˜¸ë„ â†‘\n",
      "\n",
      "-------------------------------------------------\n",
      "4. ì¶”ë¡ (ì¸í¼ëŸ°ìŠ¤) ë‹¨ê³„\n",
      "-------------------------------------------------\n",
      "ì£¼ì–´ì§„ ëŒ€í™” ê¸°ë¡ì„ í† í° ì‹œí€€ìŠ¤ë¡œ ë³€í™˜ â†’  \n",
      "Transformerê°€ í•œ í† í°ì”© í™•ë¥  ë¶„ì‚° ì¶œë ¥ â†’  \n",
      "temperatureÂ·top-p ìƒ˜í”Œë§ìœ¼ë¡œ ë‹¤ìŒ í† í° ì„ íƒ â†’  \n",
      "ë°˜ë³µí•˜ì—¬ ì¢…ë£Œ í† í° ë‚˜ì˜¬ ë•Œê¹Œì§€ ìƒì„±.\n",
      "\n",
      "-------------------------------------------------\n",
      "ì™œ â€œëŒ€í™”â€ê°€ ë˜ëŠ”ê°€?\n",
      "-------------------------------------------------\n",
      "1. í•™ìŠµ ë°ì´í„°ì— â€œHuman: â€¦ Assistant: â€¦â€ í˜•ì‹ì´ SFT/RLHFì— í¬í•¨ë¼ ìˆì–´ì„œ í”„ë¡¬í”„íŠ¸ë§Œ ì´ë ‡ê²Œ ì£¼ë©´ â€œëŒ€í™”â€ì²˜ëŸ¼ ì‘ë™.  \n",
      "2. RLHFì—ì„œ ì¸ê°„ì€ â€˜ì •ë³´ê°€ í‹€ë¦¬ì§€ ì•Šê³ , ê°„ê²°í•˜ê³ , ì˜ˆì˜ ë°”ë¥´ê³ , ê±°ì ˆí•  ì¤„ ì•„ëŠ”â€™ ì‘ë‹µì— ë†’ì€ ì ìˆ˜ë¥¼ ì£¼ë¯€ë¡œ, ê·¸ëŸ° ì„±í–¥ì´ ì •ì±…ì— ë…¹ì•„ë“¦.  \n",
      "3. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸(â€œYou are a helpful assistantâ€¦â€)ë¥¼ ì•ì— ë¶™ì—¬ë‘ë©´, ëª¨ë¸ì€ ì´ ë§¥ë½ì„ ê³„ì† ìœ ì§€í•˜ë©´ì„œ ìƒì„±.\n",
      "\n",
      "-------------------------------------------------\n",
      "ì •ë¦¬\n",
      "-------------------------------------------------\n",
      "ChatGPT =  \n",
      "(1) ëŒ€ê·œëª¨ ì½”í¼ìŠ¤ë¡œ ë‹¤ìŒ í† í° ì˜ˆì¸¡ì„ í•™ìŠµí•œ íŠ¸ëœìŠ¤í¬ë¨¸  \n",
      "(2) ì§€ì‹œ-ì‘ë‹µ ìŒìœ¼ë¡œ ë¯¸ì„¸ì¡°ì •  \n",
      "(3) ì¸ê°„ì˜ ì„ í˜¸ ë¹„êµ ë°ì´í„°ë¡œ í•™ìŠµí•œ ë³´ìƒ ëª¨ë¸ì„ ì´ìš©í•œ PPO ê°•í™”í•™ìŠµ  \n",
      "\n",
      "ì´ 3ë‹¨ê³„ë¥¼ ê±°ì¹˜ë©´ â€œëŒ€í™”ë¥¼ í•˜ë©° ì§€ì‹œë¥¼ ë”°ë¥´ê³ , ìœ í•´ì„±ì€ ì¤„ì´ê³ , ìœ ìš©ì„±ì€ ë†’ì¸â€ ìƒì„± ëª¨ë¸ì´ ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ì„ ìƒì„±í•˜ì—¬ í˜¸ì¶œí•˜ê¸°\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"topic\":\"AI\", \"model_name\":\"ChatGPT\"})\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) ChatPromptTemplate\n",
    "* SystemMessagePromptTemplateì™€ HumanMessagePromptTemplate í´ë˜ìŠ¤ ì‚¬ìš©\n",
    "* ê°ì²´ ì§€í–¥ì  ì ‘ê·¼ - Message ê°ì²´ë¥¼ ë…ë¦½ì ìœ¼ë¡œ ìƒì„± ê°€ëŠ¥\n",
    "* ì—¬ëŸ¬ ì¡°ê±´ì— ë”°ë¼ ë‹¤ë¥¸ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì„ íƒ\n",
    "\n",
    "```python\n",
    "if user_is_beginner:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"ì´ˆë³´ìë¥¼ ìœ„í•œ ì„¤ëª…: {topic}\")\n",
    "else:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"ì „ë¬¸ê°€ë¥¼ ìœ„í•œ ìƒì„¸ ë¶„ì„: {topic}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ChatMessagePromptTemplate í™œìš©\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ê°œë³„ ë©”ì‹œì§€ í…œí”Œë¦¿ ì •ì˜\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI expert in {topic}. Please provide clear and detailed explanations.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplateë¡œ ë©”ì‹œì§€ë“¤ì„ ë¬¶ê¸°\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# ë©”ì‹œì§€ ìƒì„±\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"What is deep learning?\")\n",
    "\n",
    "# LLM í˜¸ì¶œ\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatMessagePromptTemplateëŠ” ì—¬ëŸ¬ ì¢…ë¥˜ì˜ ë©”ì‹œì§€(ì‹œìŠ¤í…œ, ì¸ê°„, AI)ë¥¼ ì¡°í•©í•˜ì—¬ ë³µì¡í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n",
    "* SystemMessagePromptTemplate: ì´ í…œí”Œë¦¿ì€ AI ëª¨ë¸ì—ê²Œ ì—­í• ì„ ë¶€ì—¬í•˜ê±°ë‚˜ ì „ë°˜ì ì¸ ê·œì¹™ì„ ì„¤ì •í•˜ëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ ë§Œë“­ë‹ˆë‹¤. ìœ„ì˜ ì˜ˆì‹œì—ì„œëŠ” \"ë²ˆì—­ì„ ë„ì™€ì£¼ëŠ” ìœ ìš©í•œ ë„ìš°ë¯¸\"ë¼ëŠ” ì—­í• ì„ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "* HumanMessagePromptTemplate: ì´ í…œí”Œë¦¿ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ë‚˜ ìš”ì²­ì„ ë‹´ëŠ” ì¸ê°„ ë©”ì‹œì§€ë¥¼ ë§Œë“­ë‹ˆë‹¤. ì•„ë˜ì˜ ì˜ˆì‹œì—ì„œëŠ” ë²ˆì—­í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ìŠµë‹ˆë‹¤.\n",
    "* ChatPromptTemplate.from_messages: ì´ í´ë˜ìŠ¤ ë©”ì„œë“œëŠ” ì‹œìŠ¤í…œ ë©”ì‹œì§€, ì¸ê°„ ë©”ì‹œì§€ ë“± ì—¬ëŸ¬ ì¢…ë¥˜ì˜ MessagePromptTemplate ê°ì²´ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ì•„ í•˜ë‚˜ì˜ ì±„íŒ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ìœ¼ë¡œ í†µí•©í•©ë‹ˆë‹¤.\n",
    "* format_messages: ì´ ë©”ì„œë“œëŠ” ì •ì˜ëœ í…œí”Œë¦¿ì— ì‹¤ì œ ê°’ì„ ì±„ì›Œ ë„£ì–´ [SystemMessage, HumanMessage] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ì´ ë¦¬ìŠ¤íŠ¸ëŠ” ì±„íŒ… ëª¨ë¸(Chat Model) ì— ë°”ë¡œ ì „ë‹¬ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant that translates English to Korean.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I love programming.', additional_kwargs={}, response_metadata={})]\n",
      "ë‚˜ëŠ” í”„ë¡œê·¸ë˜ë°ì„ ì‚¬ë‘í•´ìš”.\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 1. SystemMessagePromptTemplateì™€ HumanMessagePromptTemplate ìƒì„±\n",
    "# SystemMessagePromptTemplateëŠ” ëª¨ë¸ì˜ í˜ë¥´ì†Œë‚˜ ë˜ëŠ” ê¸°ë³¸ ì§€ì¹¨ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "system_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# HumanMessagePromptTemplateëŠ” ì‚¬ìš©ìë¡œë¶€í„° ë°›ëŠ” ì…ë ¥ í”„ë¡¬í”„íŠ¸ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "human_template = \"{text_to_translate}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 2. ChatPromptTemplate ìƒì„±\n",
    "# ìœ„ì—ì„œ ë§Œë“  ë‘ í…œí”Œë¦¿ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë¬¶ì–´ ChatPromptTemplateì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# 3. í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ…\n",
    "# chat_prompt_template.format_messages()ë¥¼ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "# ì´ í•¨ìˆ˜ëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœì˜ ì…ë ¥ ë³€ìˆ˜ë¥¼ ë°›ìŠµë‹ˆë‹¤.\n",
    "formatted_prompt = chat_prompt_template.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Korean\",\n",
    "    text_to_translate=\"I love programming.\"\n",
    ")\n",
    "\n",
    "# 4. ê²°ê³¼ ì¶œë ¥\n",
    "print(formatted_prompt)\n",
    "\n",
    "# LLM í˜¸ì¶œ\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) FewShotPromptTemplate\n",
    "* FewShotPromptTemplateì€ ëª¨ë¸ì´ íŠ¹ì • í˜•ì‹ì„ ë”°ë¥´ê²Œ í•˜ê±°ë‚˜, ì¼ê´€ëœ ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ ìœ ë„í•  ë•Œ ìœ ìš©í•©ë‹ˆë‹¤.\n",
    "* ë„ë©”ì¸ ì§€ì‹ì´ í•„ìš”í•˜ê±°ë‚˜, AIê°€ ì˜¤ë‹µì„ ì¤„ì´ê³  ë” ì‹ ë¢°í•  ë§Œí•œ ë‹µë³€ì„ ìƒì„±í•˜ë„ë¡ í•´ì•¼ í•  ë•Œ íš¨ê³¼ì ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1) PromptTemplateì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "íƒœì–‘ê³„ í–‰ì„±(íƒœì–‘ì—ì„œë¶€í„°ì˜ ìˆœì„œ)\n",
      "\n",
      "1. ìˆ˜ì„±(Mercury) â€“ ê°€ì¥ ì‘ê³ , ê°€ê¹Œìš°ë©°, í‘œë©´ ì˜¨ë„ ë³€í™”ê°€ ê·¹ì‹¬  \n",
      "2. ê¸ˆì„±(Venus) â€“ ë‘êº¼ìš´ ì´ì‚°í™”íƒ„ì†Œ ëŒ€ê¸°, ì§€ë¦„Â·ì§ˆëŸ‰ì€ ì§€êµ¬ì™€ ë¹„ìŠ·í•˜ì§€ë§Œ í‘œë©´ 460 Â°C  \n",
      "3. ì§€êµ¬(Earth) â€“ ìœ ì¼í•œ ì•¡ì²´ í•´ì–‘ê³¼ ìƒëª…ì²´ ë³´ìœ   \n",
      "4. í™”ì„±(Mars) â€“ ë¶‰ì€ ì‚¬ë§‰Â·ê·¹å† , ì–‡ì€ ëŒ€ê¸°, íƒì‚¬ ë¡œë´‡ ìƒì£¼  \n",
      "5. ëª©ì„±(Jupiter) â€“ íƒœì–‘ê³„ ìµœëŒ€ ê¸°ì²´ í–‰ì„±, ëŒ€ì ì Â·79ê°œ ì´ìƒ ìœ„ì„±(ê°€ë‹ˆë©”ë° ë“±)  \n",
      "6. í† ì„±(Saturn) â€“ ëˆˆì— ë„ëŠ” ê³ ë¦¬ê³„, ë°€ë„ëŠ” ë¬¼ë³´ë‹¤ ë‚®ìŒ, 80ê°œ ì´ìƒ ìœ„ì„±(íƒ€ì´íƒ„ ë“±)  \n",
      "7. ì²œì™•ì„±(Uranus) â€“ ì˜†ìœ¼ë¡œ ëˆ„ìš´ ìì „ì¶•, ì–¼ìŒÂ·ê°€ìŠ¤ í˜¼í•©, ì•½í•œ ê³ ë¦¬  \n",
      "8. í•´ì™•ì„±(Neptune) â€“ íƒœì–‘ê³„ ê¶¤ë„ê°€ ê°€ì¥ ê¸´ ê¸°ì²´ í–‰ì„±, ê°•í•œ ë°”ëŒ(ì´ˆì† 600 m)\n",
      "\n",
      "â€» ì‘ì€ í–‰ì„±(ì§€êµ¬í˜•) 4ê°œ â†’ í° í–‰ì„±(ëª©ì„±í˜•) 4ê°œ  \n",
      "â€» 2006ë…„ ëª…ì™•ì„±ì€ â€˜ì™œí–‰ì„±â€™ìœ¼ë¡œ ë¶„ë¥˜ë¨\n"
     ]
    }
   ],
   "source": [
    "# PromptTemplateì„ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš°\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# chain ì‹¤í–‰\n",
    "result = llm.invoke(\"íƒœì–‘ê³„ì˜ í–‰ì„±ë“¤ì„ ê°„ëµíˆ ì •ë¦¬í•´ ì£¼ì„¸ìš”.\")\n",
    "\n",
    "print(type(result))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-2) FewShotChatMessagePromptTemplate ì‚¬ìš©í•˜ëŠ” ê²½ìš°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ê³¼í•™ êµìœ¡ìì…ë‹ˆë‹¤.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': 'ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.', 'output': '### ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™\\n1. **ê´€ì„±ì˜ ë²•ì¹™**: í˜ì´ ì‘ìš©í•˜ì§€ ì•Šìœ¼ë©´ ë¬¼ì²´ëŠ” ê³„ì† ê°™ì€ ìƒíƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\\n2. **ê°€ì†ë„ì˜ ë²•ì¹™**: ë¬¼ì²´ì— í˜ì´ ì‘ìš©í•˜ë©´, í˜ê³¼ ì§ˆëŸ‰ì— ë”°ë¼ ê°€ì†ë„ê°€ ê²°ì •ë©ë‹ˆë‹¤.\\n3. **ì‘ìš©-ë°˜ì‘ìš© ë²•ì¹™**: ëª¨ë“  í˜ì—ëŠ” í¬ê¸°ê°€ ê°™ê³  ë°©í–¥ì´ ë°˜ëŒ€ì¸ í˜ì´ ì‘ìš©í•©ë‹ˆë‹¤.'}, {'input': 'ì§€êµ¬ì˜ ëŒ€ê¸° êµ¬ì„± ìš”ì†Œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.', 'output': '### ì§€êµ¬ ëŒ€ê¸°ì˜ êµ¬ì„±\\n- **ì§ˆì†Œ (78%)**: ëŒ€ê¸°ì˜ ëŒ€ë¶€ë¶„ì„ ì°¨ì§€í•©ë‹ˆë‹¤.\\n- **ì‚°ì†Œ (21%)**: ìƒëª…ì²´ê°€ í˜¸í¡í•˜ëŠ” ë° í•„ìš”í•©ë‹ˆë‹¤.\\n- **ì•„ë¥´ê³¤ (0.93%)**: ë°˜ì‘ì„±ì´ ë‚®ì€ ê¸°ì²´ì…ë‹ˆë‹¤.\\n- **ì´ì‚°í™”íƒ„ì†Œ (0.04%)**: ê´‘í•©ì„± ë° ì˜¨ì‹¤ íš¨ê³¼ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x12c473e00>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x12ce50980>, root_client=<openai.OpenAI object at 0x12c471550>, root_async_client=<openai.AsyncOpenAI object at 0x12ce506e0>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "### ì–‘ìì»´í“¨í„°ê°€ ë­”ê°€ìš”?\n",
      "\n",
      "1. **ìš°ë¦¬ê°€ ì“°ëŠ” ì»´í“¨í„°**  \n",
      "   - ì „ê¸° ìŠ¤ìœ„ì¹˜ê°€ 0 ë˜ëŠ” 1 í•˜ë‚˜ë§Œ ë³´ì—¬ìš”.  \n",
      "   - ì´ ìŠ¤ìœ„ì¹˜ë¥¼ â€œë¹„íŠ¸â€ë¼ê³  í•´ìš”.\n",
      "\n",
      "2. **ì–‘ì ì»´í“¨í„°**  \n",
      "   - ìŠ¤ìœ„ì¹˜ê°€ 0ê³¼ 1ì„ â€œë™ì‹œì—â€ ë³¼ ìˆ˜ ìˆì–´ìš”.  \n",
      "   - ì´ëŸ° ë§ˆë²• ìŠ¤ìœ„ì¹˜ë¥¼ â€œíë¹„íŠ¸â€ë¼ê³  ë¶ˆëŸ¬ìš”.\n",
      "\n",
      "3. **ì™œ ë§ˆë²•ì¼ê¹Œ?**  \n",
      "   - 0ê³¼ 1ì„ ë™ì‹œì— ì“°ë©´ ê¸¸ì´ 3ì§œë¦¬ ë¹„ë°€ë²ˆí˜¸(000~111)ë¥¼ í•œ ë²ˆì— ë‹¤ í™•ì¸í•  ìˆ˜ ìˆì–´ìš”.  \n",
      "   - ë¬¸ì œê°€ ì»¤ì§ˆìˆ˜ë¡ ë” ë§ì€ ê¸¸ì„ â€œí•œë°©ì—â€ ì°¾ì•„ì„œ ë¹¨ë¦¬ ëë‚´ìš”.\n",
      "\n",
      "4. **í•˜ì§€ë§Œ ì•„ì§ì€â€¦**  \n",
      "   - íë¹„íŠ¸ê°€ ì•„ì£¼ ì˜ˆë¯¼í•´ì„œ ì¡°ê¸ˆë§Œ í”ë“¤ë ¤ë„ ê¹¨ì ¸ ë²„ë ¤ìš”.  \n",
      "   - ì§€ê¸ˆì€ ì‹¤í—˜ì‹¤ì—ì„œë§Œ ì‘ë™í•´ìš”. ê³¼í•™ìë“¤ì´ ë” íŠ¼íŠ¼í•˜ê²Œ ë§Œë“œëŠ” ì¤‘!\n",
      "\n",
      "â†’ **ìš”ì•½**  \n",
      "ì–‘ì ì»´í“¨í„°ëŠ” 0ê³¼ 1ì„ â€˜ë™ì‹œì—â€™ ì“°ëŠ” íŠ¹ë³„í•œ ê³„ì‚°ê¸°ë¡œ, ì•„ì£¼ ì–´ë ¤ìš´ í¼ì¦ì„é–ƒç”µì²˜ëŸ¼ í’€ì–´ ì¤„ ë¯¸ë˜ì˜ ì»´í“¨í„°ì˜ˆìš”.\n"
     ]
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate ì‚¬ìš©í•˜ëŠ” ê²½ìš°\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.\",\n",
    "        \"output\": \"\"\"### ë‰´í„´ì˜ ìš´ë™ ë²•ì¹™\n",
    "1. **ê´€ì„±ì˜ ë²•ì¹™**: í˜ì´ ì‘ìš©í•˜ì§€ ì•Šìœ¼ë©´ ë¬¼ì²´ëŠ” ê³„ì† ê°™ì€ ìƒíƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "2. **ê°€ì†ë„ì˜ ë²•ì¹™**: ë¬¼ì²´ì— í˜ì´ ì‘ìš©í•˜ë©´, í˜ê³¼ ì§ˆëŸ‰ì— ë”°ë¼ ê°€ì†ë„ê°€ ê²°ì •ë©ë‹ˆë‹¤.\n",
    "3. **ì‘ìš©-ë°˜ì‘ìš© ë²•ì¹™**: ëª¨ë“  í˜ì—ëŠ” í¬ê¸°ê°€ ê°™ê³  ë°©í–¥ì´ ë°˜ëŒ€ì¸ í˜ì´ ì‘ìš©í•©ë‹ˆë‹¤.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"ì§€êµ¬ì˜ ëŒ€ê¸° êµ¬ì„± ìš”ì†Œë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\",\n",
    "        \"output\": \"\"\"### ì§€êµ¬ ëŒ€ê¸°ì˜ êµ¬ì„±\n",
    "- **ì§ˆì†Œ (78%)**: ëŒ€ê¸°ì˜ ëŒ€ë¶€ë¶„ì„ ì°¨ì§€í•©ë‹ˆë‹¤.\n",
    "- **ì‚°ì†Œ (21%)**: ìƒëª…ì²´ê°€ í˜¸í¡í•˜ëŠ” ë° í•„ìš”í•©ë‹ˆë‹¤.\n",
    "- **ì•„ë¥´ê³¤ (0.93%)**: ë°˜ì‘ì„±ì´ ë‚®ì€ ê¸°ì²´ì…ë‹ˆë‹¤.\n",
    "- **ì´ì‚°í™”íƒ„ì†Œ (0.04%)**: ê´‘í•©ì„± ë° ì˜¨ì‹¤ íš¨ê³¼ì— ì¤‘ìš”í•œ ì—­í• ì„ í•©ë‹ˆë‹¤.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# ì˜ˆì œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate ì ìš©\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‰½ê²Œ ì„¤ëª…í•˜ëŠ” ê³¼í•™ êµìœ¡ìì…ë‹ˆë‹¤.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± ë° ì²´ì¸ êµ¬ì„±\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "chain = final_prompt | llm\n",
    "print(chain)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "result = chain.invoke({\"input\": \"ì–‘ìì»´í“¨íŒ…ì— ëŒ€í•˜ì—¬ ì„¤ëª…í•´ ì£¼ì„¸ìš”.\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1) PartialPrompt \n",
    "* í”„ë¡¬í”„íŠ¸ë¥¼ ë” ë™ì ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆìœ¼ë©°, AI ì‘ë‹µì„ ë” ì¼ê´€ì„± ìˆê²Œ ì¡°ì • ê°€ëŠ¥í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " í”„ë¡¬í”„íŠ¸: ê°€ì„ì— ì¼ì–´ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒì€ íƒœí’ ë°œìƒì´ ë§ë‚˜ìš”? ê°€ì„ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ì§€êµ¬ê³¼í•™ í˜„ìƒì„ 3ê°œ ì•Œë ¤ì£¼ì„¸ìš”\n",
      " ëª¨ë¸ ì‘ë‹µ: ê°€ì„ì— **\"íƒœí’ ë°œìƒ\"**ì€ **ì •í™•íˆ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤**.  \n",
      "íƒœí’ì€ **ì—¬ë¦„ì² (7~9ì›”)**ì— **ê°€ì¥ ë§ì´ ë°œìƒ**í•˜ì§€ë§Œ, **ê°€ì„ì—ë„ ë°œìƒí•  ìˆ˜ëŠ” ìˆìŠµë‹ˆë‹¤**â€”íŠ¹íˆ 9~10ì›”ì—ëŠ” **ê³ ë„ ë°œë‹¬í•œ ê°•ë ¥í•œ íƒœí’(ì˜ˆ: ê°€ì„ íƒœí’)**ì´ ìì£¼ ì˜¤ì§€ë§Œ, **ê°€ì„ì— \"ì£¼ë¡œ\" ë°œìƒí•˜ëŠ” í˜„ìƒì€ ì•„ë‹™ë‹ˆë‹¤**.\n",
      "\n",
      "---\n",
      "\n",
      "### âœ… ê°€ì„ì— **ì£¼ë¡œ ë°œìƒí•˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€**:\n",
      "\n",
      "1. **ëŒ€ê¸° ì•ˆì •í™”ë¡œ ì¸í•œ **ê°€ì„ ê³ ê¸°ì••** í˜•ì„±**  \n",
      "   â†’ ì—¬ë¦„ì² ì˜ ë¶ˆì•ˆì •í•œ ëŒ€ê¸°ê°€ ì•ˆì •ë˜ë©´ì„œ **ê³ ê¸°ì••ì´ ê°•í™”**ë˜ê³ , **ë§‘ê³  ê±´ì¡°í•œ ë‚ ì”¨**ê°€ ê³„ì†ë¨.\n",
      "\n",
      "2. **ê¸°ì˜¨ ì—­ì „ í˜„ìƒ (Radiation inversion)**  \n",
      "   â†’ ë°¤ì´ ê¸¸ì–´ì§€ê³  ì§€ë©´ì´ ë¹ ë¥´ê²Œ ì‹ìœ¼ë©´ì„œ **ì§€í‘œ ê·¼ì²˜ì˜ ê¸°ì˜¨ì´ ìƒì¸µë³´ë‹¤ ë‚®ì•„ì§€ëŠ” í˜„ìƒ**ì´ ë¹ˆë²ˆí•´ì§.  \n",
      "   â†’ **ì•ˆê°œ**, **ì„œë¦¬**, **ì´ìŠ¬**ì´ ìì£¼ ë°œìƒ.\n",
      "\n",
      "3. **ë‹¨í’ê³¼ ë‚™ì—½ì˜ ê³„ì ˆì  ë³€í™” (ì‹ìƒ ê³„ì ˆì„±)**  \n",
      "   â†’ ê¸°ì˜¨ í•˜ê°•ê³¼ ì¼ì¡° ì‹œê°„ ê°ì†Œë¡œ **ë‚˜ë¬´ì˜ í™œë™ì´ ì¤„ì–´ë“¤ê³ **, **ìì˜ ìƒ‰ì†Œ ë³€í™”(ë‹¨í’)**ê°€ ì¼ì–´ë‚¨.  \n",
      "   â†’ ì´ëŠ” **ê¸°í›„í•™ì  ê³„ì ˆ ë³€í™”**ì˜ ì¼ë¶€ë¡œ, **ì§€êµ¬ê³¼í•™ì ìœ¼ë¡œë„ ì¤‘ìš”í•œ í˜„ìƒ**ì…ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### ìš”ì•½\n",
      "- íƒœí’ì€ **ì—¬ë¦„ì²  ì£¼ìš” í˜„ìƒ**, ê°€ì„ì—” **ë“œë¬¼ê²Œ ê°•ë ¥í•œ ê°€ì„ íƒœí’**ì´ ì˜¬ ë¿.\n",
      "- ê°€ì„ì—ëŠ” **ê³ ê¸°ì•• ê°•í™”**, **ê¸°ì˜¨ ì—­ì „**, **ë‹¨í’/ë‚™ì—½** ê°™ì€ **ê³„ì ˆì  ì§€êµ¬ê³¼í•™ í˜„ìƒ**ì´ ëŒ€í‘œì ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ê³„ì ˆì„ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ (ë‚¨ë°˜êµ¬/ë¶ë°˜êµ¬ ê³ ë ¤)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # ë¶ë°˜êµ¬ (ê¸°ë³¸ê°’)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ë´„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ì—¬ë¦„\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ê°€ì„\"\n",
    "        else:\n",
    "            return \"ê²¨ìš¸\"\n",
    "    else:  # ë‚¨ë°˜êµ¬ (ê³„ì ˆ ë°˜ëŒ€)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ê°€ì„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ê²¨ìš¸\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ë´„\"\n",
    "        else:\n",
    "            return \"ì—¬ë¦„\"\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜ (ë¶€ë¶„ ë³€ìˆ˜ ì ìš©)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{season}ì— ì¼ì–´ë‚˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒì€ {phenomenon}ì´ ë§ë‚˜ìš”? {season}ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ì§€êµ¬ê³¼í•™ í˜„ìƒì„ 3ê°œ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
    "    input_variables=[\"phenomenon\"],  # ì‚¬ìš©ì ì…ë ¥ í•„ìš”\n",
    "    partial_variables={\"season\": get_current_season()}  # ë™ì ìœ¼ë¡œ ê³„ì ˆ ê°’ í• ë‹¹\n",
    ")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "# íŠ¹ì • ê³„ì ˆì˜ í˜„ìƒ ì§ˆì˜\n",
    "query = prompt.format(phenomenon=\"íƒœí’ ë°œìƒ\")\n",
    "result = llm.invoke(query)\n",
    "\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\" í”„ë¡¬í”„íŠ¸: {query}\")\n",
    "print(f\" ëª¨ë¸ ì‘ë‹µ: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ê³„ì ˆ: ê°€ì„\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ê³„ì ˆì„ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ (ë‚¨ë°˜êµ¬/ë¶ë°˜êµ¬ ê³ ë ¤)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # ë¶ë°˜êµ¬ (ê¸°ë³¸ê°’)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ë´„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ì—¬ë¦„\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ê°€ì„\"\n",
    "        else:\n",
    "            return \"ê²¨ìš¸\"\n",
    "    else:  # ë‚¨ë°˜êµ¬ (ê³„ì ˆ ë°˜ëŒ€)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"ê°€ì„\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"ê²¨ìš¸\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"ë´„\"\n",
    "        else:\n",
    "            return \"ì—¬ë¦„\"\n",
    "\n",
    "# Step 1: í˜„ì¬ ê³„ì ˆ ê²°ì •\n",
    "season_name = get_current_season()  # ê³„ì ˆ ê°’ ì–»ê¸°\n",
    "print(f\"í˜„ì¬ ê³„ì ˆ: {season_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ê°€ì„ì— ë°œìƒí•˜ëŠ” ìì—° í˜„ìƒ:\n",
      "ê°€ì„ì² ì— ëšœë ·í•˜ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€ë¥¼ ê¼½ìœ¼ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1. ì‹œë² ë¦¬ì•„ ê³ ê¸°ì••ì˜ ë°œë‹¬  \n",
      "   ì•„ì‹œì•„ ëŒ€ë¥™ì´ ê¸‰ì†íˆ ì‹ìœ¼ë©´ì„œ ì‹œë² ë¦¬ì•„-ëª½ê³¨ ë¶€ê·¼ì— ê°•í•œ ê³ ê¸°ì••ì´ í˜•ì„±ë©ë‹ˆë‹¤. ì´ ê³ ê¸°ì••ì´ ë‚¨í•˜í•˜ë©´ì„œ í•œë°˜ë„ì— ë§‘ê³  ê±´ì¡°í•œ ê°€ì„ ë‚ ì”¨ë¥¼ ë§Œë“¤ê³ , ë‚¨ìª½ìœ¼ë¡œ ì§„ì¶œí•  ë•ŒëŠ” ê²¨ìš¸ì²  ë¶ì„œ ê³„ì ˆí’ì˜ â€˜ì „ì´ˆë¶€â€™ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "\n",
      "2. ê¸°ì••ê³¨ ì£¼ë„ì˜ ì´ìƒê³ ì˜¨(ê°€ì„ ëŠ¦ë”ìœ„)  \n",
      "   ì¤‘êµ­ ëŒ€ë¥™ì—ì„œ ë™ì§„í•˜ëŠ” ê¸°ì••ê³¨ì´ í•œë°˜ë„ ìƒê³µì„ ì§€ë‚˜ë©´ ëŒ€ê¸°ê°€ ê°•í•œ í•˜ê°•æ°”æµ(í•˜ê°•æ°”æµ)ë¥¼ íƒ€ê³  ì••ì¶•Â·ê°€ì—´ë©ë‹ˆë‹¤. ì´ë•Œ í•˜ì¸µì˜ ë™í’ì´ ëœ¨ê±°ì§„ ì•¼ì‚°ì„±(ì•¼ê°„ ì‚°ì„±) ê¸°ë¥˜ë¥¼ ë‚´ë¥™ìœ¼ë¡œ ëŒì–´ë“¤ì—¬ 9âˆ¼10ì›”ì— 30 â„ƒ ì•ˆíŒì˜ â€˜ê°€ì„ ëŠ¦ë”ìœ„â€™ë¥¼ ë°œìƒì‹œí‚µë‹ˆë‹¤.\n",
      "\n",
      "3. ì‚°ê°„ ê³„ê³¡ì—ì„œì˜ ë³µì‚¬(è¼»å°„) ì•ˆê°œ  \n",
      "   ë°¤ì´ ê¸¸ì–´ì§€ê³  ì§€ë©´ì´ ë§‘ê²Œ ê°ê¸°ë©´ì„œ ê³„ê³¡ ë°”ë‹¥ì€ ëŒ€ê¸°ë³´ë‹¤ í›¨ì”¬ ì°¨ê°€ì›Œì§‘ë‹ˆë‹¤. ì´ì— ë”°ë¼ ì¸ê·¼ ê³µê¸°ê°€ ìˆ˜ì¦í™” í¬í™” ìƒíƒœì— ì´ë¥´ëŸ¬ ìˆ˜ì¦ê¸°ê°€ ì‘ê²°Â·ë¶€ìœ í•˜ë©´ì„œ ì—°ë¬´(ì•ˆê°œ)ê°€ ê¹Šê²Œ ê¹”ë¦¬ëŠ” í˜„ìƒì´ ìì£¼ ê´€ì¸¡ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: í•´ë‹¹ ê³„ì ˆì˜ ìì—° í˜„ìƒ ì¶”ì²œ\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{season}ì— ì£¼ë¡œ ë°œìƒí•˜ëŠ” ëŒ€í‘œì ì¸ ì§€êµ¬ê³¼í•™ í˜„ìƒ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. \"\n",
    "    \"ê° í˜„ìƒì— ëŒ€í•´ ê°„ë‹¨í•œ ì„¤ëª…ì„ í¬í•¨í•´ì£¼ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "##llm = ChatOpenAI(\n",
    "##    #api_key=OPENAI_API_KEY,\n",
    "##    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "##    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "##    temperature=0.0\n",
    "##)\n",
    "\n",
    "# ì²´ì¸ 2: ìì—° í˜„ìƒ ì¶”ì²œ (ì…ë ¥: ê³„ì ˆ â†’ ì¶œë ¥: ìì—° í˜„ìƒ ëª©ë¡)\n",
    "chain2 = (\n",
    "    {\"season\": lambda x : season_name}  # chain1ì˜ ì¶œë ¥ì„ season ë³€ìˆ˜ë¡œ ì „ë‹¬\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# ì‹¤í–‰: í˜„ì¬ ê³„ì ˆì— ë”°ë¥¸ ìì—° í˜„ìƒ ì¶”ì²œ\n",
    "response = chain2.invoke({})\n",
    "print(f\"\\n {season_name}ì— ë°œìƒí•˜ëŠ” ìì—° í˜„ìƒ:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2) PartialPrompt \n",
    "* API í˜¸ì¶œ ë°ì´í„°, ì‹œê°„ ì •ë³´, ì‚¬ìš©ì ì •ë³´ ë“±ì„ ë°˜ì˜í•  ë•Œ ë§¤ìš° ìœ ìš©í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " í”„ë¡¬í”„íŠ¸: í˜„ì¬ 1ë‹¬ëŸ¬ = 1406.48ì› ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. ì´ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.\n",
      " ëª¨ë¸ ì‘ë‹µ: í˜„ì¬ í™˜ìœ¨ 1ë‹¬ëŸ¬ = 1,406.48ì›ì€ **ì—­ëŒ€ ìµœê³  ìˆ˜ì¤€**ì— ê·¼ì ‘í•œ ìˆ˜ì¹˜ë¡œ, ë‹¨ìˆœí•œ 'ì•½ì„¸'ë¥¼ ë„˜ì–´ **ì‹¬ê°í•œ ì›í™” ì·¨ì•½ ì¦í›„êµ°**ì´ ë³¸ê²©í™”ëœ ì‹ í˜¸ë¡œ ì½íˆëŠ” êµ¬ê°„ì…ë‹ˆë‹¤. ì•„ë˜ì— 5ê°€ì§€ ì¸¡ë©´ì—ì„œ êµ¬ì¡°ì Â·ì •ì±…ì  í•¨ì˜ë¥¼ ì •ë¦¬í•´ ë“œë¦½ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. ìˆ˜ì¹˜ë¡œ ë³¸ ìœ„ì¹˜\n",
      "- **ê³ ì  ëŒ€ë¹„ ìƒìŠ¹ë¥ **: 2017ë…„ 1,050ì› ëŒ€ë¹„ ì•½ 34% ì ˆìƒ(ì›í™” ì•½ì„¸)  \n",
      "- **ì‘ë…„ ë™ê¸° ëŒ€ë¹„**: 2023ë…„ 5ì›” 1,320ì› â†’ 1ë…„ ìƒˆ ì•½ 6.5% ì¶”ê°€ ì•½ì„¸  \n",
      "- **íŠ¸ë¦¬í”Œ ë””ì§€íŠ¸ ì‹¬ë¦¬ì„ **: 1,400ì› ëŒíŒŒëŠ” ì„œìš¸Â·ì›Œì‹±í„´ ì–‘ìª½ ëª¨ë‘ 'ì‚¬ì•ˆ'ì´ ë  ìˆ˜ì¤€\n",
      "\n",
      "---\n",
      "\n",
      "### 2. ì›í™” ì•½ì„¸ì˜ 3ëŒ€ êµ¬ì¡°ì  ì±…ì„ ìš”ì¸\n",
      "| ìš”ì¸ | ì„¤ëª… | ë¹„ê³  |\n",
      "|---|---|---|\n",
      "| **1) ìˆ˜ì¶œ êµ¬ì¡° ì „í™˜** | ë°˜ë„ì²´Â·ë°°í„°ë¦¬ ë“± ëŒ€í˜• í’ˆëª©ì´ ìˆ˜ì¶œ ë‘”í™”, ì¤‘êµ­ ë² ì´ìŠ¤ ì´ê²©â†‘ | í•œêµ­ì€í–‰ ê¸°ì¤€, 2024ë…„ 1-4ì›” ìˆ˜ì¶œ YoY -6.5% |\n",
      "| **2) ì•ˆì „ìì‚° ì„ í˜¸** | ë¯¸êµ­ 10ë…„ë¬¼ 4.5% vs í•œêµ­ 10ë…„ë¬¼ 3.5% â†’ ì°¨ìµê±°ë˜ ìê¸ˆ ì§€ì† ìœ ì¶œ | ì™¸êµ­ì¸ ì±„ê¶Œíˆ¬ì 2024ë…„ ëˆ„ì  â€“8ì¡°ì› |\n",
      "| **3) ê²½ìƒìˆ˜ì§€ êµ¬ì¡° ë³€í™”** | 2022ë…„ ì´í›„ ì—ë„ˆì§€Â·ì‹í’ˆ ì—­ì™¸ ê°€ê²©â†‘ì—ë„ ë¶ˆêµ¬, ì¬ì •ê±´ì „ì„± ìš°ì„  â†’ ì¬ì •ì†Œë¹„ ì–µì œ | 2023ë…„ ê²½ìƒìˆ˜ì§€ í‘ì 29.8bn$ â†’ 2024ë…„ 13bn$ ì „ë§(í•˜ë½) |\n",
      "\n",
      "---\n",
      "\n",
      "### 3. ê¸ˆí†µìœ„Â·ì¬ì •ë‹¹êµ­ì˜ ì„ íƒì§€\n",
      "1. **ì™¸í™˜ê±´ì „ì„± ë¶€ë‹´**  \n",
      "   - í•œêµ­ì€í–‰ì´ 1,400ì› 'ì‹¬ë¦¬ì„ 'ì„ ì‚¬ì‹¤ìƒ ë°©ì¹˜ â†’ ì‹œì¥ \"ë¼ì¸ ì¸ ë” ìƒŒë“œ\" ì‹ ë¢° í•˜ë½  \n",
      "   - ì‹¤íš¨ì„± ìˆëŠ” ë°©ì–´ëŠ” 1) 1ì¡°+ ë‹¬ëŸ¬ ë§¤ë„(ì™¸í™˜ë³´ìœ ì•¡ 4,100ì–µ$ ëŒ€ë¹„ 2.5% ìˆ˜ì¤€) 2) ì–‘ì  ê¸´ì¶•(í†µí™”ì•ˆì •ì¦ê¶Œ ë°œí–‰ í™•ëŒ€) 3) ì¬ì •Â·ê¸ˆìœµë‹¹êµ­ í•©ë™ 'ë³€ë™ì„± ì™„í™”' ì„ ì–¸  \n",
      "\n",
      "2. **ë¬¼ê°€Â·ê°€ê³„ë¶€ë‹´**  \n",
      "   - ì›í™” ì•½ì„¸ 10% â†’ ìˆ˜ì…ë¬¼ê°€ì§€ìˆ˜ 6~7%â†‘ â†’ CPI 0.4~0.5%p ê°€ì‚°  \n",
      "   - 1ì¸ë‹¹ êµ­ë¯¼ì†Œë“ 3ë§Œ$ ì‹œëŒ€, ì²´ê° êµ¬ë§¤ë ¥ í•˜ë½ì´ ì‹¤ì§ˆì†Œë“ë³´ë‹¤ ë¹ ë¥´ê²Œ ë‚˜íƒ€ë‚¨\n",
      "\n",
      "3. **ê¸°ì—… ì¬ë¬´**  \n",
      "   - ë‹¬ëŸ¬ ë¶€ì±„ ë¹„ì¤‘ ë†’ì€ í•­ê³µÂ·ì¡°ì„ Â·ì„ìœ í™”í•™ ì—…ì¢…ì€ í™˜ì†ìµ ê°œì„ , ë°˜ëŒ€ë¡œ ë‚´ìˆ˜í˜• ì œì¡°Â·ìœ í†µì—…ì€ ì›ìì¬ë¹„â†‘  \n",
      "   - 2024ë…„ 1ë¶„ê¸° ìƒì¥ì‚¬ 30%ê°€ í™˜ì°¨ì†(ë³„ë„ ê¸°ì¤€) ê¸°ë¡, ì—­ëŒ€ ìµœëŒ€\n",
      "\n",
      "---\n",
      "\n",
      "### 4. êµ­ì œ ì‹œê°\n",
      "- **ë¯¸ ì¬ë¬´ë¶€ í†µí™”ë³´ê³ ì„œ**ì—ì„œëŠ” 'ê´€ì°°ëŒ€ìƒêµ­' ìš”ê±´(ëŒ€ë¯¸ í‘ì 150ì–µ$, ê²½ìƒí‘ì 2% ì´ˆê³¼) ì¤‘ í•˜ë‚˜ë¼ë„ ì¶©ì¡± ì‹œ **í™˜ìœ¨ì €ê²©ì„± ê°„ì£¼** ê°€ëŠ¥  \n",
      "- í˜„ì¬ í•œêµ­ì€ ëŒ€ë¯¸ í‘ì 2023ë…„ 440ì–µ$, ê²½ìƒí‘ì 1.4% â†’ **ê°„ë°œì˜ ì°¨ì´**ë¡œ 'ê´€ì°°ëŒ€ìƒêµ­' íšŒí”¼\n",
      "\n",
      "---\n",
      "\n",
      "### 5. ì•ìœ¼ë¡œì˜ ì‹œë‚˜ë¦¬ì˜¤(6ê°œì›” ì‹œì•¼)\n",
      "| ì‹œë‚˜ë¦¬ì˜¤ | í™˜ìœ¨ êµ¬ê°„ | í•µì‹¬ ì¡°ê±´ |\n",
      "|---|---|---|\n",
      "| **A. ì†Œí”„íŠ¸ ëœë”©** | 1,350~1,380 | â‘  ì—°ì¤€ 9ì›” ì¸í•˜ 1íšŒ, â‘¡ ì¤‘êµ­ ê²½ê¸° ë°˜ë“±, â‘¢ í•œì€ CPI 2% ì•ˆì°© |\n",
      "| **B. ë² ì´ìŠ¤ ì¼€ì´ìŠ¤** | 1,380~1,430 | â‘  ì—°ì¤€ ì—°ë‚´ 0~1íšŒ ì¸í•˜, â‘¡ ìˆ˜ì¶œ íšŒë³µ ëŠë¦¼, â‘¢ í•œì€ CPI 2% ì´ˆë°˜ |\n",
      "| **C. ë¦¬ìŠ¤í¬ ì˜¤í”„** | 1,450~1,500+ | â‘  ì¤‘ë™Â·ëŸ¬-ìš°í¬ ì „ì¥ í™•ëŒ€, â‘¡ ë¯¸ ê²½ê¸° ì¹¨ì²´, â‘¢ í•œÂ·ì¤‘ ìˆ˜ì¶œ ë™ë°˜ ê¸‰ê° |\n",
      "\n",
      "---\n",
      "\n",
      "### 6. íˆ¬ìÂ·ìš´ìš© í¬ì¸íŠ¸\n",
      "1. **í—¤ì§€ ë¹„ìœ¨**  \n",
      "   - ìˆ˜ì…ì˜ 60% ì´ìƒì´ ë‹¬ëŸ¬Â·ì—”Â·ìœ„ì•ˆí™” â†’ 3ê°œì›” ì´ë‚´ ê²°ì œë¬¼ëŸ‰ ê¸°ì¤€ 50%Â±10% ì„ ë¬¼Â·ìŠ¤ì™‘ í—¤ì§€ ê¶Œì¥(ë³€ë™ì„± 12% ê¸°ì¤€)\n",
      "\n",
      "2. **ìì‚° ë°°ë¶„**  \n",
      "   - ì›í™” í‘œë©´ ìˆ˜ìµë¥ ì´ ë†’ì€ ì±„ê¶Œ(ì˜ˆ: 5ë…„ ë§Œê¸° êµ­ê³ ì±„ 3.6%)ì€ í™˜í—¤ì§€ í›„ ì‹¤ì§ˆìˆ˜ìµ â†“ â†’ **ë‹¬ëŸ¬ í‘œì‹œ ê¸€ë¡œë²Œ íˆ¬ìë“±ê¸‰ ì±„ê¶Œ**ì´ë‚˜ **ë‹¨ê¸° ë¯¸êµ­ êµ­ì±„(T-Bill 5.2%)**ê°€ ì‹¤ì§ˆ ë§¤ë ¥ë„ ìš°ìœ„\n",
      "\n",
      "3. **ì£¼ì‹ ì„¹í„°**  \n",
      "   - í™˜ìœ¨ 1,400ì› ì´í›„ 3ê°œì›”ê°„ **ë°˜ë„ì²´ ëŒ€í˜•ì£¼(ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤)**ëŠ” í‰ê·  10% ì´ˆê³¼ìˆ˜ìµ, **ë‚´ìˆ˜í˜• ìœ í†µÂ·ê±´ì„¤ì£¼**ëŠ” â€“5% ìˆ˜ì¤€ â†’ ì„¹í„° ë¡œí…Œì´ì…˜ ìœ íš¨\n",
      "\n",
      "---\n",
      "\n",
      "### 7. ê²°ë¡  & ì•¡ì…˜ ì•„ì´í…œ\n",
      "\"1,400ì› ì´ìƒì˜ í™˜ìœ¨ì€ ë‹¨ìˆœí•œ 'ê²½ê³ ë“±'ì´ ì•„ë‹ˆë¼ **ê²½ì œÂ·ì •ì¹˜Â·ì™¸êµ ì „ë°©ìœ„ì— ê±¸ì¹œ ì „ëµì  ë¦¬ìŠ¤í¬**ë‹¤.\"\n",
      "\n",
      "- ê¸°ì—…CFO: 6ê°œì›”~1ë…„ê°„ ë‹¬ëŸ¬ ìˆ˜ìš”ë¥¼ ì„ ë°˜(å…ˆè²©)Â·ì„ ì…(å…ˆå…¥) í—¤ì§€ ë¹„ì¤‘ 30%p í™•ëŒ€  \n",
      "- ê°€ê³„Â·ê°œì¸: í•´ì™¸ ì§êµ¬Â·ì—¬í–‰ ì†Œë¹„ 20% ì ˆê°, **ë‹¬ëŸ¬ í‘œì‹œ MMFÂ·ë‹¨ê¸° ì±„ê¶Œ**ìœ¼ë¡œ í˜„ê¸ˆì„± ìì‚° 10~20% í¸ì…  \n",
      "- ì •ì±…ë‹¹êµ­:  \n",
      "  1) ì™¸í™˜ìœ ë™ì„± ê³µê¸‰ í”„ë¡œê·¸ë¨(FX swap line) ì¬ê°œ ê²€í†   \n",
      "  2) ë¬¼ê°€ ì•ˆì •ì„ ìœ„í•œ ìˆ˜ì…ê´€ì„¸Â·íŠ¹ë³„í• ë‹¹ í• ì¸ í•œì‹œë³µê·€  \n",
      "  3) 'ê´€ì°°ëŒ€ìƒêµ­' íšŒí”¼ë¥¼ ìœ„í•œ ëŒ€ë¯¸ í‘ì ì¶•ì†Œ ë¡œë“œë§µ(ì—ë„ˆì§€Â·ë°©ìœ„ì‚°ì—… í˜‘ìƒ) ìˆ˜ë¦½\n",
      "\n",
      "ì´ìƒìœ¼ë¡œ, **1,406.48ì›ì€ ì›í™”ê°€ ë§ë‹¥ëœ¨ë¦° 'ìƒˆë¡œìš´ ì •ìƒ'ì´ì ë™ì‹œì— 'ìƒˆë¡œìš´ ìœ„í—˜'**ì´ë¼ëŠ” ì ì„ ì—¼ë‘ì— ë‘ê³  ì¬ë¬´Â·íˆ¬ìÂ·ì •ì±… í¬íŠ¸í´ë¦¬ì˜¤ë¥¼ ì¬ì •ë¹„í•  ì‹œì ì´ë¼ê³  íŒë‹¨ë©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ì‹¤ì‹œê°„ í™˜ìœ¨ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1ë‹¬ëŸ¬ = {data['rates']['KRW']}ì›\"\n",
    "\n",
    "# Partial Prompt í™œìš©\n",
    "prompt = PromptTemplate(\n",
    "    template=\"í˜„ì¬ {info} ê¸°ì¤€ìœ¼ë¡œ í™˜ìœ¨ ì •ë³´ë¥¼ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤. ì´ì— ëŒ€í•œ ë¶„ì„ì„ ì œê³µí•´ ì£¼ì„¸ìš”.\",\n",
    "    input_variables=[],  # ì‚¬ìš©ì ì…ë ¥ ì—†ìŒ\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # APIì—ì„œ ê°€ì ¸ì˜¨ ë°ì´í„° ìë™ ë°˜ì˜\n",
    ")\n",
    "\n",
    "# LLM ëª¨ë¸ ì„¤ì •\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "# ëª¨ë¸ì— í”„ë¡¬í”„íŠ¸ ì „ë‹¬ ë° ì‘ë‹µ ë°›ê¸°\n",
    "response = llm.invoke(prompt.format())\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\" í”„ë¡¬í”„íŠ¸:\", prompt.format())\n",
    "print(\" ëª¨ë¸ ì‘ë‹µ:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
