{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d4cb2eb",
   "metadata": {},
   "source": [
    "# LLM Chain 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1e012",
   "metadata": {},
   "source": [
    "## 1. 환경 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addb358f",
   "metadata": {},
   "source": [
    "### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "983a63b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c8b9d0",
   "metadata": {},
   "source": [
    "### 2) OpenAI 인증키 설정\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92fb8c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_T\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a965e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.27\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3139ae1",
   "metadata": {},
   "source": [
    "## 2. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1096a2cb",
   "metadata": {},
   "source": [
    "### 1) Prompt + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "559b327f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eon/skRookies/myLangChain/mylangchain-app/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"인공지능 모델의 학습 원리에 대하여 쉽게 설명해 주세요.\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0deaaba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='인공지능 모델의 학습 원리를 쉽게 설명하면 다음과 같습니다.\\n\\n1. **데이터 수집**: 인공지능 모델이 학습할 수 있는 데이터를 수집합니다. 이 데이터는 모델이 학습할 수 있는 형태여야 합니다.\\n\\n2. **데이터 전처리**: 수집한 데이터를 모델이 학습할 수 있는 형태로 변환합니다. 예를 들어, 이미지 데이터를 모델이 이해할 수 있는 숫자의 형태로 변환하는 것입니다.\\n\\n3. **모델 초기화**: 인공지능 모델을 초기화합니다. 모델은 일반적으로 신경망 구조로 구성되며, 가중치와 편향이라는 매개변수를 가지고 있습니다.\\n\\n4. **학습**: 모델에 데이터를 입력하고, 모델이 예측한 결과와 실제 결과 사이의 차이를 계산합니다. 이 차이를 **손실 함수**라고 합니다.\\n\\n5. **역전파**: 손실 함수를 최소화하기 위해 모델의 가중치와 편향을 업데이트합니다. 이 과정은 **역전파**라고 하며, 모델의 가중치와 편향을 조정하여 손실 함수를 최소화하는 방향으로 진행됩니다.\\n\\n6. **반복**: 학습 데이터를 반복적으로 입력하고, 모델의 가중치와 편향을 업데이트하여 손실 함수를 최소화합니다.\\n\\n7. **수렴**: 모델의 손실 함수가 일정 수준 이하로 떨어지면, 모델은 학습을 완료합니다.\\n\\n이 과정을 통해 인공지능 모델은 데이터로부터 패턴을 학습하고, 새로운 데이터에 대해 예측할 수 있는 능력을 갖추게 됩니다.\\n\\n예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 학습한다고 가정해 봅시다. 모델은 고양이와 강아지의 사진을 입력으로 받고, 고양이인지 강아지인지를 출력으로 내보냅니다. 모델은 학습 데이터를 통해 고양이와 강아지의 특징을 학습하고, 새로운 사진에 대해 고양이인지 강아지인지를 예측할 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 365, 'prompt_tokens': 24, 'total_tokens': 389, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.202164666, 'prompt_time': 0.000301233, 'completion_time': 0.904213143, 'total_time': 0.904514376}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_5d3e4e58e1', 'id': 'chatcmpl-9527619c-a152-4b64-af15-43cf3cdd8402', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--8ccabc7d-2ef9-4abe-8924-936803447037-0' usage_metadata={'input_tokens': 24, 'output_tokens': 365, 'total_tokens': 389, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb66eda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리를 쉽게 설명하면 다음과 같습니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델이 학습할 수 있는 데이터를 수집합니다. 이 데이터는 모델이 학습할 수 있는 형태여야 합니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집한 데이터를 모델이 학습할 수 있는 형태로 변환합니다. 예를 들어, 이미지 데이터를 모델이 이해할 수 있는 숫자의 형태로 변환하는 것입니다.\n",
      "\n",
      "3. **모델 초기화**: 인공지능 모델을 초기화합니다. 모델은 일반적으로 신경망 구조로 구성되며, 가중치와 편향이라는 매개변수를 가지고 있습니다.\n",
      "\n",
      "4. **학습**: 모델에 데이터를 입력하고, 모델이 예측한 결과와 실제 결과 사이의 차이를 계산합니다. 이 차이를 **손실 함수**라고 합니다.\n",
      "\n",
      "5. **역전파**: 손실 함수를 최소화하기 위해 모델의 가중치와 편향을 업데이트합니다. 이 과정은 **역전파**라고 하며, 모델의 가중치와 편향을 조정하여 손실 함수를 최소화하는 방향으로 진행됩니다.\n",
      "\n",
      "6. **반복**: 학습 데이터를 반복적으로 입력하고, 모델의 가중치와 편향을 업데이트하여 손실 함수를 최소화합니다.\n",
      "\n",
      "7. **수렴**: 모델의 손실 함수가 일정 수준 이하로 떨어지면, 모델은 학습을 완료합니다.\n",
      "\n",
      "이 과정을 통해 인공지능 모델은 데이터로부터 패턴을 학습하고, 새로운 데이터에 대해 예측할 수 있는 능력을 갖추게 됩니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 학습한다고 가정해 봅시다. 모델은 고양이와 강아지의 사진을 입력으로 받고, 고양이인지 강아지인지를 출력으로 내보냅니다. 모델은 학습 데이터를 통해 고양이와 강아지의 특징을 학습하고, 새로운 사진에 대해 고양이인지 강아지인지를 예측할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821574e",
   "metadata": {},
   "source": [
    "### 2) PromptTemplate + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b617e8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} template='You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3358f7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 스스로 규칙을 찾아내고, 이를 통해 미래의 새로운 데이터에 대해 예측하거나 분류할 수 있도록 하는 것입니다.\\n\\n예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 보겠습니다. 이 모델에게 수많은 고양이와 강아지의 사진을 보여주고, 이것이 고양이인지 강아지인지를 알려줍니다. 처음에는 모델이 고양이와 강아지를 구분하지 못하지만, 점점 더 많은 사진을 학습하면서 모델은 고양이는 고양이답고, 강아지는 강아지다운 특징을 스스로 찾아내기 시작합니다.\\n\\n이 과정은 다음과 같습니다:\\n\\n1. **데이터 수집**: 다양한 고양이와 강아지의 사진을 수집합니다.\\n2. **데이터 입력**: 이 사진들을 모델에 입력합니다.\\n3. **모델의 예측**: 모델은 각 사진을 보고 이것이 고양이인지 강아지인지를 예측합니다.\\n4. **오답 수정**: 사용자가 모델의 예측이 맞았는지 틀렸었는지를 피드백해 줍니다.\\n5. **학습**: 모델은 예측과 실제 값의 차이(오류)를 계산하고, 이 오류를 줄이기 위해 내부의 가중치와 편향을 조정합니다. 이 과정을 여러 번 반복하면서 모델은 점점 더 정확한 예측을 할 수 있게 됩니다.\\n\\n이처럼 인공지능 모델은 데이터를 통해 학습하고, 스스로 규칙을 찾아내어 새로운 데이터에 대해 예측하거나 분류할 수 있는 능력을 키웁니다. 이를 통해 이미지 인식, 음성 인식, 자연어 처리 등 다양한 분야에서 활용할 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 328, 'prompt_tokens': 36, 'total_tokens': 364, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.202388199, 'prompt_time': 0.000521189, 'completion_time': 0.883512848, 'total_time': 0.884034037}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_5d3e4e58e1', 'id': 'chatcmpl-c423954a-542f-4d61-8d42-a7633ac514bb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--8b23ea69-a397-48a6-906e-9686812b14b9-0' usage_metadata={'input_tokens': 36, 'output_tokens': 328, 'total_tokens': 364, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))\n",
    "\n",
    "# chain 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4b14ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 스스로 규칙을 찾아내고, 이를 통해 미래의 새로운 데이터에 대해 예측하거나 분류할 수 있도록 하는 것입니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 보겠습니다. 이 모델에게 수많은 고양이와 강아지의 사진을 보여주고, 이것이 고양이인지 강아지인지를 알려줍니다. 처음에는 모델이 고양이와 강아지를 구분하지 못하지만, 점점 더 많은 사진을 학습하면서 모델은 고양이는 고양이답고, 강아지는 강아지다운 특징을 스스로 찾아내기 시작합니다.\n",
      "\n",
      "이 과정은 다음과 같습니다:\n",
      "\n",
      "1. **데이터 수집**: 다양한 고양이와 강아지의 사진을 수집합니다.\n",
      "2. **데이터 입력**: 이 사진들을 모델에 입력합니다.\n",
      "3. **모델의 예측**: 모델은 각 사진을 보고 이것이 고양이인지 강아지인지를 예측합니다.\n",
      "4. **오답 수정**: 사용자가 모델의 예측이 맞았는지 틀렸었는지를 피드백해 줍니다.\n",
      "5. **학습**: 모델은 예측과 실제 값의 차이(오류)를 계산하고, 이 오류를 줄이기 위해 내부의 가중치와 편향을 조정합니다. 이 과정을 여러 번 반복하면서 모델은 점점 더 정확한 예측을 할 수 있게 됩니다.\n",
      "\n",
      "이처럼 인공지능 모델은 데이터를 통해 학습하고, 스스로 규칙을 찾아내어 새로운 데이터에 대해 예측하거나 분류할 수 있는 능력을 키웁니다. 이를 통해 이미지 인식, 음성 인식, 자연어 처리 등 다양한 분야에서 활용할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35860af9",
   "metadata": {},
   "source": [
    "### 3) PromptTemplate + LLM(invoke()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e888e777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'str'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 스스로 학습하고, 학습한 내용을 토대로 미래의 새로운 데이터에 대해 예측하거나 분류할 수 있도록 만드는 것입니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 보겠습니다.\n",
      "\n",
      "1. **데이터 수집**: 수많은 고양이와 강아지의 사진을 수집합니다. 이 사진들이 바로 인공지능이 학습하는 자료가 됩니다.\n",
      "\n",
      "2. **데이터 준비**: 수집한 사진들을 컴퓨터가 처리할 수 있는 형태로 변환합니다. 이 과정에는 사진의 픽셀 값을 숫자로 바꾸는 작업 등이 포함됩니다.\n",
      "\n",
      "3. **모델 선택**: 고양이와 강아지의 특징을 어떻게 추출하고 분류할지 결정하는 모델을 선택합니다. 예를 들어, 합성곱 신경망(CNN)과 같은 모델을 사용할 수 있습니다.\n",
      "\n",
      "4. **학습**: 준비한 사진들을 모델에 입력하고, 모델이 스스로 고양이와 강아지의 특징을 찾아내도록 합니다. 이 과정에서는 '레이블(label)'이라 불리는 실제 고양이/강아지 분류 정보가 필요합니다. 모델은 입력된 사진이 고양이인지 강아지인지를 맞추려고 하면서, 스스로 특징을 학습합니다. 이 학습 과정에서는 '손실 함수(loss function)'라는 것을 통해 모델의 예측이 얼마나 정확한지 평가하고, '최적화 알고리즘(optimization algorithm)'를 통해 모델의 성능을 점점 개선해 나갑니다.\n",
      "\n",
      "5. **평가**: 학습이 어느 정도 되었는지 확인하기 위해, 별도로 준비한 테스트 데이터를 모델에 입력하여 성능을 평가합니다.\n",
      "\n",
      "6. **예측**: 이제 모델은 새로운, 보지 못한 고양이와 강아지의 사진을 보고 그것이 고양이인지 강아지인지 분류할 수 있습니다.\n",
      "\n",
      "이처럼 인공지능 모델은 대량의 데이터를 통해 스스로 학습하고, 학습한 패턴을 바탕으로 새로운 데이터에 대해 예측하거나 분류하는 능력을 키웁니다. 이를 통해 이미지 인식, 음성 인식, 자연어 처리 등 다양한 분야에서 활용할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. \\\n",
    "                                      Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 2. chain 생성 (LCEL)\n",
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "\n",
    "# 3. chain의 invoke 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7106b99",
   "metadata": {},
   "source": [
    "### 4) PromptTemplate + LLM(stream()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14003c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 배우고, 판단하고, 결정하는 능력을 키우는 과정이라고 생각하시면 됩니다.\n",
      "\n",
      "예를 들어, 어린 아이에게 고양이를 보여주고 \"이것은 고양이야\"라고 말해준다고 가정해 봅시다. 처음에는 아이가 고양이를 이해하지 못할 수 있지만, 여러 번 고양이를 보여주고 설명해 주면 아이는 고양이의 특징(귀가 길고, 털이 보드라다)을 스스로 터득하게 됩니다.\n",
      "\n",
      "인공지능 모델의 학습 과정도 이와 비슷합니다.\n",
      "\n",
      "1. **데이터 수집**: 많은 양의 데이터(고양이 사진들)를 모읍니다.\n",
      "2. **데이터 입력**: 이 데이터를 인공지능 모델에 입력합니다.\n",
      "3. **모델의 예측**: 모델은 입력된 데이터를 보고, 스스로 고양이인지 아닌지 예측합니다.\n",
      "4. **오답 수정**: 사용자가 \"이것은 고양이야\"라고 말해주거나(레이블링), 모델의 예측이 맞았는지 틀렸는지 알려줍니다.\n",
      "5. **반복 학습**: 이 과정을 매우 많은 번 반복하면서, 모델은 고양이의 특징을 스스로 학습합니다.\n",
      "\n",
      "이렇게 학습한 모델은 새로운, 보지 못했던 고양이 사진을 보고도 \"이것은 고양이야\"라고 스스로 판단할 수 있습니다.\n",
      "\n",
      "이러한 학습 원리는 신경망(Neural Network) 구조를 기반으로 하며, 딥러닝(Deep Learning) 기술의 핵심입니다. 모델이 깊고 복잡해질수록 더 많은 데이터를 통해 더 많은 학습을 하게 되며, 이를 통해 이미지 인식, 자연어 처리, 음성 인식 등 다양한 분야에서 높은 성능을 발휘할 수 있습니다."
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. \\\n",
    "                                      Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "lm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "# 스트리밍 출력\n",
    "#print(answer)\n",
    "\n",
    "for token in answer:\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.(flush=True)\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9facb193",
   "metadata": {},
   "source": [
    "### 5) Multiple Chains\n",
    "- Multi Chain을 활용한 영화 추천 및 줄거리 요약 (잘 동작하지 않는 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce6e5cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      " ===> 추천된 영화:\n",
      "드라마 장르라면 이 영화를 꼽고 싶습니다.\n",
      "\n",
      "**《문라이트》(원제: Moonlight, 2016)**  \n",
      "감독: 배리 젠킨스  \n",
      "\n",
      "- **줄거리**  \n",
      "  마이애미의 rough한 환경에서 자란 검은색 소년 ‘치론’이 10대, 20대, 30대 세 시기를 거치며 자신의 정체성과 사랑을 찾아가는 이야기입니다.  \n",
      "\n",
      "- **추천 포인트**  \n",
      "  – 2017년 아카데미 작품상을 비롯해 3관왕(각본·남우조연)  \n",
      "  – 독특한 3막 구성이 주인공의 내면 변화를 섬세하게 포착  \n",
      "  – 사회적 소수자의 시선으로 ‘성장·가족·사랑’을 조용하면서도 강렬하게 그려냄  \n",
      "  – 색감·음악·연기 모두 몰입도 높음  \n",
      "\n",
      "한 편의 시를 보는 듯한 여운이 오래 남습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "movie = chain1.invoke({\"genre\": \"Drama\"})  # 영화 제목 얻기\n",
    "\n",
    "print(type(movie))\n",
    "print(\" ===> 추천된 영화:\")  # movie 값 출력\n",
    "print(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c1268e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first={\n",
      "  movie: ChatPromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, template='{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.'), additional_kwargs={})])\n",
      "         | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x158308510>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1583088a0>, root_client=<openai.OpenAI object at 0x1583082b0>, root_async_client=<openai.AsyncOpenAI object at 0x158308640>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "         | StrOutputParser()\n",
      "} middle=[ChatPromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, template='{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요'), additional_kwargs={})]), ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x158308510>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1583088a0>, root_client=<openai.OpenAI object at 0x1583082b0>, root_async_client=<openai.AsyncOpenAI object at 0x158308640>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n",
      "\n",
      "🔹 영화 줄거리 요약:\n",
      " **『쇼생크 탈출』**\n",
      "\n",
      "쇼생크 탈출  \n",
      "감독: 프랭크 다라본트  \n",
      "출연: 팀 로빈스(앤디 듀프레인), 모건 프리먼(레드), 밥 건턴(워든 노튼)  \n",
      "줄거리: 1947년, 아내와 그녀의 정부를 살해했다는 누명을 쓴 은행원 앤디는 쇼생크 교도소에 무기징역으로 수감된다. 차가운 철창 속에서도 희망을 놓지 않던 앤디는 동료 죄수 레드와 특별한 우정을 맺고, 19년에 걸친 치밀한 계획 끝에 자유를 쟁취한다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(chain2)\n",
    "\n",
    "# 실행: \"Drama\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\\n\", response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae506f04",
   "metadata": {},
   "source": [
    "##### chain1과 chain2에서 영화 제목이 일관되게 전달 되도록 변경 (잘 동작하는 코드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37f8e752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 영화 줄거리 요약:\n",
      "('**쇼생크 탈출**  \\n'\n",
      " '(The Shawshank Redemption, 1994)\\n'\n",
      " '\\n'\n",
      " '제목: 쇼생크 탈출  \\n'\n",
      " '감독: 프랭크 다라본트  \\n'\n",
      " '출연: 팀 로빈스(앤디 듀프레인), 모건 프리먼(엘리스 보이드 “레드” 레딩)  \\n'\n",
      " '줄거리: 1947년, 아내와 그의 정부를 살해했다는 누명을 쓴 은행원 앤디는 쇼생크 교도소에 무기징역으로 수감된다. 차가운 외면과 잔혹한 '\n",
      " '교도소 일상 속에서 그는 끝없는 침묵과 인내로 시간을 견디지만, 동시에 희망을 잃지 않는다. 20년 넘게 마춰온 우정, 책, 지혜, '\n",
      " '그리고 한 줌의 망치로 그는 누구도 상상 못 한 ‘탈출’을 감행한다. 자유를 향한 오랜 준비와 우정의 진면목이 마지막 10분에 폭발하며, '\n",
      " '희망이란 결코 허황된 말이 아님을 증명한다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: \"Drama\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\")\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
