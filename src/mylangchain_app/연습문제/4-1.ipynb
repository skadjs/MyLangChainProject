{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0f66cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 1: 카페 메뉴 도구 호출 체인 구현\n",
    "\n",
    "import re\n",
    "import os\n",
    "from textwrap import dedent\n",
    "from pprint import pprint\n",
    "from typing import List\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig, chain\n",
    "\n",
    "from langchain_upstage import UpstageEmbeddings, ChatUpstage\n",
    "from langchain_community.tools import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce343c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n",
    "\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "print(UPSTAGE_API_KEY[30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9178d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. 카페 메뉴 데이터 로드 및 벡터 DB 구축\n",
    "def create_cafe_vector_db():\n",
    "    # 카페 메뉴 텍스트 데이터를 로드\n",
    "    loader = TextLoader(\"../data/cafe_menu_data.txt\", encoding=\"utf-8\")\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # 메뉴 항목별로 분할\n",
    "    def split_menu_items(document):\n",
    "        pattern = r'(\\d+\\.\\s.*?)(?=\\n\\n\\d+\\.|$)'\n",
    "        menu_items = re.findall(pattern, document.page_content, re.DOTALL)\n",
    "        \n",
    "        menu_documents = []\n",
    "        for i, item in enumerate(menu_items, 1):\n",
    "            # 메뉴 이름 추출\n",
    "            menu_name = item.split('\\n')[0].split('.', 1)[1].strip()\n",
    "            \n",
    "            menu_doc = Document(\n",
    "                page_content=item.strip(),\n",
    "                metadata={\n",
    "                    \"source\": document.metadata['source'],\n",
    "                    \"menu_number\": i,\n",
    "                    \"menu_name\": menu_name\n",
    "                }\n",
    "            )\n",
    "            menu_documents.append(menu_doc)\n",
    "        \n",
    "        return menu_documents\n",
    "    \n",
    "    # 메뉴 항목 분리 실행\n",
    "    menu_documents = []\n",
    "    for doc in documents:\n",
    "        menu_documents += split_menu_items(doc)\n",
    "    \n",
    "    # 임베딩 모델 설정\n",
    "    #embeddings_model = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "    embeddings_model = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "    \n",
    "    # FAISS 인덱스 생성\n",
    "    cafe_db = FAISS.from_documents(\n",
    "        documents=menu_documents, \n",
    "        embedding=embeddings_model\n",
    "    )\n",
    "    \n",
    "    # FAISS 인덱스 저장\n",
    "    cafe_db.save_local(\"../db/cafe_db\")\n",
    "    \n",
    "    return cafe_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "928297f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.tools.structured.StructuredTool'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. 도구 정의\n",
    "# 웹 검색 도구\n",
    "@tool\n",
    "def tavily_search_func(query: str) -> str:\n",
    "    \"\"\"Searches the internet for information that does not exist in the database or for the latest information.\"\"\"\n",
    "    tavily_search = TavilySearchResults(max_results=2)\n",
    "    docs = tavily_search.invoke(query)\n",
    "    \n",
    "    formatted_docs = \"\\n---\\n\".join([\n",
    "        f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
    "        for doc in docs\n",
    "    ])\n",
    "    \n",
    "    if len(formatted_docs) > 0:\n",
    "        return formatted_docs\n",
    "    \n",
    "    return \"관련 정보를 찾을 수 없습니다.\"\n",
    "print(type(tavily_search_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f7469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 위키피디아 검색 도구\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "def wiki_search_and_summarize(input_data: dict):\n",
    "    wiki_loader = WikipediaLoader(query=input_data[\"query\"], load_max_docs=2, lang=\"ko\")\n",
    "    wiki_docs = wiki_loader.load()\n",
    "    \n",
    "    formatted_docs = [\n",
    "        f'<Document source=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "        for doc in wiki_docs\n",
    "    ]\n",
    "    \n",
    "    return formatted_docs\n",
    "\n",
    "class WikiSummarySchema(BaseModel):\n",
    "    \"\"\"Input schema for Wikipedia search.\"\"\"\n",
    "    query: str = Field(..., description=\"The query to search for in Wikipedia\")\n",
    "\n",
    "summary_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following text in a concise manner:\\n\\n{context}\\n\\nSummary:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a47bacc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solar-pro\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LLM 모델 \n",
    "# llm = ChatOpenAI(\n",
    "#     #api_key=OPENAI_API_KEY,\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "#     model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "#     temperature=0.7\n",
    "# )\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5,\n",
    ")\n",
    "print(llm.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45789a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.tools.structured.StructuredTool'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/_c9chpr14vxg3hvpscn52m740000gn/T/ipykernel_23356/1575251558.py:6: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  wiki_summary = summary_chain.as_tool(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "summary_chain = (\n",
    "    {\"context\": RunnableLambda(wiki_search_and_summarize)}\n",
    "    | summary_prompt | llm\n",
    ")\n",
    "\n",
    "wiki_summary = summary_chain.as_tool(\n",
    "    name=\"wiki_summary\",\n",
    "    description=dedent(\"\"\"\n",
    "        Use this tool when you need to search for information on Wikipedia.\n",
    "        It searches for Wikipedia articles related to the user's query and returns\n",
    "        a summarized text. This tool is useful when general knowledge\n",
    "        or background information is required.\n",
    "    \"\"\"),\n",
    "    args_schema=WikiSummarySchema\n",
    ")\n",
    "print(type(wiki_summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1f99bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.tools.structured.StructuredTool'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 카페 메뉴 검색 도구\n",
    "@tool\n",
    "def db_search_cafe_func(query: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Securely retrieve and access authorized cafe menu information from the encrypted database.\n",
    "    Use this tool only for cafe menu-related queries to maintain data confidentiality.\n",
    "    \"\"\"\n",
    "    #embeddings_model = OllamaEmbeddings(model=\"bge-m3:latest\")\n",
    "    embeddings_model = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "    cafe_db = FAISS.load_local(\n",
    "        \"../db/cafe_db\", \n",
    "        embeddings_model, \n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    \n",
    "    docs = cafe_db.similarity_search(query, k=2)\n",
    "    if len(docs) > 0:\n",
    "        return docs\n",
    "    \n",
    "    return [Document(page_content=\"관련 카페 메뉴 정보를 찾을 수 없습니다.\")]\n",
    "print(type(db_search_cafe_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ccfc362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. 도구를 LLM에 바인딩\n",
    "tools = [tavily_search_func, wiki_summary, db_search_cafe_func]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4a663d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. 간단한 도구 호출 체인 구현\n",
    "@chain\n",
    "def cafe_search_chain(user_input: str, config: RunnableConfig):\n",
    "    # 첫 번째 LLM 호출로 도구 사용 결정\n",
    "    ai_msg = llm_with_tools.invoke(user_input, config=config)\n",
    "    \n",
    "    # 도구 실행\n",
    "    tool_msgs = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        print(f\"{tool_call['name']}: \\n{tool_call}\")\n",
    "        print(\"-\"*100)\n",
    "        if tool_call[\"name\"] == \"tavily_search_func\":\n",
    "            tool_message = tavily_search_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "        elif tool_call[\"name\"] == \"wiki_summary\":\n",
    "            tool_message = wiki_summary.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "        elif tool_call[\"name\"] == \"db_search_cafe_func\":\n",
    "            tool_message = db_search_cafe_func.invoke(tool_call, config=config)\n",
    "            tool_msgs.append(tool_message)\n",
    "    \n",
    "    # 최종 답변 생성을 위한 프롬프트\n",
    "    final_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful cafe assistant. Provide accurate information based on the search results.\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "        (\"ai\", ai_msg.content if ai_msg.content else \"도구를 사용하여 정보를 검색했습니다.\"),\n",
    "        (\"human\", \"검색 결과: {tool_results}\")\n",
    "    ])\n",
    "    \n",
    "    # 도구 결과를 문자열로 변환\n",
    "    tool_results_str = \"\\n\\n\".join([str(msg.content) for msg in tool_msgs])\n",
    "    \n",
    "    # 최종 답변 생성\n",
    "    final_chain = final_prompt | llm\n",
    "    return final_chain.invoke({\n",
    "        \"user_input\": user_input,\n",
    "        \"tool_results\": tool_results_str\n",
    "    }, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff0be59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "카페 메뉴 벡터 DB가 성공적으로 생성되었습니다.\n",
      "db_search_cafe_func: \n",
      "{'name': 'db_search_cafe_func', 'args': {'query': '아메리카노 가격 및 유래'}, 'id': 'chatcmpl-tool-ed04266c457b480589e8ead1b5278dff', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "wiki_summary: \n",
      "{'name': 'wiki_summary', 'args': {'query': '아메리카노 유래'}, 'id': 'chatcmpl-tool-b37666f918ae42e383baa4b51e12a17a', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tavily_search_func: \n",
      "{'name': 'tavily_search_func', 'args': {'query': '최근 인기 있는 서울 카페 추천'}, 'id': 'chatcmpl-tool-4bad011ac707486ba284e9a09638509b', 'type': 'tool_call'}\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/_c9chpr14vxg3hvpscn52m740000gn/T/ipykernel_23356/35227420.py:6: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_search = TavilySearchResults(max_results=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문: 아메리카노의 가격은 얼마인가요? 아메리카노의 유래는 무엇인가요? 그리고 최근에 가장 인기 있는 서울에 있는 카페도 추천해 주세요.\n",
      "답변: ### 1. 아메리카노 가격  \n",
      "- **핫 아메리카노**: ₩4,500  \n",
      "- **아이스 아메리카노**: ₩4,500  \n",
      "(제공된 카페 메뉴 데이터 기준)\n",
      "\n",
      "---\n",
      "\n",
      "### 2. 아메리카노의 유래  \n",
      "- **기원**: 20세기 초 이탈리아에서 유래했다는 설이 가장 유력합니다.  \n",
      "  - \"Americano\"는 미국인들이 유럽의 에스프레소를 자신의 커피 문화에 맞게 **뜨거운 물로 희석**해 마신 데서 이름이 붙었습니다.  \n",
      "  - 2차 세계대전 당시 미군 병사들이 이탈리아의 에스프레소를 희석해 마신 것이 시초로 알려져 있습니다.  \n",
      "- **어원**: 영어 \"American\"(미국인)에서 파생되었으며, 원두 본연의 맛을 강조하는 클래식한 블랙 커피로 발전했습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. 서울 인기 카페 추천 (2024년 기준)  \n",
      "검색 결과를 종합해 최근 인기 있는 카페를 선정했습니다:  \n",
      "\n",
      "#### 🏆 **1위: 천상가옥 (낙산 성곽 근처)**  \n",
      "- **특징**:  \n",
      "  - 낙산 전망과 어우러진 힐링 공간.  \n",
      "  - 뮤지엄 CAFE로 리모델링되어 음료 구매 시 박물관 입장 가능.  \n",
      "  - 산미 없는 고소한 커피와 스콘/베이커리 메뉴가 인기.  \n",
      "- **영업시간**: 월-목 10:00 ~ 21:50 / 금-일 10:00 ~ 22:50  \n",
      "\n",
      "#### 🌿 **2위: 사유 (한남동)**  \n",
      "- **특징**:  \n",
      "  - 5층 복합문화공간. 층마다 다른 테마(미디어아트, 갤러리, 스카이 라운지).  \n",
      "  - 천창과 식물로 평화로운 분위기. 커피 양은 적지만 로스팅 직접 진행.  \n",
      "- **영업시간**: 매일 11:00 ~ 22:00  \n",
      "\n",
      "#### 🐶 **3위: 구욱희씨 (서울숲)**  \n",
      "- **특징**:  \n",
      "  - 반려동물 동반 가능. 파스텔톤 인테리어와 포토존(그네) 인기.  \n",
      "  - 직접 로스팅한 커피와 다양한 베이커리 메뉴.  \n",
      "- **영업시간**: 매일 12:00 ~ 22:00  \n",
      "\n",
      "#### 🌃 **4위: 뷰클랜즈 (송리단길)**  \n",
      "- **특징**:  \n",
      "  - 주택 개조 카페로 우드 인테리어와 자연 조망.  \n",
      "  - 시그니처 \"스웨덴 커피\"와 달콤한 스윗라떼 추천.  \n",
      "- **영업시간**: 매일 12:00 ~ 22:00 (라스트 오더 21:20)  \n",
      "\n",
      "> ※ 참고: 인기 카페는 시즌별로 변동될 수 있으니 방문 전 영업시간 확인이 필요합니다.  \n",
      "\n",
      "--- \n",
      "\n",
      "도움이 되셨다면 추가 문의 사항을 알려주세요! ☕\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. 실행 및 테스트\n",
    "if __name__ == \"__main__\":\n",
    "    # 벡터 DB 생성 (최초 1회만 실행)\n",
    "    try:\n",
    "        create_cafe_vector_db()\n",
    "        print(\"카페 메뉴 벡터 DB가 성공적으로 생성되었습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"벡터 DB 생성 중 오류: {e}\")\n",
    "    \n",
    "    # 질문에 답변    \n",
    "    query = \"아메리카노의 가격은 얼마인가요? 아메리카노의 유래는 무엇인가요? 그리고 최근에 가장 인기 있는 서울에 있는 카페도 추천해 주세요.\"\n",
    "    #query = \"최근에 가장 인기 있는 서울에 있는 카페를 추천해 주세요.\"\n",
    "    response = cafe_search_chain.invoke(query)\n",
    "    \n",
    "    print(\"질문:\", query)\n",
    "    print(\"답변:\", response.content)                                      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
