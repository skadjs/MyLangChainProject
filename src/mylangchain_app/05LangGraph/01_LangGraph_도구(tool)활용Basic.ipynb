{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangGraph에서 도구(tool) 활용 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 도구(tool)를 활용한 에이전트 개발 방법을 알아봅니다\n",
    "- workflow를 직접 선언하지 않고, 사용가능한 도구들을 전달하면, 에이전트가 적합한 도구를 판단해서 사용합니다\n",
    "    - 이번 회차에서는 `ToolNode`를 통해 도구를 활용하는 방법을 알아봅니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n",
    "\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "print(UPSTAGE_API_KEY[30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-0125\n"
     ]
    }
   ],
   "source": [
    "# from langchain_upstage import ChatUpstage\n",
    "# llm = ChatUpstage(\n",
    "#         model=\"solar-pro\",\n",
    "#         base_url=\"https://api.upstage.ai/v1\",\n",
    "#         temperature=0.5\n",
    "#     )\n",
    "# print(llm)\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-3.5-turbo-0125', \n",
    "    temperature=0,\n",
    ")\n",
    "print(llm.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 더합니다.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 곱합니다.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LangGraph는 `ToolNode`를 통해 도구를 활용합니다\n",
    "- `ToolNode`의 `invoke()`결과는 도구의 `invoke()` 결과와 유사합니다\n",
    "    - 도구는 도구의 실행 결과를 리턴하고, `ToolNode`는 도구의 실행 결과를 포함한 `ToolMessage`를 리턴합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableBinding'>\n",
      "tools(tags=None, recurse=True, explode_args=False, func_accepts={'config': ('N/A', <class 'inspect._empty'>), 'store': ('store', None)}, tools_by_name={'add': StructuredTool(name='add', description='숫자 a와 b를 더합니다.', args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x112c26660>), 'multiply': StructuredTool(name='multiply', description='숫자 a와 b를 곱합니다.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x113494e00>)}, tool_to_state_args={'add': {}, 'multiply': {}}, tool_to_store_arg={'add': None, 'multiply': None}, handle_tool_errors=True, messages_key='messages')\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_list = [add, multiply]\n",
    "llm_with_tools = llm.bind_tools(tool_list)\n",
    "\n",
    "tool_node = ToolNode(tool_list)\n",
    "\n",
    "print(type(llm_with_tools))\n",
    "print(tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = multiply.invoke({'a': 3, 'b': 5})\n",
    "\n",
    "print(type(result))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_QX1E9kMD4aCJUp4Uy1GVjeJ4', 'function': {'arguments': '{\"a\":3,\"b\":5}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 88, 'total_tokens': 105, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CLVTBnDAPr4aUG0ccTKO4sEWhKe2u', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c8238201-b934-4ff2-9354-1711221a8cfc-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'call_QX1E9kMD4aCJUp4Uy1GVjeJ4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 88, 'output_tokens': 17, 'total_tokens': 105, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message = llm_with_tools.invoke('What is 3 plus 5?')\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'a': 3, 'b': 5},\n",
       "  'id': 'call_QX1E9kMD4aCJUp4Uy1GVjeJ4',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `ToolNode`를 `invoke()`하려면 `tool_calls` 속성을 포함한 `AIMessage`를 전달해야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [ToolMessage(content='8', name='add', tool_call_id='call_QX1E9kMD4aCJUp4Uy1GVjeJ4')]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_msg = tool_node.invoke({'messages': [ai_message]})\n",
    "\n",
    "print(type(tool_msg))\n",
    "tool_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 간단한 에이전트를 만들기 위해 LangGraph에서 제공하는 [`StateGraph`](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate)를 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state: MessagesState) -> MessagesState:\n",
    "    \"\"\"\n",
    "    에이전트 함수는 주어진 상태에서 메시지를 가져와\n",
    "    LLM과 도구를 사용하여 응답 메시지를 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        state (MessagesState): 메시지 상태를 포함하는 state.\n",
    "\n",
    "    Returns:\n",
    "        MessagesState: 응답 메시지를 포함하는 새로운 state.\n",
    "    \"\"\"\n",
    "    # 상태에서 메시지를 추출합니다.\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # LLM과 도구를 사용하여 메시지를 처리하고 응답을 생성합니다. (RunnableBinding)\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    # 응답 메시지를 새로운 상태로 반환합니다.\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import END\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal['tools', END]:\n",
    "    \"\"\"\n",
    "    주어진 메시지 상태를 기반으로 에이전트가 계속 진행할지 여부를 결정합니다.\n",
    "\n",
    "    Args:\n",
    "        state (MessagesState): `state`를 포함하는 객체.\n",
    "\n",
    "    Returns:\n",
    "        Literal['tools', END]: 도구를 사용해야 하면 `tools`를 리턴하고, \n",
    "        답변할 준비가 되었다면 END를 반환해서 프로세스를 종료합니다.\n",
    "    \"\"\"\n",
    "    # 상태에서 메시지를 추출합니다.\n",
    "    messages = state['messages']\n",
    "    print(type(messages))\n",
    "    print(messages)\n",
    "    \n",
    "    # 마지막 AI 메시지를 가져옵니다.\n",
    "    last_ai_message = messages[-1]\n",
    "    \n",
    "    # 마지막 AI 메시지가 도구 호출을 포함하고 있는지 확인합니다.\n",
    "    if last_ai_message.tool_calls:\n",
    "        # 도구 호출이 있으면 'tools'를 반환합니다.\n",
    "        return 'tools'\n",
    "    \n",
    "    # 도구 호출이 없으면 END를 반환하여 프로세스를 종료합니다.\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `node`를 추가하고 `edge`로 연결합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent': StateNodeSpec(runnable=agent(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None, input_schema=<class 'langgraph.graph.message.MessagesState'>, retry_policy=None, cache_policy=None, ends=(), defer=False),\n",
       " 'tools': StateNodeSpec(runnable=tools(tags=None, recurse=True, explode_args=False, func_accepts={'config': ('N/A', <class 'inspect._empty'>), 'store': ('store', None)}, tools_by_name={'add': StructuredTool(name='add', description='숫자 a와 b를 더합니다.', args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x112c26660>), 'multiply': StructuredTool(name='multiply', description='숫자 a와 b를 곱합니다.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x113494e00>)}, tool_to_state_args={'add': {}, 'multiply': {}}, tool_to_store_arg={'add': None, 'multiply': None}, handle_tool_errors=True, messages_key='messages'), metadata=None, input_schema=<class 'langgraph.graph.message.MessagesState'>, retry_policy=None, cache_policy=None, ends=(), defer=False)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_node('agent', agent)\n",
    "#tool_node = ToolNode(tool_list)\n",
    "graph_builder.add_node('tools', tool_node)\n",
    "\n",
    "graph_builder.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('__start__', 'agent'), ('tools', 'agent')}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "graph_builder.add_edge(START, 'agent')\n",
    "graph_builder.add_conditional_edges(\n",
    "    'agent',\n",
    "    should_continue,\n",
    "    ['tools', END]\n",
    ")\n",
    "graph_builder.add_edge('tools', 'agent')\n",
    "\n",
    "graph_builder.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langgraph.graph.state.CompiledStateGraph'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x1137a0c20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph= graph_builder.compile()\n",
    "print(type(graph))\n",
    "\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mermaid Code:\n",
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tagent(agent)\n",
      "\ttools(tools)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> agent;\n",
      "\tagent -.-> __end__;\n",
      "\tagent -.-> tools;\n",
      "\ttools --> agent;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mermaid_code = graph.get_graph().draw_mermaid()\n",
    "print(\"Mermaid Code:\")\n",
    "print(mermaid_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://mermaid.live/ 에서  mermain_code 로 직접 확인한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `graph.stream()`을 활용하면 에이전트가 답변을 생성하는 과정을 모니터링 할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "3에다 5를 더하고 거기에 8을 곱하면?\n",
      "<class 'list'>\n",
      "[HumanMessage(content='3에다 5를 더하고 거기에 8을 곱하면?', additional_kwargs={}, response_metadata={}, id='eba365a5-8816-42a4-861c-dffaf0ec8429'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_afdWTE8iiZ1FCZMvzDWHnm2i', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function'}, {'id': 'call_rECr5n0wNaMx4MUPQqAAb7Oq', 'function': {'arguments': '{\"a\": 8, \"b\": 8}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 103, 'total_tokens': 152, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CLVTDgaBpsNFRKu6brET1IjTIj0BZ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4dc8e62d-973a-4f92-bf2b-aac1310afa60-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'call_afdWTE8iiZ1FCZMvzDWHnm2i', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 8, 'b': 8}, 'id': 'call_rECr5n0wNaMx4MUPQqAAb7Oq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 103, 'output_tokens': 49, 'total_tokens': 152, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  add (call_afdWTE8iiZ1FCZMvzDWHnm2i)\n",
      " Call ID: call_afdWTE8iiZ1FCZMvzDWHnm2i\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 5\n",
      "  multiply (call_rECr5n0wNaMx4MUPQqAAb7Oq)\n",
      " Call ID: call_rECr5n0wNaMx4MUPQqAAb7Oq\n",
      "  Args:\n",
      "    a: 8\n",
      "    b: 8\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "64\n",
      "<class 'list'>\n",
      "[HumanMessage(content='3에다 5를 더하고 거기에 8을 곱하면?', additional_kwargs={}, response_metadata={}, id='eba365a5-8816-42a4-861c-dffaf0ec8429'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_afdWTE8iiZ1FCZMvzDWHnm2i', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function'}, {'id': 'call_rECr5n0wNaMx4MUPQqAAb7Oq', 'function': {'arguments': '{\"a\": 8, \"b\": 8}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 103, 'total_tokens': 152, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CLVTDgaBpsNFRKu6brET1IjTIj0BZ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4dc8e62d-973a-4f92-bf2b-aac1310afa60-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'call_afdWTE8iiZ1FCZMvzDWHnm2i', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 8, 'b': 8}, 'id': 'call_rECr5n0wNaMx4MUPQqAAb7Oq', 'type': 'tool_call'}], usage_metadata={'input_tokens': 103, 'output_tokens': 49, 'total_tokens': 152, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='8', name='add', id='41bb7273-71a0-4968-8275-fe9ad33558a3', tool_call_id='call_afdWTE8iiZ1FCZMvzDWHnm2i'), ToolMessage(content='64', name='multiply', id='02383a9d-7fc8-45dd-84f0-5d7f00720d35', tool_call_id='call_rECr5n0wNaMx4MUPQqAAb7Oq'), AIMessage(content='3에다 5를 더한 값은 8이고, 그 값에 8을 곱하면 64가 됩니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 168, 'total_tokens': 202, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CLVTEEgA3huAX6Dztv5ZNN95qUyoV', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--1547a2e2-59b9-4bda-8942-9a8a9d39ffbe-0', usage_metadata={'input_tokens': 168, 'output_tokens': 34, 'total_tokens': 202, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "3에다 5를 더한 값은 8이고, 그 값에 8을 곱하면 64가 됩니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "for chunk in graph.stream({'messages': [HumanMessage('3에다 5를 더하고 거기에 8을 곱하면?')]}, stream_mode='values'):\n",
    "    chunk['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangGraph 내장 ReAct 에이전트 사용\n",
    "* create_react_agent()의 작동 방식\n",
    "    * create_react_agent() 함수 내부에서 이미 StateGraph와 필요한 노드(사고, 도구 실행, 응답 생성 등)를 자동으로 구성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-0125\n",
      "<class 'langgraph.graph.state.CompiledStateGraph'>\n",
      "{'messages': [HumanMessage(content='3+5는?', additional_kwargs={}, response_metadata={}, id='a8172587-bd97-411d-98df-7474e9f87f85'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_hg6mumy2Oq4X3dYXG7pfqDGU', 'function': {'arguments': '{\"a\":3,\"b\":5}', 'name': 'add2'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 58, 'total_tokens': 76, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CLVTIuRgIQM2VoIb04Wp5SI81K5bw', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--e79aa7d1-059e-4477-9f0a-cc9d13e27da5-0', tool_calls=[{'name': 'add2', 'args': {'a': 3, 'b': 5}, 'id': 'call_hg6mumy2Oq4X3dYXG7pfqDGU', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 18, 'total_tokens': 76, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='8', name='add2', id='9a6aaf94-664a-4f18-a34d-85351f37f030', tool_call_id='call_hg6mumy2Oq4X3dYXG7pfqDGU'), AIMessage(content='3 + 5는 8입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 85, 'total_tokens': 95, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CLVTKTJ9qliU7kOd7HZUys78HJDmC', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6b0f547e-0996-43ce-9ae0-63d5e3d9b216-0', usage_metadata={'input_tokens': 85, 'output_tokens': 10, 'total_tokens': 95, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.agents import tool\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "# llm = ChatUpstage(\n",
    "#         model=\"solar-pro\",\n",
    "#         base_url=\"https://api.upstage.ai/v1\",\n",
    "#         temperature=0.5\n",
    "#     )\n",
    "# print(llm)\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    model='gpt-3.5-turbo-0125', \n",
    "    temperature=0,\n",
    ")\n",
    "print(llm.model_name)\n",
    "\n",
    "@tool\n",
    "def add2(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 더합니다.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "# 한 줄로 에이전트 생성 - 내부에서 StateGraph를 자동 구성\n",
    "\n",
    "agent = create_react_agent(model=llm, tools=[add2])\n",
    "print(type(agent))\n",
    "\n",
    "# 바로 사용 가능\n",
    "result = agent.invoke({\"messages\": [HumanMessage(content=\"3+5는?\")]})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 더 복잡한 도구들 정의\n",
    "@tool\n",
    "def calculate_compound_interest(principal: float, rate: float, years: int) -> str:\n",
    "    \"\"\"원금, 이자율, 기간을 받아 복리 이자를 계산합니다.\"\"\"\n",
    "    amount = principal * (1 + rate/100) ** years\n",
    "    interest = amount - principal\n",
    "    return f\"{years}년 후 원리금: {amount:,.0f}원, 이자: {interest:,.0f}원\"\n",
    "\n",
    "@tool\n",
    "def calculate_tax(income: float) -> str:\n",
    "    \"\"\"연소득을 받아 간이 세액을 계산합니다.\"\"\"\n",
    "    if income <= 12000000:\n",
    "        tax = income * 0.06\n",
    "    elif income <= 46000000:\n",
    "        tax = 720000 + (income - 12000000) * 0.15\n",
    "    elif income <= 88000000:\n",
    "        tax = 5820000 + (income - 46000000) * 0.24\n",
    "    else:\n",
    "        tax = 15900000 + (income - 88000000) * 0.35\n",
    "    \n",
    "    return f\"예상 세액: {tax:,.0f}원, 세후 소득: {income - tax:,.0f}원\"\n",
    "\n",
    "@tool\n",
    "def get_weekday(date_str: str) -> str:\n",
    "    \"\"\"YYYY-MM-DD 형식의 날짜를 받아 요일을 반환합니다.\"\"\"\n",
    "    from datetime import datetime\n",
    "    date_obj = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "    weekdays = [\"월요일\", \"화요일\", \"수요일\", \"목요일\", \"금요일\", \"토요일\", \"일요일\"]\n",
    "    return f\"{date_str}은 {weekdays[date_obj.weekday()]}입니다.\"\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "print(llm.model_name)\n",
    "\n",
    "# 도구 리스트\n",
    "tools_list = [calculate_compound_interest, calculate_tax, get_weekday]\n",
    "\n",
    "# ReAct 에이전트 생성\n",
    "agent = create_react_agent(model=llm, tools=tools_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: 1억원을 연 5% 복리로 10년 동안 예금하면 얼마가 될까?\n",
      "--------------------------------------------------\n",
      "답변: 1억원을 연 5% 복리로 10년 동안 예금하면 10년 후에 100,501,127원이 될 것입니다. 이 중 이자는 501,127원입니다.\n",
      "================================================================================\n",
      "\n",
      "질문: 연소득 5천만원일 때 내야 할 세금은 얼마야?\n",
      "--------------------------------------------------\n",
      "답변: 연소득 5천만원일 때 내야 할 세금은 6,780,000원이며, 세후 소득은 43,220,000원입니다.\n",
      "================================================================================\n",
      "\n",
      "질문: 2024-12-25은 무슨 요일이야?\n",
      "--------------------------------------------------\n",
      "답변: 2024년 12월 25일은 수요일입니다.\n",
      "================================================================================\n",
      "\n",
      "질문: 연소득 8천만원일 때 세금을 계산하고, 남은 돈을 연 4% 복리로 5년간 예금하면 얼마가 돼?\n",
      "--------------------------------------------------\n",
      "답변: 세금을 공제한 후 연소득 66,020,000원을 연 4% 복리로 5년간 예금하면 총 80,323,425원이 됩니다.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 복합적인 질문 테스트\n",
    "complex_questions = [\n",
    "    \"1억원을 연 5% 복리로 10년 동안 예금하면 얼마가 될까?\",\n",
    "    \"연소득 5천만원일 때 내야 할 세금은 얼마야?\",\n",
    "    \"2024-12-25은 무슨 요일이야?\",\n",
    "    \"연소득 8천만원일 때 세금을 계산하고, 남은 돈을 연 4% 복리로 5년간 예금하면 얼마가 돼?\"\n",
    "]\n",
    "\n",
    "for question in complex_questions:\n",
    "    print(f\"\\n질문: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    result = agent.invoke({\"messages\": [HumanMessage(content=question)]})\n",
    "    response = result[\"messages\"][-1].content\n",
    "    \n",
    "    print(f\"답변: {response}\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "1억원을 연 5% 복리로 10년 동안 예금하면 얼마가 될까?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  calculate_compound_interest (call_Dc71na4vMY1TR3IIE1USeVey)\n",
      " Call ID: call_Dc71na4vMY1TR3IIE1USeVey\n",
      "  Args:\n",
      "    principal: 100000000\n",
      "    rate: 0.05\n",
      "    years: 10\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: calculate_compound_interest\n",
      "\n",
      "10년 후 원리금: 100,501,127원, 이자: 501,127원\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "1억원을 연 5% 복리로 10년 동안 예금하면 10년 후에는 총 10,050,1127원이 됩니다. 이 중 이자는 501,127원입니다.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "연소득 5천만원일 때 내야 할 세금은 얼마야?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  calculate_tax (call_kxz97KaI9Mi0EhU06GEVu3Uq)\n",
      " Call ID: call_kxz97KaI9Mi0EhU06GEVu3Uq\n",
      "  Args:\n",
      "    income: 50000000\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: calculate_tax\n",
      "\n",
      "예상 세액: 6,780,000원, 세후 소득: 43,220,000원\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "연소득 5천만원에 대한 간이 세액은 6,780,000원이며, 세후 소득은 43,220,000원입니다.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "2024-12-25은 무슨 요일이야?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weekday (call_m8baXzRcRnZ6dmd50mAcSIU4)\n",
      " Call ID: call_m8baXzRcRnZ6dmd50mAcSIU4\n",
      "  Args:\n",
      "    date_str: 2024-12-25\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: get_weekday\n",
      "\n",
      "2024-12-25은 수요일입니다.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "2024년 12월 25일은 수요일입니다.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "연소득 8천만원일 때 세금을 계산하고, 남은 돈을 연 4% 복리로 5년간 예금하면 얼마가 돼?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  calculate_tax (call_xrRkYZGX67krUK7bNyxsrGLF)\n",
      " Call ID: call_xrRkYZGX67krUK7bNyxsrGLF\n",
      "  Args:\n",
      "    income: 80000000\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: calculate_tax\n",
      "\n",
      "예상 세액: 13,980,000원, 세후 소득: 66,020,000원\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  calculate_compound_interest (call_fe5ETSXsSsyPTCgutMyElZgb)\n",
      " Call ID: call_fe5ETSXsSsyPTCgutMyElZgb\n",
      "  Args:\n",
      "    principal: 66020000\n",
      "    rate: 4\n",
      "    years: 5\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: calculate_compound_interest\n",
      "\n",
      "5년 후 원리금: 80,323,425원, 이자: 14,303,425원\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "연소득 8천만원일 때 예상 세액은 13,980,000원이며, 세후 소득은 66,020,000원입니다. 이를 연 4% 복리로 5년간 예금하면 5년 후 원리금은 80,323,425원이며, 이자는 14,303,425원입니다.\n"
     ]
    }
   ],
   "source": [
    "complex_questions = [\n",
    "    \"1억원을 연 5% 복리로 10년 동안 예금하면 얼마가 될까?\",\n",
    "    \"연소득 5천만원일 때 내야 할 세금은 얼마야?\",\n",
    "    \"2024-12-25은 무슨 요일이야?\",\n",
    "    \"연소득 8천만원일 때 세금을 계산하고, 남은 돈을 연 4% 복리로 5년간 예금하면 얼마가 돼?\"\n",
    "]\n",
    "\n",
    "for question in complex_questions:\n",
    "    for chunk in agent.stream({'messages': [HumanMessage(content=question)]}, stream_mode='values'):\n",
    "        chunk['messages'][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
