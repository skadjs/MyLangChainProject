{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LangChain vs LangGraph (feat. LangGraph 개념 설명)\n",
        "* LangGraph의 개념과 주요 기능을 이해하고, 차이점을 비교합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# poetry add langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sk\n",
            "24\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "print(OPENAI_API_KEY[:2])\n",
        "\n",
        "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
        "print(UPSTAGE_API_KEY[30:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "client=<openai.resources.chat.completions.completions.Completions object at 0x11662e990> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x11662f390> model_name='solar-pro' temperature=0.5 model_kwargs={} upstage_api_key=SecretStr('**********') upstage_api_base='https://api.upstage.ai/v1'\n",
            "**LangGraph**는 **LangChain** 생태계에서 제공하는 **상태(state) 관리가 가능한 그래프 기반 프레임워크**로, 복잡한 LLM(Large Language Model) 애플리케이션의 흐름을 구조화하고 관리할 수 있도록 설계되었습니다.  \n",
            "\n",
            "### 📌 **LangGraph의 핵심 개념**\n",
            "1. **그래프 기반 워크플로우**  \n",
            "   - 노드(Node)와 엣지(Edge)로 구성된 방향성 그래프로, LLM 체인을 시각화/관리합니다.  \n",
            "   - 예: `Chain A → Router → Chain B/C`와 같은 분기 구조 구현 가능.\n",
            "\n",
            "2. **상태(State) 관리**  \n",
            "   - 각 노드 간 전달되는 데이터(`state`)를 자동으로 추적하며, 메모리/데이터베이스와 연동해 장기 상태를 유지할 수 있습니다.  \n",
            "   - 예: 대화 기록, 사용자 프로필 등을 그래프 내에서 유지.\n",
            "\n",
            "3. **확장성**  \n",
            "   - LangChain의 기존 컴포넌트(Chains, Tools, Agents)와 호환되며, 복잡한 애플리케이션을 모듈식으로 구축 가능.\n",
            "\n",
            "4. **실시간 협업 지원**  \n",
            "   - 여러 사용자 세션이나 병렬 처리를 위한 상태 분리 기능을 제공합니다.\n",
            "\n",
            "---\n",
            "\n",
            "### 🛠 **주요 사용 사례**\n",
            "- **대화형 에이전트**: 멀티턴 대화 관리, 상태 기반 응답 생성.  \n",
            "- **업무 자동화**: 조건부 분기(예: \"고객 문의 → 분류 → 해결 방안 제시\").  \n",
            "- **게임/AI 시뮬레이션**: 복잡한 의사결정 트리 구현.  \n",
            "\n",
            "---\n",
            "\n",
            "### 📦 **간단한 예제 코드 (Python)**\n",
            "```python\n",
            "from langgraph import State, BaseGraph\n",
            "\n",
            "class MyGraph(BaseGraph):\n",
            "    def __init__(self):\n",
            "        super().__init__(\"start\", {\"start\": self.start_node})\n",
            "\n",
            "    @classmethod\n",
            "    def start_node(cls, state: State, inputs: dict):\n",
            "        state[\"message\"] = \"Hello from LangGraph!\"\n",
            "        return {\"next\": {\"self\": \"end\"}}\n",
            "\n",
            "    @classmethod\n",
            "    def end_node(cls, state: State, inputs: dict):\n",
            "        return state\n",
            "\n",
            "# 실행\n",
            "graph = MyGraph()\n",
            "state = graph.run({})\n",
            "print(state[\"message\"])  # 출력: \"Hello from LangGraph!\"\n",
            "```\n",
            "\n",
            "---\n",
            "\n",
            "### 🔍 **LangChain과의 차이점**\n",
            "- **LangChain**: 단순한 체인(Chain) 또는 에이전트에 집중.  \n",
            "- **LangGraph**: 상태 관리와 그래프 기반 워크플로우를 추가해 **복잡한 애플리케이션**에 적합.\n",
            "\n",
            "LangGraph는 LLM 기반 시스템의 **확장성**과 **유지보수성**을 높이는 도구로, 특히 다중 단계 프로세스나 실시간 상호작용이 필요한 경우 유용합니다. 공식 문서에서는 [LangGraph GitHub](https://github.com/langchain-ai/langgraph)에서 더 자세한 예제를 확인할 수 있습니다.\n"
          ]
        }
      ],
      "source": [
        "# from langchain_openai import ChatOpenAI\n",
        "\n",
        "# llm = ChatOpenAI(model='gpt-4o-mini') # 테스트의 경우에는 작은 모델을 사용합니다\n",
        "\n",
        "from langchain_upstage import ChatUpstage\n",
        "llm = ChatUpstage(\n",
        "        model=\"solar-pro\",\n",
        "        base_url=\"https://api.upstage.ai/v1\",\n",
        "        temperature=0.5\n",
        "    )\n",
        "print(llm)\n",
        "\n",
        "query = 'LangGraph는 무엇인가요?'\n",
        "ai_msg = llm.invoke(query)\n",
        "print(ai_msg.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LangGraph의 기본개념\n",
        "* `state`는 LangGraph 에이전트의 state를 나타내는 데이터 구조입니다.\n",
        "* `state`는 `TypedDict`를 사용하여 정의되며, 이는 Python의 타입 힌팅을 통해 구조를 명확히 합니다.\n",
        "    * 간단하게 `messages`라는 필드만 있습니다.\n",
        "    * 필요에 따라 다양한 값들을 활용할 수 있습니다.\n",
        "* `state`는 에이전트의 동작을 결정하는 데 사용되며, 각 노드에서 state를 업데이트하거나 참조할 수 있습니다.\n",
        "* `state`는 LangGraph의 노드 간에 전달되며, 에이전트의 state 전이를 관리합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Annotated # 타입 힌트를 사용하기 위해 \n",
        "from typing_extensions import TypedDict # 구조화된 딕셔너리 타입을 정의하기 위해 \n",
        "\n",
        "from langgraph.graph.message import add_messages \n",
        "from langchain_core.messages import AnyMessage # LangChain에서 사용하는 모든 종류의 메시지(예: HumanMessage, AIMessage, ToolMessage)\n",
        "\n",
        "# AgentState는 에이전트의 현재 상태를 나타내는 딕셔너리 타입을 정의합니다.\n",
        "# TypedDict를 사용하면 딕셔너리가 어떤 키와 값 타입을 가져야 하는지 명확하게 지정할 수 있습니다.\n",
        "class AgentState(TypedDict):\n",
        "    # 'messages' 키는 에이전트의 대화 기록을 저장합니다.\n",
        "    # 이 목록에는 LangChain 메시지 객체(AnyMessage)가 들어갑니다.\n",
        "    # LangGraph가 이 상태를 처리할 때, 새로운 메시지가 추가되면\n",
        "    # 기존 메시지 목록의 끝에 자동으로 추가되도록(append) 설정합니다.\n",
        "    messages: list[Annotated[AnyMessage, add_messages]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 위에 선언한 `AgentState`를 활용하여 `StateGraph`를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'langgraph.graph.state.StateGraph'>\n"
          ]
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph\n",
        "\n",
        "graph_builder = StateGraph(AgentState)\n",
        "print(type(graph_builder))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `graph`에 추가할 `node`를 생성합니다\n",
        "-  `node`는 LangGraph에서 실행되는 개별적인 작업 단위를 의미합니다. \n",
        "    - 각 노드는 특정 기능을 수행하는 독립적인 컴포넌트로, 예를 들어 텍스트 생성, 데이터 처리, 또는 의사 결정과 같은 작업을 담당할 수 있습니다.\n",
        "    - `node`는 기본적으로 함수(function)로 정의되고, 뒤에서 다루지만 다른 에이전트(agent)를 활용할 수도 있습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Node 역할을 하는 함수의 인자로 state 객체를 사용함  LLM을 호출하는 노드\n",
        "def generate(state: AgentState) -> AgentState:\n",
        "    \"\"\"\n",
        "    `generate` 노드는 사용자의 질문을 받아서 응답을 생성하는 노드입니다.\n",
        "    \"\"\"\n",
        "    messages = state['messages']\n",
        "    ai_message = llm.invoke(messages)\n",
        "    return {'messages': [ai_message]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `node`를 생성한 후에 `edge`로 연결합니다\n",
        "- `edge`는 노드들 사이의 연결을 나타내며, 데이터와 제어 흐름의 경로를 정의합니다. \n",
        "    - 엣지를 통해 한 노드의 출력이 다음 노드의 입력으로 전달되어, 전체적인 워크플로우가 형성됩니다.\n",
        "    - `node`와 `edge`의 조합은 방향성 그래프(Directed Graph)를 형성하며, 이를 통해 복잡한 AI 에이전트의 행동 흐름을 구조화할 수 있습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x116f29010>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# LLM을 호출하는 generate 함수를 Node로 추가함\n",
        "graph_builder.add_node('generate', generate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 모든 그래프는 `START(시작)`와 `END(종료)`가 있습니다\n",
        "    - `END`를 explicit하게 선언하지 않는 경우도 종종 있지만, 가독성을 위해 작성해주는 것을 권장합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x116f29010>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langgraph.graph import START, END\n",
        "\n",
        "graph_builder.add_edge(START, 'generate')\n",
        "graph_builder.add_edge('generate', END)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `node`를 생성하고 `edge`로 연결한 후에 `compile` 메서드를 호출하여 `Graph`를 생성합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'langgraph.graph.state.CompiledStateGraph'>\n"
          ]
        }
      ],
      "source": [
        "graph = graph_builder.compile()\n",
        "print(type(graph))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `compile` 후에는 그래프를 시각화하여 확인할 수 있습니다\n",
        "- 의도한대로 그래프가 생성됐는지 확인하는 습관을 기르는 것이 좋습니다\n",
        "    - `git`에서 코드 작업물을 commit하기 전에 `git diff`를 통해 변경사항을 확인하는 것과 같습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "#from IPython.display import display, Image\n",
        "\n",
        "#display(Image(graph.get_graph().draw_mermaid_png(max_retries=5, retry_delay=2.0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mermaid Code:\n",
            "---\n",
            "config:\n",
            "  flowchart:\n",
            "    curve: linear\n",
            "---\n",
            "graph TD;\n",
            "\t__start__([<p>__start__</p>]):::first\n",
            "\tgenerate(generate)\n",
            "\t__end__([<p>__end__</p>]):::last\n",
            "\t__start__ --> generate;\n",
            "\tgenerate --> __end__;\n",
            "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
            "\tclassDef first fill-opacity:0\n",
            "\tclassDef last fill:#bfb6fc\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 대체 방법\n",
        "mermaid_code = graph.get_graph().draw_mermaid()\n",
        "print(\"Mermaid Code:\")\n",
        "print(mermaid_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* https://mermaid.live/ 에서  mermain_code 로 직접 확인한다.\n",
        "\n",
        "* [Graph 이미지](https://mermaidchart.com/play?utm_source=mermaid_live_editor&utm_medium=share#pako:eNpVkN1ugjAUx1-lObvRBLCAVq3Gm_kIu9q6mAqn0AwKKSWZM777KirR3vR8_f7n4wxZkyNwKKxsS_Kx3wgj3OHQOWn9N_natrvR287a3feUc6607dy1sECDVjqcPIzpDUeTj_Bgj2glb-QoSsJwRx745ll0yNz5IZF5uNujIjkq2VeOKF1V_E0liioVVNpgWKIuSsfjKHkBhoGH8rBpZabdidOXgutYd7mjOjKVQeBPonPgzvYYQI22llcXzsIQIsCVWKMA7s1c2h8Bwlw800rz2TT1A7NNX5TAlaw67_Vt7tfaa-mPXY9R6xdE-970xgFP4kED-Bl-gaeURYyyNEmXbJGuaDIP4OTDLIqT-XoVp2tK54ytLwH8DV1ptFou6NOLL_-94J8W) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "<class 'langchain_core.messages.ai.AIMessage'>\n",
            "[AIMessage(content='**LangGraph**와 **LangChain**은 모두 LLM(Large Language Model) 기반 애플리케이션 개발을 위한 프레임워크이지만, 목적과 적용 범위에서 차이가 있습니다. 아래에 각 도구의 특징과 차이점을 정리했습니다.\\n\\n---\\n\\n### **1. LangChain이란?**\\n- **정의**: LangChain은 LLM을 활용해 복잡한 애플리케이션을 구축할 수 있도록 돕는 **모듈형 프레임워크**입니다.\\n- **주요 기능**:\\n  - **모듈 조합**: 프롬프트 관리, 체인(Chain), 메모리, 검색(Retrieval), 에이전트(Agent) 등 다양한 컴포넌트를 조합해 유연한 파이프라인 구성 가능.\\n  - **다양한 LLM 지원**: OpenAI, Anthropic, Llama 등 다양한 모델과 호환.\\n  - **유스 케이스**: 챗봇, 문서 분석, 요약, QA 시스템 등 **단일 또는 순차적 작업**에 최적화.\\n- **예시**:  \\n  ```python\\n  from langchain.chains import LLMChain\\n  from langchain.prompts import PromptTemplate\\n  from langchain.llms import OpenAI\\n\\n  llm = OpenAI(model_name=\"gpt-3.5-turbo\")\\n  prompt = PromptTemplate(input_variables=[\"topic\"], template=\"설명해 주세요: {topic}\")\\n  chain = LLMChain(llm=llm, prompt=prompt)\\n  chain.run(\"기후 변화\")\\n  ```\\n\\n---\\n\\n### **2. LangGraph란?**\\n- **정의**: LangGraph는 **상태(State)가 있는 복잡한 워크플로우**를 구축하기 위한 **LangChain의 확장 도구**입니다.  \\n  - 그래프 기반의 상태 머신(State Machine)을 지원해 **다중 단계, 분기, 순환 작업**을 모델링할 수 있습니다.\\n- **주요 기능**:\\n  - **상태 관리**: 각 노드(LLM 호출 또는 외부 작업) 간 상태(State)를 유지하며 복잡한 흐름 제어 가능.\\n  - **동적 라우팅**: 조건에 따라 다른 경로로 분기하거나 반복 작업 처리 가능 (예: 다단계 대화, 의사 결정 트리).\\n  - **시각적 표현**: 그래프 구조로 워크플로우를 시각화해 디버깅 용이.\\n- **예시**:  \\n  ```python\\n  from langgraph import State, BaseGraph, ToolsNode\\n\\n  class MyState(State):\\n      counter: int = 0\\n\\n  graph_definition = (\\n      BaseGraph(MyState)\\n      .add_node(\"llm\", ToolsNode(...))  # LLM 또는 외부 도구 연결\\n      .add_edge(match={\"counter\": lambda s: s.counter < 3}, source=\"llm\", target=\"llm\")\\n      .add_edge(match={\"counter\": lambda s: s.counter >= 3}, source=\"llm\", target=\"end\")\\n  )\\n  ```\\n\\n---\\n\\n### **3. LangChain vs. LangGraph 차이점**\\n| **기준**       | **LangChain**                          | **LangGraph**                          |\\n|----------------|----------------------------------------|----------------------------------------|\\n| **목적**       | 단순한 LLM 체인 또는 에이전트 구축     | 복잡한 상태 기반 워크플로우 관리        |\\n| **구조**       | 선형 또는 분기 체인                    | 그래프 기반 상태 머신                  |\\n| **상태 관리**  | 제한적 (메모리 모듈로 보완 가능)       | 명시적 상태(State) 지원                |\\n| **유연성**     | 빠른 프로토타이핑에 적합               | 다단계/반복 작업에 최적화              |\\n| **사용 사례**  | 챗봇, 단일 QA 시스템                   | 다단계 대화, 의사 결정 시스템, 게임 AI |\\n\\n---\\n\\n### **4. 함께 사용하는 경우**\\n- LangGraph는 LangChain의 컴포넌트(예: LLMChain, Tools)를 노드로 활용할 수 있어 **통합 활용**이 가능합니다.  \\n  예: LangChain으로 개별 모듈을 만들고, LangGraph로 전체 워크플로우를 구성.\\n\\n---\\n\\n### **요약**\\n- **LangChain**은 LLM 애플리케이션의 **기본 빌딩 블록**을 제공하는 반면,  \\n- **LangGraph**는 LangChain의 컴포넌트를 활용해 **복잡한 상태 머신**을 구축할 때 사용됩니다.  \\n- **단순한 작업**에는 LangChain, **다단계/분기 작업**에는 LangGraph가 적합합니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 825, 'prompt_tokens': 25, 'total_tokens': 850, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '52ca083f-3836-4d94-b953-abe017b57342', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--1c604473-9183-4538-bc38-1024dae62f7d-0', usage_metadata={'input_tokens': 25, 'output_tokens': 825, 'total_tokens': 850, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "query = 'LangGraph는 무엇인가요? LangChain과의 차이점은 무엇인가요?'\n",
        "initial_state = {'messages': [HumanMessage(query)]}\n",
        "result = graph.invoke(initial_state)\n",
        "\n",
        "print(type(result))\n",
        "print(type(result['messages'][0]))\n",
        "print(result['messages'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2개의 AI 에이전트 협력하기\n",
        "* 첫번째 AI 에이전트\n",
        "    * 사용자의 질문을 분석하고 핵심 키워드와 배경 정보를 추가하는 역할\n",
        "* 두번째 AI 에이전트\n",
        "    * 첫번째 에이전트가 제공한 정보를 기반으로 좀 더 자세한 답변을 생성하는 역할    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "solar-pro\n"
          ]
        }
      ],
      "source": [
        "print(llm.model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph\n",
        "from pprint import pprint\n",
        "\n",
        "#첫번째 AI 에이전트\n",
        "def agent_1(state):\n",
        "    \"\"\"사용자의 질문을 분석하고 핵심 키워드아 배경 정보를 추가하는 역할\"\"\"\n",
        "    query = state['query']\n",
        "    \n",
        "    keywords = llm.invoke(f'질문: {query}\\n 이 질문에서 핵심 키워드를 3~5개 추출해 주세요.')\n",
        "\n",
        "     # 질문과 관련된 배경 정보 제공\n",
        "    background_info = llm.invoke(f\"질문: {query}\\n 이 질문을 이해하는 데 도움이 될 만한 추가 정보를 제공해 주세요.\")\n",
        "\n",
        "    print(f\"\\n[Agent 1] 원본 질문: {query}\")\n",
        "    print(f\"[Agent 1] 핵심 키워드: {keywords}\")\n",
        "    print(f\"[Agent 1] 배경 정보: {background_info}\\n\")\n",
        "\n",
        "    return {\"refined_query\": query, \"keywords\": keywords, \"background_info\": background_info}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 두번째 AI 에이전트\n",
        "def agent_2(state):\n",
        "    \"\"\"첫번째 에이전트가 제공한 정보를 기반으로 좀 더 자세한 답변을 생성하는 역할\"\"\"\n",
        "    refined_query = state['refined_query']\n",
        "    keywords = state['keywords']\n",
        "    background_info = state['background_info']\n",
        "\n",
        "    # Agent 1이 제공한 정보를 활용하여 최종 답변 생성\n",
        "    final_response = llm.invoke(\n",
        "        f\"질문: {refined_query}\\n\"\n",
        "        f\"핵심 키워드: {keywords}\\n\"\n",
        "        f\"배경 정보: {background_info}\\n\"\n",
        "        f\"위 정보를 바탕으로 질문에 대한 깊이 있는 답변을 작성해 주세요.\"\n",
        "    )\n",
        "\n",
        "    print(f\"[Agent 2] 최종 답변 생성 완료\\n\")\n",
        "    \n",
        "    return {\"final_answer\": final_response}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'langgraph.graph.state.StateGraph'>\n",
            "{<class 'dict'>: {'__root__': <langgraph.channels.last_value.LastValue object at 0x1166689c0>}}\n"
          ]
        }
      ],
      "source": [
        "# WorkFlow 역할을 하는 StateGraph 객체를 생성하기\n",
        "workflow = StateGraph(dict)\n",
        "\n",
        "print(type(workflow))\n",
        "print(workflow.schemas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'agent_1': StateNodeSpec(runnable=agent_1(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None, input_schema=<class 'dict'>, retry_policy=None, cache_policy=None, ends=(), defer=False),\n",
              " 'agent_2': StateNodeSpec(runnable=agent_2(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None, input_schema=<class 'dict'>, retry_policy=None, cache_policy=None, ends=(), defer=False)}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# WorkFlow에 Node 추가하기\n",
        "workflow.add_node(\"agent_1\", agent_1)\n",
        "workflow.add_node(\"agent_2\", agent_2)\n",
        "\n",
        "workflow.nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{('agent_1', 'agent_2'), ('__start__', 'agent_1')}\n"
          ]
        }
      ],
      "source": [
        "# WorkFlow에 Edge 추가하기\n",
        "# agent_1이 먼저 실행됨\n",
        "workflow.set_entry_point(\"agent_1\")\n",
        "# agent_1 -> agent_2\n",
        "workflow.add_edge(\"agent_1\",\"agent_2\")\n",
        "\n",
        "print(workflow.edges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'langgraph.graph.state.CompiledStateGraph'>\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x117208a50>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph = workflow.compile()\n",
        "\n",
        "print(type(graph))\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---\n",
            "config:\n",
            "  flowchart:\n",
            "    curve: linear\n",
            "---\n",
            "graph TD;\n",
            "\t__start__([<p>__start__</p>]):::first\n",
            "\tagent_1(agent_1)\n",
            "\tagent_2(agent_2)\n",
            "\t__end__([<p>__end__</p>]):::last\n",
            "\t__start__ --> agent_1;\n",
            "\tagent_1 --> agent_2;\n",
            "\tagent_2 --> __end__;\n",
            "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
            "\tclassDef first fill-opacity:0\n",
            "\tclassDef last fill:#bfb6fc\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mermaid_code = graph.get_graph().draw_mermaid()\n",
        "print(mermaid_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Agent 1] 원본 질문: LangGraph는 무엇이며, LangChain과 어떤 차이점이 있나요? 그리고 LangGraph를 사용해야 하는 이유는 무엇인가요?\n",
            "[Agent 1] 핵심 키워드: content='핵심 키워드:  \\n1. **LangGraph**  \\n2. **LangChain**  \\n3. **차이점**  \\n4. **사용 이유**  \\n\\n(추가로 \"워크플로우 관리\"나 \"상태 기반 추론\"을 포함할 수도 있지만, 질문의 핵심 요구사항을 고려해 4개로 압축했습니다.)' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 49, 'total_tokens': 110, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '3b9fec8c-c7cf-4818-a70b-bc14f1c2650e', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--bfbe0731-f5e7-4113-ad2d-987b7f82e18d-0' usage_metadata={'input_tokens': 49, 'output_tokens': 61, 'total_tokens': 110, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "[Agent 1] 배경 정보: content='### **LangGraph란 무엇인가요?**\\nLangGraph는 **대규모 언어 모델(LLM)을 활용한 복잡한 상태 기반 애플리케이션**을 구축하기 위한 프레임워크로, **LangChain의 확장 도구**입니다. 주로 다음과 같은 특징을 가집니다:\\n- **상태(State) 관리**: 대화 기록, 메모리, 외부 데이터 소스 등을 추적하며 다단계 작업을 처리합니다.\\n- **그래프 기반 워크플로우**: 노드(LLM 호출, 툴킷, 조건 분기 등)와 엣지(상태 전이)로 구성된 **유한 상태 머신(FSM)** 또는 **상태 그래프**를 정의할 수 있습니다.\\n- **LangChain과의 통합**: LangChain의 컴포넌트(체이너, 에이전트, 메모리 등)를 LangGraph에서 재사용할 수 있습니다.\\n\\n---\\n\\n### **LangChain vs. LangGraph 차이점**\\n| **기준**       | **LangChain**                          | **LangGraph**                          |\\n|----------------|----------------------------------------|----------------------------------------|\\n| **주요 목적**  | 단일/단순 LLM 워크플로우 (예: Q&A, 요약) | 복잡한 다단계 상태 기반 애플리케이션 (예: 대화형 에이전트, 태스크 자동화) |\\n| **구조**       | 선형 체이닝, 에이전트, 메모리 관리      | 상태 그래프 (노드 + 엣지로 정의)       |\\n| **상태 관리**  | 제한적 (메모리 모듈로 부분적 지원)      | 명시적 상태 추적 (JSON/딕셔너리 기반)   |\\n| **유연성**     | 빠른 프로토타이핑에 적합               | 복잡한 분기/루프 로직 구현에 최적화     |\\n| **예시**       | 문서 Q&A, 번역 파이프라인              | 대화형 쇼핑 어시스턴트, 멀티스텝 문제 해결 |\\n\\n---\\n\\n### **LangGraph를 사용해야 하는 이유**\\n1. **복잡한 워크플로우 단순화**  \\n   - 예를 들어, 사용자 질문에 따라 다른 API를 호출하거나, 이전 대화 기록을 기반으로 다음 단계를 결정하는 애플리케이션을 쉽게 설계할 수 있습니다.\\n\\n2. **상태 기반 로직 구현**  \\n   - `if-then-else` 조건, 루프, 외부 데이터 연동(예: 데이터베이스 조회)이 필요한 경우 LangGraph의 상태 전이 메커니즘이 유용합니다.\\n\\n3. **확장성**  \\n   - LangChain의 모든 컴포넌트(LLM, 툴, 메모리)를 LangGraph에 통합할 수 있어 기존 코드 재사용이 가능합니다.\\n\\n4. **디버깅 및 시각화**  \\n   - 그래프 구조를 시각화하여 워크플로우의 흐름을 명확히 이해할 수 있습니다.\\n\\n---\\n\\n### **추가 정보: LangGraph 사용 사례**\\n1. **대화형 에이전트**  \\n   - 사용자가 \"항공권 예약\" → \"호텔 확인\" → \"결제 진행\"과 같은 다단계 작업을 수행할 때 각 단계를 상태로 관리합니다.\\n\\n2. **문서 분석 파이프라인**  \\n   - PDF 분석 → 키워드 추출 → 데이터베이스 저장 → 요약 생성과 같은 작업을 상태 그래프로 연결합니다.\\n\\n3. **게임/시뮬레이션**  \\n   - LLM 기반 캐릭터와의 상호작용에서 이전 대화 기록을 유지하며 플롯을 전개합니다.\\n\\n---\\n\\n### **예제 코드 (간단한 LangGraph)**\\n```python\\nfrom langgraph import State, BaseGraph, Endpoint\\n\\nclass MyGraph(BaseGraph):\\n    @State()\\n    def start(self):\\n        return {\"next\": \"ask_question\"}\\n\\n    @Endpoint()\\n    def ask_question(self, state: State):\\n        # LLM 호출 또는 사용자 입력 처리\\n        response = \"What\\'s your name?\"\\n        state[\"name\"] = response  # 상태 업데이트\\n        return {\"next\": \"greet_user\"}\\n\\n    @Endpoint()\\n    def greet_user(self, state: State):\\n        print(f\"Hello, {state[\\'name\\']}!\")\\n\\n# 그래프 실행\\ngraph = MyGraph()\\ngraph.run()\\n```\\n\\n---\\n\\n### **참고 자료**\\n- [LangGraph 공식 문서](https://langchain-ai.github.io/langgraph/)\\n- [LangChain vs. LangGraph 비교 글](https://python.langchain.com/docs/langgraph/getting_started/introduction)  \\n- GitHub: [LangGraph 저장소](https://github.com/langchain-ai/langgraph)\\n\\nLangGraph는 **복잡한 상태 관리가 필요한 애플리케이션**에서 빛을 발하며, LangChain의 단순한 체이닝으로는 구현하기 어려운 시나리오를 처리할 때 유용합니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 833, 'prompt_tokens': 49, 'total_tokens': 882, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '138df2b6-24a1-4fdb-81ab-d79cd6c4d50d', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--ba525105-907d-4000-8ca8-eb907d8249eb-0' usage_metadata={'input_tokens': 49, 'output_tokens': 833, 'total_tokens': 882, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "\n",
            "[Agent 2] 최종 답변 생성 완료\n",
            "\n",
            "{'final_answer': AIMessage(content='### **LangGraph와 LangChain의 차이점 및 LangGraph 사용 이유**\\n\\n#### 1. **LangGraph란?**  \\nLangGraph는 **상태(State) 기반의 복잡한 워크플로우**를 구축하기 위한 프레임워크로, LangChain의 확장 도구입니다.  \\n- **핵심 기능**:  \\n  - **상태 관리**: 대화 기록, 외부 데이터, 사용자 입력 등을 JSON/딕셔너리 형태로 추적합니다.  \\n  - **그래프 기반 구조**: 노드(LLM 호출, 툴킷, 조건 분기)와 엣지(상태 전이)로 구성된 유한 상태 머신(FSM)을 정의합니다.  \\n  - **시각적 디버깅**: 워크플로우를 그래프 형태로 시각화하여 복잡한 로직을 명확히 이해할 수 있습니다.  \\n\\n#### 2. **LangChain vs. LangGraph: 주요 차이점**  \\n| **기준**       | **LangChain**                          | **LangGraph**                          |\\n|----------------|----------------------------------------|----------------------------------------|\\n| **목적**       | 단순/단일 LLM 작업 (Q&A, 요약)         | 다단계 상태 기반 애플리케이션 (대화형 에이전트, 태스크 자동화) |\\n| **구조**       | 선형 체이닝, 에이전트, 메모리           | 상태 그래프 (노드 + 엣지)              |\\n| **상태 관리**  | 제한적 (메모리 모듈로 부분적 지원)      | 명시적 상태 추적 (JSON 기반)           |\\n| **유연성**     | 빠른 프로토타이핑에 적합               | 분기/루프/조건 로직에 최적화           |\\n| **예시**       | 문서 Q&A, 번역 파이프라인              | 대화형 쇼핑 어시스턴트, 멀티스텝 문제 해결 |\\n\\n#### 3. **LangGraph를 사용해야 하는 이유**  \\n**(1) 복잡한 워크플로우 단순화**  \\n- **예시**:  \\n  - 사용자 질문에 따라 다른 API 호출 (예: \"날씨 알려줘\" → 날씨 API, \"예약 변경\" → 예약 시스템 연동).  \\n  - 대화 기록을 기반으로 다음 단계 결정 (예: 이전 대화에서 호텔 예약 완료 → 이제 항공권 추천).  \\n\\n**(2) 상태 기반 로직 구현**  \\n- **조건 분기**: `if-then-else` 로직을 상태 전이로 표현 (예: 사용자 입력이 \"예\" → 다음 단계, \"아니오\" → 종료).  \\n- **루프 처리**: 특정 조건을 만족할 때까지 반복 작업 (예: \"다시 시도\" → 이전 단계로 복귀).  \\n- **외부 데이터 연동**: 데이터베이스 조회 결과를 상태에 저장하여 다음 단계에 활용.  \\n\\n**(3) 확장성**  \\n- LangChain의 모든 컴포넌트(LLM, 툴, 메모리)를 LangGraph에 통합할 수 있어 기존 코드 재사용이 가능합니다.  \\n- **예시**: LangChain의 `RetrievalQA` 체이닝을 LangGraph의 노드로 활용.  \\n\\n**(4) 디버깅 및 시각화**  \\n- 그래프 구조를 시각화 도구(예: LangSmith)로 모니터링하여 복잡한 흐름을 명확히 파악할 수 있습니다.  \\n\\n#### 4. **사용 사례**  \\n- **대화형 에이전트**:  \\n  - \"항공권 예약\" → \"호텔 확인\" → \"결제 진행\"과 같은 다단계 작업을 상태 그래프로 관리.  \\n- **문서 분석 파이프라인**:  \\n  - PDF 분석 → 키워드 추출 → 데이터베이스 저장 → 요약 생성.  \\n- **게임/시뮬레이션**:  \\n  - LLM 기반 캐릭터와의 상호작용에서 이전 대화 기록을 유지하며 플롯 전개.  \\n\\n#### 5. **예제 코드**  \\n```python\\nfrom langgraph import State, BaseGraph, Endpoint\\n\\nclass BookingGraph(BaseGraph):\\n    @State()\\n    def start(self):\\n        return {\"next\": \"ask_destination\"}\\n\\n    @Endpoint()\\n    def ask_destination(self, state: State):\\n        state[\"destination\"] = \"파리\"  # 사용자 입력 또는 LLM 생성\\n        return {\"next\": \"check_flight\"}\\n\\n    @Endpoint()\\n    def check_flight(self, state: State):\\n        # 외부 API 호출 (예: 항공권 조회)\\n        state[\"flight_available\"] = True\\n        return {\"next\": \"confirm_booking\"}\\n\\n    @Endpoint()\\n    def confirm_booking(self, state: State):\\n        if state[\"flight_available\"]:\\n            print(f\"{state[\\'destination\\']} 행 항공권 예약 완료!\")\\n        else:\\n            print(\"예약 가능한 항공권이 없습니다.\")\\n\\n# 그래프 실행\\ngraph = BookingGraph()\\ngraph.run()\\n```\\n\\n#### 6. **결론: LangGraph가 필요한 경우**  \\n- **LangChain으로 부족한 경우**:  \\n  - 단순한 체이닝으로는 구현할 수 없는 복잡한 분기/루프 로직이 필요할 때.  \\n  - 대화 기록이나 외부 데이터를 기반으로 동적 워크플로우를 설계해야 할 때.  \\n- **LangGraph의 강점**:  \\n  - 상태 관리를 통해 **확장성**과 **유지보수성**을 높이면서도, LangChain의 유연성을 그대로 활용할 수 있습니다.  \\n\\n> 🔍 **참고**: LangGraph는 LangChain의 \"상태 관리 확장판\"으로, 복잡한 애플리케이션에서 진정한 힘을 발휘합니다. 공식 문서와 예제 코드를 통해 실제 구현 방식을 익히는 것이 중요합니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1018, 'prompt_tokens': 1642, 'total_tokens': 2660, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '54676159-8d0b-4578-a350-b0c29391d1f4', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--939dabae-4067-4d40-8dc5-eca8d0026b78-0', usage_metadata={'input_tokens': 1642, 'output_tokens': 1018, 'total_tokens': 2660, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n"
          ]
        }
      ],
      "source": [
        "# Graph 호출하기\n",
        "query = \"LangGraph는 무엇이며, LangChain과 어떤 차이점이 있나요? 그리고 LangGraph를 사용해야 하는 이유는 무엇인가요?\"\n",
        "\n",
        "state = {\"query\": query}\n",
        "result = graph.invoke(state)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'final_answer': AIMessage(content='### **LangGraph와 LangChain의 차이점 및 LangGraph 사용 이유**\\n\\n#### 1. **LangGraph란?**  \\nLangGraph는 **상태(State) 기반의 복잡한 워크플로우**를 구축하기 위한 프레임워크로, LangChain의 확장 도구입니다.  \\n- **핵심 기능**:  \\n  - **상태 관리**: 대화 기록, 외부 데이터, 사용자 입력 등을 JSON/딕셔너리 형태로 추적합니다.  \\n  - **그래프 기반 구조**: 노드(LLM 호출, 툴킷, 조건 분기)와 엣지(상태 전이)로 구성된 유한 상태 머신(FSM)을 정의합니다.  \\n  - **시각적 디버깅**: 워크플로우를 그래프 형태로 시각화하여 복잡한 로직을 명확히 이해할 수 있습니다.  \\n\\n#### 2. **LangChain vs. LangGraph: 주요 차이점**  \\n| **기준**       | **LangChain**                          | **LangGraph**                          |\\n|----------------|----------------------------------------|----------------------------------------|\\n| **목적**       | 단순/단일 LLM 작업 (Q&A, 요약)         | 다단계 상태 기반 애플리케이션 (대화형 에이전트, 태스크 자동화) |\\n| **구조**       | 선형 체이닝, 에이전트, 메모리           | 상태 그래프 (노드 + 엣지)              |\\n| **상태 관리**  | 제한적 (메모리 모듈로 부분적 지원)      | 명시적 상태 추적 (JSON 기반)           |\\n| **유연성**     | 빠른 프로토타이핑에 적합               | 분기/루프/조건 로직에 최적화           |\\n| **예시**       | 문서 Q&A, 번역 파이프라인              | 대화형 쇼핑 어시스턴트, 멀티스텝 문제 해결 |\\n\\n#### 3. **LangGraph를 사용해야 하는 이유**  \\n**(1) 복잡한 워크플로우 단순화**  \\n- **예시**:  \\n  - 사용자 질문에 따라 다른 API 호출 (예: \"날씨 알려줘\" → 날씨 API, \"예약 변경\" → 예약 시스템 연동).  \\n  - 대화 기록을 기반으로 다음 단계 결정 (예: 이전 대화에서 호텔 예약 완료 → 이제 항공권 추천).  \\n\\n**(2) 상태 기반 로직 구현**  \\n- **조건 분기**: `if-then-else` 로직을 상태 전이로 표현 (예: 사용자 입력이 \"예\" → 다음 단계, \"아니오\" → 종료).  \\n- **루프 처리**: 특정 조건을 만족할 때까지 반복 작업 (예: \"다시 시도\" → 이전 단계로 복귀).  \\n- **외부 데이터 연동**: 데이터베이스 조회 결과를 상태에 저장하여 다음 단계에 활용.  \\n\\n**(3) 확장성**  \\n- LangChain의 모든 컴포넌트(LLM, 툴, 메모리)를 LangGraph에 통합할 수 있어 기존 코드 재사용이 가능합니다.  \\n- **예시**: LangChain의 `RetrievalQA` 체이닝을 LangGraph의 노드로 활용.  \\n\\n**(4) 디버깅 및 시각화**  \\n- 그래프 구조를 시각화 도구(예: LangSmith)로 모니터링하여 복잡한 흐름을 명확히 파악할 수 있습니다.  \\n\\n#### 4. **사용 사례**  \\n- **대화형 에이전트**:  \\n  - \"항공권 예약\" → \"호텔 확인\" → \"결제 진행\"과 같은 다단계 작업을 상태 그래프로 관리.  \\n- **문서 분석 파이프라인**:  \\n  - PDF 분석 → 키워드 추출 → 데이터베이스 저장 → 요약 생성.  \\n- **게임/시뮬레이션**:  \\n  - LLM 기반 캐릭터와의 상호작용에서 이전 대화 기록을 유지하며 플롯 전개.  \\n\\n#### 5. **예제 코드**  \\n```python\\nfrom langgraph import State, BaseGraph, Endpoint\\n\\nclass BookingGraph(BaseGraph):\\n    @State()\\n    def start(self):\\n        return {\"next\": \"ask_destination\"}\\n\\n    @Endpoint()\\n    def ask_destination(self, state: State):\\n        state[\"destination\"] = \"파리\"  # 사용자 입력 또는 LLM 생성\\n        return {\"next\": \"check_flight\"}\\n\\n    @Endpoint()\\n    def check_flight(self, state: State):\\n        # 외부 API 호출 (예: 항공권 조회)\\n        state[\"flight_available\"] = True\\n        return {\"next\": \"confirm_booking\"}\\n\\n    @Endpoint()\\n    def confirm_booking(self, state: State):\\n        if state[\"flight_available\"]:\\n            print(f\"{state[\\'destination\\']} 행 항공권 예약 완료!\")\\n        else:\\n            print(\"예약 가능한 항공권이 없습니다.\")\\n\\n# 그래프 실행\\ngraph = BookingGraph()\\ngraph.run()\\n```\\n\\n#### 6. **결론: LangGraph가 필요한 경우**  \\n- **LangChain으로 부족한 경우**:  \\n  - 단순한 체이닝으로는 구현할 수 없는 복잡한 분기/루프 로직이 필요할 때.  \\n  - 대화 기록이나 외부 데이터를 기반으로 동적 워크플로우를 설계해야 할 때.  \\n- **LangGraph의 강점**:  \\n  - 상태 관리를 통해 **확장성**과 **유지보수성**을 높이면서도, LangChain의 유연성을 그대로 활용할 수 있습니다.  \\n\\n> 🔍 **참고**: LangGraph는 LangChain의 \"상태 관리 확장판\"으로, 복잡한 애플리케이션에서 진정한 힘을 발휘합니다. 공식 문서와 예제 코드를 통해 실제 구현 방식을 익히는 것이 중요합니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1018, 'prompt_tokens': 1642, 'total_tokens': 2660, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '54676159-8d0b-4578-a350-b0c29391d1f4', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--939dabae-4067-4d40-8dc5-eca8d0026b78-0', usage_metadata={'input_tokens': 1642, 'output_tokens': 1018, 'total_tokens': 2660, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n"
          ]
        }
      ],
      "source": [
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('### **LangGraph와 LangChain의 차이점 및 LangGraph 사용 이유**\\n'\n",
            " '\\n'\n",
            " '#### 1. **LangGraph란?**  \\n'\n",
            " 'LangGraph는 **상태(State) 기반의 복잡한 워크플로우**를 구축하기 위한 프레임워크로, LangChain의 확장 '\n",
            " '도구입니다.  \\n'\n",
            " '- **핵심 기능**:  \\n'\n",
            " '  - **상태 관리**: 대화 기록, 외부 데이터, 사용자 입력 등을 JSON/딕셔너리 형태로 추적합니다.  \\n'\n",
            " '  - **그래프 기반 구조**: 노드(LLM 호출, 툴킷, 조건 분기)와 엣지(상태 전이)로 구성된 유한 상태 머신(FSM)을 '\n",
            " '정의합니다.  \\n'\n",
            " '  - **시각적 디버깅**: 워크플로우를 그래프 형태로 시각화하여 복잡한 로직을 명확히 이해할 수 있습니다.  \\n'\n",
            " '\\n'\n",
            " '#### 2. **LangChain vs. LangGraph: 주요 차이점**  \\n'\n",
            " '| **기준**       | **LangChain**                          | '\n",
            " '**LangGraph**                          |\\n'\n",
            " '|----------------|----------------------------------------|----------------------------------------|\\n'\n",
            " '| **목적**       | 단순/단일 LLM 작업 (Q&A, 요약)         | 다단계 상태 기반 애플리케이션 (대화형 '\n",
            " '에이전트, 태스크 자동화) |\\n'\n",
            " '| **구조**       | 선형 체이닝, 에이전트, 메모리           | 상태 그래프 (노드 + 엣지)              '\n",
            " '|\\n'\n",
            " '| **상태 관리**  | 제한적 (메모리 모듈로 부분적 지원)      | 명시적 상태 추적 (JSON 기반)           |\\n'\n",
            " '| **유연성**     | 빠른 프로토타이핑에 적합               | 분기/루프/조건 로직에 최적화           |\\n'\n",
            " '| **예시**       | 문서 Q&A, 번역 파이프라인              | 대화형 쇼핑 어시스턴트, 멀티스텝 문제 해결 |\\n'\n",
            " '\\n'\n",
            " '#### 3. **LangGraph를 사용해야 하는 이유**  \\n'\n",
            " '**(1) 복잡한 워크플로우 단순화**  \\n'\n",
            " '- **예시**:  \\n'\n",
            " '  - 사용자 질문에 따라 다른 API 호출 (예: \"날씨 알려줘\" → 날씨 API, \"예약 변경\" → 예약 시스템 연동).  \\n'\n",
            " '  - 대화 기록을 기반으로 다음 단계 결정 (예: 이전 대화에서 호텔 예약 완료 → 이제 항공권 추천).  \\n'\n",
            " '\\n'\n",
            " '**(2) 상태 기반 로직 구현**  \\n'\n",
            " '- **조건 분기**: `if-then-else` 로직을 상태 전이로 표현 (예: 사용자 입력이 \"예\" → 다음 단계, \"아니오\" → '\n",
            " '종료).  \\n'\n",
            " '- **루프 처리**: 특정 조건을 만족할 때까지 반복 작업 (예: \"다시 시도\" → 이전 단계로 복귀).  \\n'\n",
            " '- **외부 데이터 연동**: 데이터베이스 조회 결과를 상태에 저장하여 다음 단계에 활용.  \\n'\n",
            " '\\n'\n",
            " '**(3) 확장성**  \\n'\n",
            " '- LangChain의 모든 컴포넌트(LLM, 툴, 메모리)를 LangGraph에 통합할 수 있어 기존 코드 재사용이 가능합니다.  \\n'\n",
            " '- **예시**: LangChain의 `RetrievalQA` 체이닝을 LangGraph의 노드로 활용.  \\n'\n",
            " '\\n'\n",
            " '**(4) 디버깅 및 시각화**  \\n'\n",
            " '- 그래프 구조를 시각화 도구(예: LangSmith)로 모니터링하여 복잡한 흐름을 명확히 파악할 수 있습니다.  \\n'\n",
            " '\\n'\n",
            " '#### 4. **사용 사례**  \\n'\n",
            " '- **대화형 에이전트**:  \\n'\n",
            " '  - \"항공권 예약\" → \"호텔 확인\" → \"결제 진행\"과 같은 다단계 작업을 상태 그래프로 관리.  \\n'\n",
            " '- **문서 분석 파이프라인**:  \\n'\n",
            " '  - PDF 분석 → 키워드 추출 → 데이터베이스 저장 → 요약 생성.  \\n'\n",
            " '- **게임/시뮬레이션**:  \\n'\n",
            " '  - LLM 기반 캐릭터와의 상호작용에서 이전 대화 기록을 유지하며 플롯 전개.  \\n'\n",
            " '\\n'\n",
            " '#### 5. **예제 코드**  \\n'\n",
            " '```python\\n'\n",
            " 'from langgraph import State, BaseGraph, Endpoint\\n'\n",
            " '\\n'\n",
            " 'class BookingGraph(BaseGraph):\\n'\n",
            " '    @State()\\n'\n",
            " '    def start(self):\\n'\n",
            " '        return {\"next\": \"ask_destination\"}\\n'\n",
            " '\\n'\n",
            " '    @Endpoint()\\n'\n",
            " '    def ask_destination(self, state: State):\\n'\n",
            " '        state[\"destination\"] = \"파리\"  # 사용자 입력 또는 LLM 생성\\n'\n",
            " '        return {\"next\": \"check_flight\"}\\n'\n",
            " '\\n'\n",
            " '    @Endpoint()\\n'\n",
            " '    def check_flight(self, state: State):\\n'\n",
            " '        # 외부 API 호출 (예: 항공권 조회)\\n'\n",
            " '        state[\"flight_available\"] = True\\n'\n",
            " '        return {\"next\": \"confirm_booking\"}\\n'\n",
            " '\\n'\n",
            " '    @Endpoint()\\n'\n",
            " '    def confirm_booking(self, state: State):\\n'\n",
            " '        if state[\"flight_available\"]:\\n'\n",
            " '            print(f\"{state[\\'destination\\']} 행 항공권 예약 완료!\")\\n'\n",
            " '        else:\\n'\n",
            " '            print(\"예약 가능한 항공권이 없습니다.\")\\n'\n",
            " '\\n'\n",
            " '# 그래프 실행\\n'\n",
            " 'graph = BookingGraph()\\n'\n",
            " 'graph.run()\\n'\n",
            " '```\\n'\n",
            " '\\n'\n",
            " '#### 6. **결론: LangGraph가 필요한 경우**  \\n'\n",
            " '- **LangChain으로 부족한 경우**:  \\n'\n",
            " '  - 단순한 체이닝으로는 구현할 수 없는 복잡한 분기/루프 로직이 필요할 때.  \\n'\n",
            " '  - 대화 기록이나 외부 데이터를 기반으로 동적 워크플로우를 설계해야 할 때.  \\n'\n",
            " '- **LangGraph의 강점**:  \\n'\n",
            " '  - 상태 관리를 통해 **확장성**과 **유지보수성**을 높이면서도, LangChain의 유연성을 그대로 활용할 수 있습니다.  \\n'\n",
            " '\\n'\n",
            " '> 🔍 **참고**: LangGraph는 LangChain의 \"상태 관리 확장판\"으로, 복잡한 애플리케이션에서 진정한 힘을 발휘합니다. '\n",
            " '공식 문서와 예제 코드를 통해 실제 구현 방식을 익히는 것이 중요합니다.')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "pprint(result['final_answer'].content)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "faiss-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
