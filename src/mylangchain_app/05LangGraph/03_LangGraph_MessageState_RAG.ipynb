{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Env 환경변수`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n",
    "\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "print(UPSTAGE_API_KEY[30:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MessageGraph 역할\n",
    "* MessageGraph는 **채팅 및 대화형 애플리케이션**을 구축하는 데 특화된 그래프 클래스입니다. \n",
    "    * 일반적인 StateGraph가 딕셔너리 기반의 상태를 관리하는 반면, MessageGraph는 대화의 흐름을 나타내는 **메시지 목록(list[messages])**을 핵심 상태로 사용합니다. \n",
    "    * 이를 통해 사용자와 AI 간의 상호작용을 자연스럽게 모델링하고 관리할 수 있습니다.\n",
    "\n",
    "* MessageGraph는 다음과 같은 주요 기능을 제공합니다.\n",
    "    * 메시지 기반 상태 관리: 상태를 messages라는 키를 가진 리스트로 자동 설정하여, 사용자와 AI의 대화 기록을 손쉽게 추적할 수 있습니다.\n",
    "    * 자동 병합: 각 노드에서 새로운 메시지 목록을 반환하면, MessageGraph는 이를 기존 메시지 목록에 자동으로 추가(append)합니다. \n",
    "        * 이는 StateGraph에서 Annotated와 add를 사용해 수동으로 구현해야 했던 기능을 기본적으로 제공합니다.\n",
    "    * 대화 중심 흐름: 대화형 에이전트의 작동 방식을 직관적으로 표현합니다. 한 노드에서 사용자 메시지를 처리하고, 다른 노드에서 AI 응답을 생성하는 등 대화의 각 단계를 명확하게 구분할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(1) Messages State 정의`\n",
    "- 이전 대화 기록을 그래프 상태에 메시지 목록으로 저장하는 것이 유용\n",
    "- 그래프 상태에 Message 객체 목록을 저장하는 키(채널)를 추가하고, 이 키에 리듀서 함수를 추가 \n",
    "- 리듀서 함수 선택:\n",
    "    - operator.add를 사용하면: 새 메시지를 기존 목록에 단순히 추가\n",
    "    - add_messages 함수를 사용하면:\n",
    "        - 새 메시지는 기존 목록에 추가\n",
    "        - 기존 메시지 업데이트도 올바르게 처리 (메시지 ID를 추적)\n",
    "```python\n",
    "class MessageState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]        \n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(2) RAG Chain 구성`\n",
    "- 메뉴 검색을 위한 벡터저장소를 초기화 (기존 저장소를 로드)\n",
    "- LangChain Runnable로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "# LangGraph MessagesState라는 미리 만들어진 상태를 사용\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from textwrap import dedent\n",
    "from typing import List, Literal, Tuple\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solar-pro\n",
      "{'id': 'e3043c2a-d98e-4eda-b18d-d3f60286276e', 'metadata': {'source': '../data/restaurant_menu.txt', 'menu_number': 5, 'menu_name': '가든 샐러드'}, 'page_content': '5. 가든 샐러드\\n   • 가격: ₩12,000\\n   • 주요 식재료: 유기농 믹스 그린, 체리 토마토, 오이, 당근, 발사믹 드레싱\\n   • 설명: 신선한 유기농 채소들로 구성된 건강한 샐러드입니다. 아삭한 식감의 믹스 그린에 달콤한 체리 토마토, 오이, 당근을 더해 다양한 맛과 식감을 즐길 수 있습니다. 특제 발사믹 드레싱이 채소 본연의 맛을 살려줍니다.', 'type': 'Document'}\n",
      "{'id': '7693797b-8fac-433b-a4e3-bb21373b32fc', 'metadata': {'source': '../data/restaurant_menu.txt', 'menu_number': 8, 'menu_name': '안심 스테이크 샐러드'}, 'page_content': '8. 안심 스테이크 샐러드\\n   • 가격: ₩26,000\\n   • 주요 식재료: 소고기 안심, 루꼴라, 체리 토마토, 발사믹 글레이즈\\n   • 설명: 부드러운 안심 스테이크를 얇게 슬라이스하여 신선한 루꼴라 위에 올린 메인 요리 샐러드입니다. 체리 토마토와 파마산 치즈 플레이크로 풍미를 더하고, 발사믹 글레이즈로 마무리하여 고기의 풍미를 한층 끌어올렸습니다.', 'type': 'Document'}\n",
      "{'id': '680ccab1-ce9d-4060-9f41-e097e5f7ed6e', 'metadata': {'source': '../data/restaurant_menu.txt', 'menu_number': 9, 'menu_name': '치킨 콘피'}, 'page_content': '9. 치킨 콘피\\n   • 가격: ₩23,000\\n   • 주요 식재료: 닭다리살, 허브, 마늘, 올리브 오일\\n   • 설명: 닭다리살을 허브와 마늘을 넣은 올리브 오일에 저온에서 장시간 조리한 프랑스 요리입니다. 부드럽고 촉촉한 육질이 특징이며, 로즈메리 감자와 제철 채소를 곁들여 제공합니다. 레몬 제스트를 뿌려 상큼한 향을 더했습니다.', 'type': 'Document'}\n",
      "{'id': 'efaa0864-f0f1-4af4-a192-7fb33dae207c', 'metadata': {'source': '../data/restaurant_menu.txt', 'menu_number': 6, 'menu_name': '해산물 파스타'}, 'page_content': '6. 해산물 파스타\\n   • 가격: ₩24,000\\n   • 주요 식재료: 링귀네 파스타, 새우, 홍합, 오징어, 토마토 소스\\n   • 설명: 알 덴테로 삶은 링귀네 파스타에 신선한 해산물을 듬뿍 올린 메뉴입니다. 토마토 소스의 산미와 해산물의 감칠맛이 조화를 이루며, 마늘과 올리브 오일로 풍미를 더했습니다. 파슬리를 뿌려 향긋한 맛을 더합니다.', 'type': 'Document'}\n",
      "{'id': '120a800f-f1fe-4c0c-876b-50319d39c324', 'metadata': {'source': '../data/restaurant_menu.txt', 'menu_number': 4, 'menu_name': '버섯 크림 수프'}, 'page_content': '4. 버섯 크림 수프\\n   • 가격: ₩10,000\\n   • 주요 식재료: 양송이버섯, 표고버섯, 생크림, 트러플 오일\\n   • 설명: 양송이버섯과 표고버섯을 오랜 시간 정성스레 끓여 만든 크림 수프입니다. 부드러운 텍스처와 깊은 버섯 향이 특징이며, 최상급 트러플 오일을 살짝 뿌려 고급스러운 향을 더했습니다. 파슬리를 곱게 다져 고명으로 올려 제공됩니다.', 'type': 'Document'}\n",
      "{'id': '3d64c6ed-a05f-4e36-9f91-3fe4fc4f7d1f', 'metadata': {'source': '../data/restaurant_menu.txt', 'menu_number': 2, 'menu_name': '트러플 리조또'}, 'page_content': '2. 트러플 리조또\\n   • 가격: ₩22,000\\n   • 주요 식재료: 이탈리아산 아르보리오 쌀, 블랙 트러플, 파르미지아노 레지아노 치즈\\n   • 설명: 크리미한 텍스처의 리조또에 고급 블랙 트러플을 듬뿍 얹어 풍부한 향과 맛을 즐길 수 있는 메뉴입니다. 24개월 숙성된 파르미지아노 레지아노 치즈를 사용하여 깊은 맛을 더했으며, 주문 즉시 조리하여 최상의 상태로 제공됩니다.', 'type': 'Document'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embeddings_model = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "\n",
    "# menu db 벡터 저장소 로드\n",
    "menu_db = FAISS.load_local(\n",
    "    \"../db/menu_db\", \n",
    "    embeddings_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "# LLM 모델 \n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    ")\n",
    "print(llm.model_name)\n",
    "\n",
    "# RAG 체인 구성\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "system = \"\"\"\n",
    "You are a helpful assistant. Use the following context to answer the user's question:\n",
    "\n",
    "[Context]\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "# 검색기 정의\n",
    "retriever = menu_db.as_retriever(\n",
    "    search_kwargs={\"k\": 6}\n",
    ")\n",
    "\n",
    "query = \"채식주의자를 위한 메뉴를 추천해주세요.\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "# 검색된 문서 출력\n",
    "for doc in retrieved_docs:\n",
    "    print(vars(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "채식주의자를 위한 메뉴로 다음과 같이 추천해드릴 수 있습니다:\n",
      "\n",
      "1. **가든 샐러드 (₩12,000)**  \n",
      "   - **이유**: 유기농 채소(믹스 그린, 체리 토마토, 오이, 당근)로만 구성된 완전한 채식 메뉴입니다. 발사믹 드레싱으로 가벼운 한 끼로 적합합니다.  \n",
      "   - **주의**: 드레싱에 동물성 성분이 포함되지 않았는지 확인이 필요할 수 있습니다.\n",
      "\n",
      "2. **트러플 리조또 (₩22,000)**  \n",
      "   - **이유**: 아르보리오 쌀, 블랙 트러플, 파르미지아노 치즈로 만든 리조또로, 채식주의자도 즐길 수 있습니다.  \n",
      "   - **주의**: 치즈가 동물성 유래이므로 **락토-오보 채식주의자**에게 적합합니다. 비건(완전 채식)인 경우 제외됩니다.\n",
      "\n",
      "### 추가 고려사항\n",
      "- **비건(완전 채식)**: 가든 샐러드만 가능합니다. 다른 메뉴는 치즈나 해산물 성분이 포함되어 있습니다.  \n",
      "- **해산물을 피하는 채식자**: 해산물 파스타와 안심 스테이크 샐러드는 제외됩니다.  \n",
      "\n",
      "메뉴 주문 전 재료에 대한 추가 확인이 필요할 수 있습니다. 😊\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# RAG 체인 구성\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# RAG 체인 실행\n",
    "query = \"채식주의자를 위한 메뉴를 추천해주세요.\"\n",
    "response = rag_chain.invoke(query)\n",
    "\n",
    "# 답변 출력\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(3) 노드(Node)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class GraphState(MessagesState):\n",
    "    # messages key는 기본적으로 제공 - 다른 키를 추가하고 싶을 경우 아래 주석과 같이 적용 가능 \n",
    "    documents: List[Document]\n",
    "    grade: float\n",
    "    num_generation: int\n",
    "    \n",
    "# 이 함수는 사용자의 질문을 받아 문서를 검색하고 답변을 생성합니다.\n",
    "def retrieve_and_respond(state: GraphState):\n",
    "    print(\"==>1. retrieve_and_respond\")\n",
    "    # 'messages' 리스트의 가장 마지막 메시지를 가져옵니다.\n",
    "    # state['messages'][-1]은 사용자의 마지막 질문을 가져옵니다.\n",
    "    last_human_message = state['messages'][-1]\n",
    "    \n",
    "    # HumanMessage 객체에서 실제 질문 내용(텍스트)을 가져옵니다.\n",
    "    query = last_human_message.content\n",
    "    \n",
    "    # retriever를 사용하여 쿼리와 관련된 문서를 벡터DB에서 검색합니다.\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "    \n",
    "    # RAG 체인(rag_chain)을 사용하여 쿼리에 대한 최종 답변을 생성합니다.\n",
    "    # 이 체인은 검색된 문서를 LLM에 전달하여 답변의 근거로 사용합니다.\n",
    "    response = rag_chain.invoke(query)\n",
    "    \n",
    "    # 검색된 문서와 AI의 응답을 GraphState에 저장하여 반환합니다.\n",
    "    # 'messages' 필드에는 새로운 AI 응답(AIMessage)이 추가됩니다.\n",
    "    # 'documents' 필드에는 검색된 문서 목록이 저장됩니다.\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=response)],\n",
    "        \"documents\": retrieved_docs\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pydantic 모델 정의: \n",
    "* GradeResponse는 LLM의 출력 형식을 **점수(score)**와 **설명(explanation)**을 포함하는 구조로 강제합니다. \n",
    "* 이 모델을 통해 LLM은 정해진 규칙을 따르는 정형화된 JSON 응답을 생성합니다.\n",
    "\n",
    "#### 답변 평가 함수: grade_answer 함수\n",
    "* 정보 추출: state 객체에서 사용자의 **질문(-2)**과 AI의 답변(-1), 그리고 답변의 근거가 된 **문서(documents)**를 가져옵니다.\n",
    "* 프롬프트 생성: LLM에게 평가 전문가 역할을 부여하는 시스템 메시지와 평가에 필요한 모든 정보를 담은 인간 메시지를 포함한 프롬프트를 만듭니다.\n",
    "* 평가 체인 구성: llm.with_structured_output(schema=GradeResponse)를 사용해, LLM이 GradeResponse 모델에 맞춰 응답을 생성하도록 강제합니다.\n",
    "* 평가 실행: 구성된 체인에 질문, 답변, 문서를 입력하여 실행하고, GradeResponse 객체를 얻습니다.\n",
    "* 상태 업데이트: 평가 점수와 현재까지의 답변 생성 횟수를 state에 저장하여 반환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pydantic을 사용해 LLM 응답의 구조를 정의합니다.\n",
    "# 이 클래스는 LLM이 반환해야 할 데이터 형식을 강제합니다.\n",
    "class GradeResponse(BaseModel):\n",
    "    \"\"\"답변 평가 결과를 나타내는 모델입니다.\"\"\"\n",
    "    \n",
    "    # score 필드는 0.0에서 1.0 사이의 점수를 나타냅니다.\n",
    "    score: float = Field(\n",
    "        #...(Ellipsis, 말줄임표)는 \"이 필드는 필수값이며 기본값이 없음\"을 의미합니다.\n",
    "        ...,\n",
    "        ge=0,  # 0보다 크거나 같음\n",
    "        le=1,  # 1보다 작거나 같음\n",
    "        description=\"0에서 1 사이의 점수, 1은 완벽한 답변을 의미\"\n",
    "    )\n",
    "    \n",
    "    # explanation 필드는 점수에 대한 설명을 담는 문자열입니다.\n",
    "    explanation: str = Field(\n",
    "        ...,\n",
    "        description=\"주어진 점수에 대한 설명\"\n",
    "    )\n",
    "\n",
    "# 답변 품질을 평가하는 함수\n",
    "# 이 함수는 RAG 시스템의 핵심 단계 중 하나로, 생성된 답변을 자체적으로 평가합니다.\n",
    "def grade_answer(state: GraphState):\n",
    "    print(\"==>2. grade_answer\")\n",
    "    # LangGraph의 상태(state)에서 메시지 기록을 가져옵니다.\n",
    "    messages = state['messages']\n",
    "    pprint(messages)\n",
    "    \n",
    "    # 질문과 답변을 추출합니다.\n",
    "    # -2는 사용자의 마지막 질문, -1은 AI의 마지막 답변을 의미합니다.\n",
    "    question = messages[-2].content\n",
    "    print('====>2. question ', type(messages[-2]))\n",
    "    print(question)\n",
    "\n",
    "    answer = messages[-1].content\n",
    "    print('====>2. answer ', type(messages[-1]))\n",
    "    print(answer)\n",
    "    \n",
    "    # 검색된 문서 목록을 가져와 프롬프트에 사용하기 위해 포맷팅합니다.\n",
    "    context = format_docs(state['documents'])\n",
    "    print('====>2. context ')\n",
    "    print(context)\n",
    "\n",
    "    # LLM에게 평가 전문가 역할을 부여하는 시스템 프롬프트입니다.\n",
    "    grading_system = \"\"\"당신은 전문 평가자입니다. 주어진 맥락을 고려하여 질문에 대한 답변의 관련성과 정확성을 평가하세요.\n",
    "    1이 완벽한 점수인 0에서 1 사이의 점수를 설명과 함께 제공하세요.\"\"\"\n",
    "\n",
    "    # LLM이 평가에 사용할 입력 프롬프트 템플릿을 정의합니다.\n",
    "    grading_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", grading_system),\n",
    "        (\"human\", \"[Question]\\n{question}\\n\\n[Context]\\n{context}\\n\\n[Answer]\\n{answer}\\n\\n[Grade]\\n\")\n",
    "    ])\n",
    "    \n",
    "    # 프롬프트와 LLM을 연결하는 체인을 만듭니다.\n",
    "    # .with_structured_output() 메서드는 LLM이 GradeResponse Pydantic 모델에 맞춰 응답하도록 강제합니다.\n",
    "    grading_chain = grading_prompt | llm.with_structured_output(schema=GradeResponse)\n",
    "    \n",
    "    # 평가 체인을 실행하고, LLM의 정형화된 응답을 받습니다.\n",
    "    grade_response = grading_chain.invoke({\n",
    "        \"question\": question,\n",
    "        \"context\": context,\n",
    "        \"answer\": answer\n",
    "    })\n",
    "\n",
    "    # 답변 생성 시도 횟수를 추적합니다.\n",
    "    num_generation = state.get('num_generation', 0)\n",
    "    num_generation += 1\n",
    "    \n",
    "    print('====>2. grade_response.score ')\n",
    "    print(grade_response.score)\n",
    "    # 평가 점수와 갱신된 생성 횟수를 상태에 저장하여 반환합니다.\n",
    "    return {\"grade\": grade_response.score, \"num_generation\": num_generation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(4) 엣지(Edge)`\n",
    "* routing 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 이 함수는 RAG 에이전트가 다음 행동을 결정하는 '라우터' 역할을 합니다.\n",
    "# 반환 값은 \"retrieve_and_respond\" 또는 \"generate\"로 고정됩니다.\n",
    "# END 노드에 대한 별칭(alias)으로 \"generate\"로 사용합니다.\n",
    "def should_retry(state: GraphState) -> Literal[\"retrieve_and_respond\", \"generate\"]:\n",
    "    print(\"==>3. should_retry 라우팅함수\")\n",
    "    print(\"----GRADTING---\")\n",
    "    print(\"Grade Score 점수 : \", state[\"grade\"])\n",
    "    print(\"시도횟수 = \", state[\"num_generation\"])\n",
    "\n",
    "    # 답변 생성 시도 횟수를 확인합니다.\n",
    "    # 만약 3번 이상 시도했다면, 더 이상 재시도하지 않고 최종 답변을 생성하도록 합니다.\n",
    "    if state[\"num_generation\"] > 2:\n",
    "        return \"generate\"\n",
    "    \n",
    "    # 답변의 품질 점수를 확인합니다.\n",
    "    # 점수가 0.7 미만이면, 현재 답변이 충분하지 않다고 판단하고\n",
    "    # 문서를 다시 검색하여 답변을 재시도하도록 합니다.\n",
    "    if state[\"grade\"] < 0.7:\n",
    "        return \"retrieve_and_respond\"\n",
    "    else:\n",
    "        # 점수가 0.7 이상이면, 답변이 충분히 좋다고 판단하고\n",
    "        # 최종 답변을 생성하도록 합니다.\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(5) 그래프(Graph) 구성`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StateGraph는 그래프의 상태를 관리하는 기본 클래스입니다.\n",
    "# GraphState는 그래프가 공유하는 데이터의 구조를 정의한 사용자정의 클래스입니다.\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "# --- Node 정의 ---\n",
    "# 그래프에 두 개의 노드(처리 단계)를 추가합니다.\n",
    "# \"retrieve_and_respond\": 문서를 검색하고 답변을 생성하는 노드입니다.\n",
    "# \"grade_answer\": 생성된 답변의 품질을 평가하는 노드입니다.\n",
    "builder.add_node(\"retrieve_and_respond\", retrieve_and_respond)\n",
    "builder.add_node(\"grade_answer\", grade_answer)\n",
    "\n",
    "# --- Edge(연결) 추가 ---\n",
    "# 그래프의 시작과 끝, 그리고 노드 간의 흐름을 정의합니다.\n",
    "# START에서 시작하여 \"retrieve_and_respond\" 노드로 이동합니다.\n",
    "builder.add_edge(START, \"retrieve_and_respond\")\n",
    "\n",
    "# \"retrieve_and_respond\" 노드에서 \"grade_answer\" 노드로 이동합니다.\n",
    "builder.add_edge(\"retrieve_and_respond\", \"grade_answer\")\n",
    "\n",
    "# --- 조건부 Edge 추가 ---\n",
    "# \"grade_answer\" 노드의 결과에 따라 다음 노드를 동적으로 결정합니다.\n",
    "builder.add_conditional_edges(\n",
    "    # 현재 노드: \"grade_answer\"\n",
    "    \"grade_answer\",\n",
    "    # 라우팅 함수: 'should_retry' 함수가 다음 노드를 결정합니다.\n",
    "    should_retry,\n",
    "    # 매핑: 'should_retry' 함수의 반환 값에 따라 이동할 노드를 정의합니다.\n",
    "    {\n",
    "        # 'should_retry'가 \"retrieve_and_respond\"를 반환하면, 같은 노드로 돌아가 재시도합니다.\n",
    "        \"retrieve_and_respond\": \"retrieve_and_respond\",\n",
    "        # 'should_retry'가 \"generate\"를 반환하면, 그래프 실행을 종료합니다.\n",
    "        # \"generate\"가 'END' 노드의 별칭 역할을 합니다.\n",
    "        \"generate\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# --- 그래프 컴파일 ---\n",
    "# 정의된 노드와 엣지를 기반으로 실행 가능한 그래프를 만듭니다.\n",
    "# 이 단계는 그래프를 최적화하고 실행 준비를 완료합니다.\n",
    "graph = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mermaid Code:\n",
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tretrieve_and_respond(retrieve_and_respond)\n",
      "\tgrade_answer(grade_answer)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> retrieve_and_respond;\n",
      "\tgrade_answer -. &nbsp;generate&nbsp; .-> __end__;\n",
      "\tgrade_answer -.-> retrieve_and_respond;\n",
      "\tretrieve_and_respond --> grade_answer;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 그래프 시각화\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n",
    "mermaid_code = graph.get_graph().draw_mermaid()\n",
    "print(\"Mermaid Code:\")\n",
    "print(mermaid_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://mermaid.live/ 에서  mermain_code 로 직접 확인한다.\n",
    "\n",
    "* [Graph이미지](https://mermaidchart.com/play?utm_source=mermaid_live_editor&utm_medium=share#pako:eNp9kd9ugjAUxl-lOUsWTYBBUcBqvJmPsKuNhVQ5BRIopJT9M777CirRhYyb9mu_8_1OD0c41CkCg0zxJicvu3UsY50krebKLLO3TbMd1eap2b7PGWOiUK3ujQq1KvADEy7TRGHb1DKdTR3Oe7dhpP1p-4lqdivmZyga_xU57Edgyc-8sRVi21syBVr_BRHbIY9y3zbrDCUqrvGsiGMSLpypov_ypy6Gjm4zBufBdN7uUJAUBe9KTURRluxBUOEKYZWFRDvHIss18xx6VzDMeLDbdcMPhf5m7p2hn8klbi_2gTjEkpgPLPMvixSY4GWLFlSoKt5rOPaGGHSOFcbAzPbSVAyxPJm6hsvXuq6AadWZSlV3WX4VXZOa0e0Kbp5YjeHKjA_Vc91JDczzhwhgR_gCFpoHhb5Ll_4q8PzFamnBt_EsIicKaLSiy8hfhDQ6WfAzMF0nDH0aUuoFPnVdP4xOv2Qa5lY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`(6) Graph 실행`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>1. retrieve_and_respond\n",
      "==>2. grade_answer\n",
      "[HumanMessage(content='LangGraph는 무엇인가요?', additional_kwargs={}, response_metadata={}, id='f7f78af4-b8a4-4a82-b089-702a304147c6'),\n",
      " AIMessage(content='LangGraph는 **대규모 언어 모델(LLM)을 활용한 상태 기반(stateful) 대화형 애플리케이션 개발을 위한 오픈소스 프레임워크**입니다. LangChain과 통합되어 설계되었으며, 복잡한 멀티턴(multi-turn) 대화 흐름을 그래프 구조로 시각화하고 관리할 수 있도록 지원합니다.  \\n\\n### 주요 특징:\\n1. **상태 관리**: 사용자 세션의 상태를 추적하여 이전 대화 내용을 기반으로 응답을 생성합니다.  \\n2. **그래프 기반 흐름 제어**: 대화 로직을 노드(Node)와 에지(Edge)로 표현해 복잡한 워크플로우를 직관적으로 설계할 수 있습니다.  \\n3. **LangChain 연동**: LangChain의 LLM, 메모리, 체인(Chain) 컴포넌트와 호환되어 확장성이 뛰어납니다.  \\n4. **확장성**: 커스텀 노드/에지를 추가해 특정 비즈니스 로직에 맞춰 흐름을 확장할 수 있습니다.  \\n\\n### 사용 사례:\\n- **챗봇**: 예약 시스템, 고객 지원 등 다단계 대화가 필요한 애플리케이션.  \\n- **에이전트 시스템**: 외부 API 호출, 툴 사용 등 복합적인 작업을 수행하는 에이전트.  \\n- **교육/튜터링**: 학습자의 이전 답변을 기반으로 적응형 학습을 제공하는 시스템.  \\n\\nLangGraph는 특히 **\"메모리 + 조건부 분기\"**가 필요한 애플리케이션에 적합하며, LangChain의 단순한 체인(Chain) 구조보다 유연한 설계가 가능합니다.  \\n\\n공식 문서: [https://langchain-ai.github.io/langgraph/](https://langchain-ai.github.io/langgraph/)  \\n\\n> 참고: 제공된 컨텍스트(해산물 파스타 등 메뉴 정보)는 LangGraph와 직접적인 관련이 없습니다. 해당 내용은 레스토랑 메뉴 설명으로 보입니다.', additional_kwargs={}, response_metadata={}, id='795972b9-8875-493f-9806-feafb1bc6d3d')]\n",
      "====>2. question  <class 'langchain_core.messages.human.HumanMessage'>\n",
      "LangGraph는 무엇인가요?\n",
      "====>2. answer  <class 'langchain_core.messages.ai.AIMessage'>\n",
      "LangGraph는 **대규모 언어 모델(LLM)을 활용한 상태 기반(stateful) 대화형 애플리케이션 개발을 위한 오픈소스 프레임워크**입니다. LangChain과 통합되어 설계되었으며, 복잡한 멀티턴(multi-turn) 대화 흐름을 그래프 구조로 시각화하고 관리할 수 있도록 지원합니다.  \n",
      "\n",
      "### 주요 특징:\n",
      "1. **상태 관리**: 사용자 세션의 상태를 추적하여 이전 대화 내용을 기반으로 응답을 생성합니다.  \n",
      "2. **그래프 기반 흐름 제어**: 대화 로직을 노드(Node)와 에지(Edge)로 표현해 복잡한 워크플로우를 직관적으로 설계할 수 있습니다.  \n",
      "3. **LangChain 연동**: LangChain의 LLM, 메모리, 체인(Chain) 컴포넌트와 호환되어 확장성이 뛰어납니다.  \n",
      "4. **확장성**: 커스텀 노드/에지를 추가해 특정 비즈니스 로직에 맞춰 흐름을 확장할 수 있습니다.  \n",
      "\n",
      "### 사용 사례:\n",
      "- **챗봇**: 예약 시스템, 고객 지원 등 다단계 대화가 필요한 애플리케이션.  \n",
      "- **에이전트 시스템**: 외부 API 호출, 툴 사용 등 복합적인 작업을 수행하는 에이전트.  \n",
      "- **교육/튜터링**: 학습자의 이전 답변을 기반으로 적응형 학습을 제공하는 시스템.  \n",
      "\n",
      "LangGraph는 특히 **\"메모리 + 조건부 분기\"**가 필요한 애플리케이션에 적합하며, LangChain의 단순한 체인(Chain) 구조보다 유연한 설계가 가능합니다.  \n",
      "\n",
      "공식 문서: [https://langchain-ai.github.io/langgraph/](https://langchain-ai.github.io/langgraph/)  \n",
      "\n",
      "> 참고: 제공된 컨텍스트(해산물 파스타 등 메뉴 정보)는 LangGraph와 직접적인 관련이 없습니다. 해당 내용은 레스토랑 메뉴 설명으로 보입니다.\n",
      "====>2. context \n",
      "6. 해산물 파스타\n",
      "   • 가격: ₩24,000\n",
      "   • 주요 식재료: 링귀네 파스타, 새우, 홍합, 오징어, 토마토 소스\n",
      "   • 설명: 알 덴테로 삶은 링귀네 파스타에 신선한 해산물을 듬뿍 올린 메뉴입니다. 토마토 소스의 산미와 해산물의 감칠맛이 조화를 이루며, 마늘과 올리브 오일로 풍미를 더했습니다. 파슬리를 뿌려 향긋한 맛을 더합니다.\n",
      "\n",
      "9. 치킨 콘피\n",
      "   • 가격: ₩23,000\n",
      "   • 주요 식재료: 닭다리살, 허브, 마늘, 올리브 오일\n",
      "   • 설명: 닭다리살을 허브와 마늘을 넣은 올리브 오일에 저온에서 장시간 조리한 프랑스 요리입니다. 부드럽고 촉촉한 육질이 특징이며, 로즈메리 감자와 제철 채소를 곁들여 제공합니다. 레몬 제스트를 뿌려 상큼한 향을 더했습니다.\n",
      "\n",
      "7. 랍스터 비스크\n",
      "   • 가격: ₩28,000\n",
      "   • 주요 식재료: 랍스터, 생크림, 브랜디, 파프리카\n",
      "   • 설명: 랍스터 껍질과 육수로 오랜 시간 우려낸 진한 비스크 수프입니다. 생크림으로 부드러운 질감을 더하고 브랜디로 깊은 풍미를 살렸습니다. 작은 랍스터 살을 토핑으로 올려 고급스러움을 더했습니다.\n",
      "\n",
      "4. 버섯 크림 수프\n",
      "   • 가격: ₩10,000\n",
      "   • 주요 식재료: 양송이버섯, 표고버섯, 생크림, 트러플 오일\n",
      "   • 설명: 양송이버섯과 표고버섯을 오랜 시간 정성스레 끓여 만든 크림 수프입니다. 부드러운 텍스처와 깊은 버섯 향이 특징이며, 최상급 트러플 오일을 살짝 뿌려 고급스러운 향을 더했습니다. 파슬리를 곱게 다져 고명으로 올려 제공됩니다.\n",
      "\n",
      "2. 트러플 리조또\n",
      "   • 가격: ₩22,000\n",
      "   • 주요 식재료: 이탈리아산 아르보리오 쌀, 블랙 트러플, 파르미지아노 레지아노 치즈\n",
      "   • 설명: 크리미한 텍스처의 리조또에 고급 블랙 트러플을 듬뿍 얹어 풍부한 향과 맛을 즐길 수 있는 메뉴입니다. 24개월 숙성된 파르미지아노 레지아노 치즈를 사용하여 깊은 맛을 더했으며, 주문 즉시 조리하여 최상의 상태로 제공됩니다.\n",
      "\n",
      "3. 연어 타르타르\n",
      "   • 가격: ₩18,000\n",
      "   • 주요 식재료: 노르웨이산 생연어, 아보카도, 케이퍼, 적양파\n",
      "   • 설명: 신선한 노르웨이산 생연어를 곱게 다져 아보카도, 케이퍼, 적양파와 함께 섞어 만든 타르타르입니다. 레몬 드레싱으로 상큼한 맛을 더했으며, 바삭한 브리오쉬 토스트와 함께 제공됩니다. 전채요리로 완벽한 메뉴입니다.\n",
      "====>2. grade_response.score \n",
      "0.98\n",
      "==>3. should_retry 라우팅함수\n",
      "----GRADTING---\n",
      "Grade Score 점수 :  0.98\n",
      "시도횟수 =  1\n",
      "최종 상태:\n",
      "\n",
      "{'documents': [Document(id='efaa0864-f0f1-4af4-a192-7fb33dae207c', metadata={'source': '../data/restaurant_menu.txt', 'menu_number': 6, 'menu_name': '해산물 파스타'}, page_content='6. 해산물 파스타\\n   • 가격: ₩24,000\\n   • 주요 식재료: 링귀네 파스타, 새우, 홍합, 오징어, 토마토 소스\\n   • 설명: 알 덴테로 삶은 링귀네 파스타에 신선한 해산물을 듬뿍 올린 메뉴입니다. 토마토 소스의 산미와 해산물의 감칠맛이 조화를 이루며, 마늘과 올리브 오일로 풍미를 더했습니다. 파슬리를 뿌려 향긋한 맛을 더합니다.'),\n",
      "               Document(id='680ccab1-ce9d-4060-9f41-e097e5f7ed6e', metadata={'source': '../data/restaurant_menu.txt', 'menu_number': 9, 'menu_name': '치킨 콘피'}, page_content='9. 치킨 콘피\\n   • 가격: ₩23,000\\n   • 주요 식재료: 닭다리살, 허브, 마늘, 올리브 오일\\n   • 설명: 닭다리살을 허브와 마늘을 넣은 올리브 오일에 저온에서 장시간 조리한 프랑스 요리입니다. 부드럽고 촉촉한 육질이 특징이며, 로즈메리 감자와 제철 채소를 곁들여 제공합니다. 레몬 제스트를 뿌려 상큼한 향을 더했습니다.'),\n",
      "               Document(id='0ca66637-b3d0-4656-a526-26ae23c875c9', metadata={'source': '../data/restaurant_menu.txt', 'menu_number': 7, 'menu_name': '랍스터 비스크'}, page_content='7. 랍스터 비스크\\n   • 가격: ₩28,000\\n   • 주요 식재료: 랍스터, 생크림, 브랜디, 파프리카\\n   • 설명: 랍스터 껍질과 육수로 오랜 시간 우려낸 진한 비스크 수프입니다. 생크림으로 부드러운 질감을 더하고 브랜디로 깊은 풍미를 살렸습니다. 작은 랍스터 살을 토핑으로 올려 고급스러움을 더했습니다.'),\n",
      "               Document(id='120a800f-f1fe-4c0c-876b-50319d39c324', metadata={'source': '../data/restaurant_menu.txt', 'menu_number': 4, 'menu_name': '버섯 크림 수프'}, page_content='4. 버섯 크림 수프\\n   • 가격: ₩10,000\\n   • 주요 식재료: 양송이버섯, 표고버섯, 생크림, 트러플 오일\\n   • 설명: 양송이버섯과 표고버섯을 오랜 시간 정성스레 끓여 만든 크림 수프입니다. 부드러운 텍스처와 깊은 버섯 향이 특징이며, 최상급 트러플 오일을 살짝 뿌려 고급스러운 향을 더했습니다. 파슬리를 곱게 다져 고명으로 올려 제공됩니다.'),\n",
      "               Document(id='3d64c6ed-a05f-4e36-9f91-3fe4fc4f7d1f', metadata={'source': '../data/restaurant_menu.txt', 'menu_number': 2, 'menu_name': '트러플 리조또'}, page_content='2. 트러플 리조또\\n   • 가격: ₩22,000\\n   • 주요 식재료: 이탈리아산 아르보리오 쌀, 블랙 트러플, 파르미지아노 레지아노 치즈\\n   • 설명: 크리미한 텍스처의 리조또에 고급 블랙 트러플을 듬뿍 얹어 풍부한 향과 맛을 즐길 수 있는 메뉴입니다. 24개월 숙성된 파르미지아노 레지아노 치즈를 사용하여 깊은 맛을 더했으며, 주문 즉시 조리하여 최상의 상태로 제공됩니다.'),\n",
      "               Document(id='5b000bd2-1a69-4a28-910d-58e2268fdee9', metadata={'source': '../data/restaurant_menu.txt', 'menu_number': 3, 'menu_name': '연어 타르타르'}, page_content='3. 연어 타르타르\\n   • 가격: ₩18,000\\n   • 주요 식재료: 노르웨이산 생연어, 아보카도, 케이퍼, 적양파\\n   • 설명: 신선한 노르웨이산 생연어를 곱게 다져 아보카도, 케이퍼, 적양파와 함께 섞어 만든 타르타르입니다. 레몬 드레싱으로 상큼한 맛을 더했으며, 바삭한 브리오쉬 토스트와 함께 제공됩니다. 전채요리로 완벽한 메뉴입니다.')],\n",
      " 'grade': 0.98,\n",
      " 'messages': [HumanMessage(content='LangGraph는 무엇인가요?', additional_kwargs={}, response_metadata={}, id='f7f78af4-b8a4-4a82-b089-702a304147c6'),\n",
      "              AIMessage(content='LangGraph는 **대규모 언어 모델(LLM)을 활용한 상태 기반(stateful) 대화형 애플리케이션 개발을 위한 오픈소스 프레임워크**입니다. LangChain과 통합되어 설계되었으며, 복잡한 멀티턴(multi-turn) 대화 흐름을 그래프 구조로 시각화하고 관리할 수 있도록 지원합니다.  \\n\\n### 주요 특징:\\n1. **상태 관리**: 사용자 세션의 상태를 추적하여 이전 대화 내용을 기반으로 응답을 생성합니다.  \\n2. **그래프 기반 흐름 제어**: 대화 로직을 노드(Node)와 에지(Edge)로 표현해 복잡한 워크플로우를 직관적으로 설계할 수 있습니다.  \\n3. **LangChain 연동**: LangChain의 LLM, 메모리, 체인(Chain) 컴포넌트와 호환되어 확장성이 뛰어납니다.  \\n4. **확장성**: 커스텀 노드/에지를 추가해 특정 비즈니스 로직에 맞춰 흐름을 확장할 수 있습니다.  \\n\\n### 사용 사례:\\n- **챗봇**: 예약 시스템, 고객 지원 등 다단계 대화가 필요한 애플리케이션.  \\n- **에이전트 시스템**: 외부 API 호출, 툴 사용 등 복합적인 작업을 수행하는 에이전트.  \\n- **교육/튜터링**: 학습자의 이전 답변을 기반으로 적응형 학습을 제공하는 시스템.  \\n\\nLangGraph는 특히 **\"메모리 + 조건부 분기\"**가 필요한 애플리케이션에 적합하며, LangChain의 단순한 체인(Chain) 구조보다 유연한 설계가 가능합니다.  \\n\\n공식 문서: [https://langchain-ai.github.io/langgraph/](https://langchain-ai.github.io/langgraph/)  \\n\\n> 참고: 제공된 컨텍스트(해산물 파스타 등 메뉴 정보)는 LangGraph와 직접적인 관련이 없습니다. 해당 내용은 레스토랑 메뉴 설명으로 보입니다.', additional_kwargs={}, response_metadata={}, id='795972b9-8875-493f-9806-feafb1bc6d3d')],\n",
      " 'num_generation': 1}\n"
     ]
    }
   ],
   "source": [
    "# 초기 상태\n",
    "#query = \"채식주의자를 위한 메뉴를 추천해주세요.\"\n",
    "query = \"LangGraph는 무엇인가요?\"\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=query)],\n",
    "}\n",
    "\n",
    "# 그래프 실행 \n",
    "final_state = graph.invoke(initial_state)\n",
    "\n",
    "# 최종 상태 출력\n",
    "print(\"최종 상태:\\n\")\n",
    "pprint(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LangGraph는 **대규모 언어 모델(LLM)을 활용한 상태 기반(stateful) 대화형 애플리케이션 개발을 위한 오픈소스 '\n",
      " '프레임워크**입니다. LangChain과 통합되어 설계되었으며, 복잡한 멀티턴(multi-turn) 대화 흐름을 그래프 구조로 시각화하고 '\n",
      " '관리할 수 있도록 지원합니다.  \\n'\n",
      " '\\n'\n",
      " '### 주요 특징:\\n'\n",
      " '1. **상태 관리**: 사용자 세션의 상태를 추적하여 이전 대화 내용을 기반으로 응답을 생성합니다.  \\n'\n",
      " '2. **그래프 기반 흐름 제어**: 대화 로직을 노드(Node)와 에지(Edge)로 표현해 복잡한 워크플로우를 직관적으로 설계할 수 '\n",
      " '있습니다.  \\n'\n",
      " '3. **LangChain 연동**: LangChain의 LLM, 메모리, 체인(Chain) 컴포넌트와 호환되어 확장성이 '\n",
      " '뛰어납니다.  \\n'\n",
      " '4. **확장성**: 커스텀 노드/에지를 추가해 특정 비즈니스 로직에 맞춰 흐름을 확장할 수 있습니다.  \\n'\n",
      " '\\n'\n",
      " '### 사용 사례:\\n'\n",
      " '- **챗봇**: 예약 시스템, 고객 지원 등 다단계 대화가 필요한 애플리케이션.  \\n'\n",
      " '- **에이전트 시스템**: 외부 API 호출, 툴 사용 등 복합적인 작업을 수행하는 에이전트.  \\n'\n",
      " '- **교육/튜터링**: 학습자의 이전 답변을 기반으로 적응형 학습을 제공하는 시스템.  \\n'\n",
      " '\\n'\n",
      " 'LangGraph는 특히 **\"메모리 + 조건부 분기\"**가 필요한 애플리케이션에 적합하며, LangChain의 단순한 체인(Chain) '\n",
      " '구조보다 유연한 설계가 가능합니다.  \\n'\n",
      " '\\n'\n",
      " '공식 문서: '\n",
      " '[https://langchain-ai.github.io/langgraph/](https://langchain-ai.github.io/langgraph/)  \\n'\n",
      " '\\n'\n",
      " '> 참고: 제공된 컨텍스트(해산물 파스타 등 메뉴 정보)는 LangGraph와 직접적인 관련이 없습니다. 해당 내용은 레스토랑 메뉴 '\n",
      " '설명으로 보입니다.')\n"
     ]
    }
   ],
   "source": [
    "# 최종 답변만 출력\n",
    "pprint(final_state['messages'][-1].content) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gradio 챗봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "import gradio as gr\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# 예시 질문 리스트\n",
    "# Gradio 인터페이스에 미리 보여줄 질문들입니다. 사용자는 이 질문들을 클릭해 바로 테스트할 수 있습니다.\n",
    "example_questions = [\n",
    "    \"채식주의자를 위한 메뉴를 추천해주세요.\",\n",
    "    \"오늘의 스페셜 메뉴는 무엇인가요?\",\n",
    "    \"스테이크 메뉴가 있나요?\"\n",
    "]\n",
    "\n",
    "# 대답 함수 정의\n",
    "# 이 함수는 Gradio의 ChatInterface에 연결되어 사용자의 질문을 처리하고 AI의 응답을 반환합니다.\n",
    "def answer_invoke(message: str, history: List[Tuple[str, str]]) -> str:\n",
    "    try:\n",
    "        # 채팅 기록을 AI 모델이 이해할 수 있는 LangChain 메시지 객체 형식으로 변환합니다.\n",
    "        chat_history = []\n",
    "        for human, ai in history:\n",
    "            chat_history.append(HumanMessage(content=human))\n",
    "            chat_history.append(AIMessage(content=ai))\n",
    "\n",
    "        # LangGraph에 전달할 초기 상태를 구성합니다.\n",
    "        # 최근 2개의 대화 기록과 현재 사용자의 질문을 포함시킵니다.\n",
    "        # 이는 AI가 이전 대화의 맥락을 이해하도록 돕습니다.\n",
    "        initial_state = {\n",
    "            \"messages\": chat_history[-2:] + [HumanMessage(content=message)],\n",
    "        }\n",
    "\n",
    "        # LangGraph를 호출하여 메시지 체인을 실행하고 최종 상태를 얻습니다.\n",
    "        # 이 과정에서 RAG 로직이 수행됩니다.\n",
    "        final_state = graph.invoke(initial_state)\n",
    "        \n",
    "        # 최종 상태에서 가장 마지막에 생성된 메시지(AI의 응답)의 내용을 반환합니다.\n",
    "        return final_state[\"messages\"][-1].content\n",
    "        \n",
    "    except Exception as e:\n",
    "        # 오류 발생 시 사용자에게 친절한 메시지를 반환하고,\n",
    "        # 개발자가 디버깅할 수 있도록 콘솔에 오류를 출력합니다.\n",
    "        print(f\"오류가 발생했습니다: {str(e)}\")\n",
    "        return \"죄송합니다. 응답을 생성하는 동안 오류가 발생했습니다. 다시 시도해 주세요.\"\n",
    "\n",
    "\n",
    "# Gradio 인터페이스 생성\n",
    "# 사용자와 상호작용할 UI를 만듭니다.\n",
    "demo = gr.ChatInterface(\n",
    "    fn=answer_invoke,  # 사용자 입력이 들어왔을 때 실행할 함수\n",
    "    title=\"레스토랑 메뉴 AI 어시스턴트\",  # UI의 제목\n",
    "    description=\"메뉴 정보, 추천, 음식 관련 질문에 답변해 드립니다.\",  # UI의 설명\n",
    "    examples=example_questions,  # 사용자가 쉽게 시작할 수 있도록 제공되는 예시 질문들\n",
    "    theme=gr.themes.Soft()  # 부드러운 색상의 UI 테마 적용\n",
    ")\n",
    "\n",
    "# Gradio 애플리케이션을 실행합니다.\n",
    "# 이 함수를 호출하면 웹 서버가 시작되어 로컬에서 채팅 인터페이스에 접속할 수 있습니다.\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "# 데모 종료\n",
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
